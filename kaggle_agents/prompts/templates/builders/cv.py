"""
Cross-validation and OOF (Out-of-Fold) instruction builders.
"""


def build_cv_instructions(working_dir: str, component_name: str) -> list[str]:
    """Build cross-validation instructions."""
    return [
        "\nðŸ”„ CONSISTENT CROSS-VALIDATION (CRITICAL - USE CANONICAL FOLDS):",
        f"  - **MANDATORY**: Load canonical folds from `{working_dir}/canonical/folds.npy`",
        f"  - **MANDATORY**: Load canonical train_ids from `{working_dir}/canonical/train_ids.npy`",
        "  - **NEVER** create your own KFold/StratifiedKFold - canonical folds are already optimized",
        "    ```python",
        "    from pathlib import Path",
        "    import numpy as np",
        "",
        f"    canonical_dir = Path('{working_dir}') / 'canonical'",
        "    folds = np.load(canonical_dir / 'folds.npy')",
        "    train_ids = np.load(canonical_dir / 'train_ids.npy', allow_pickle=True)",
        "    n_folds = int(folds.max()) + 1",
        "",
        "    for fold_idx in range(n_folds):",
        "        train_mask = folds != fold_idx",
        "        val_mask = folds == fold_idx",
        "        X_train, X_val = X[train_mask], X[val_mask]",
        "        y_train, y_val = y[train_mask], y[val_mask]",
        "        # ... train model on fold ...",
        "    ```",
        "  - WHY: Independent fold creation causes OOF misalignment â†’ stacking ensemble fails",
        "  - CRITICAL: Fit FEATURE preprocessing/scalers INSIDE each CV fold (fit on X_train, transform X_val/X_test)",
        "  - EXCEPTION: TARGET LabelEncoder must be fit ONCE on FULL y BEFORE the CV loop (see tabular constraints)",
        f"  - CRITICAL: MUST save Out-of-Fold (OOF) predictions during CV to models/oof_{component_name}.npy",
        "  - OOF predictions enable proper stacking ensemble (meta-model trained on OOF)",
        "  - AFTER saving OOF/Test: print lines 'Saved OOF predictions to ...' and 'Saved test predictions to ...'",
        "  - MUST print 'Final Validation Performance: {score}'",
        "  - If metric is NaN/inf, replace with 0.0 before printing Final Validation Performance",
        "  - Multiclass log_loss: after clipping, renormalize rows to sum to 1",
        "  - If OOF rows are empty due to early stop, compute log_loss on rows with sum>0",
        "  - MUST handle class imbalance with class_weight='balanced'",
    ]


def build_stacking_oof_instructions(working_dir: str, component_name: str) -> list[str]:
    """Build stacking/OOF instructions."""
    instructions = [
        "\nSTACKING & OOF REQUIREMENTS (CRITICAL):",
        "  1. Initialize `oof_preds` array of zeros with shape (n_train, n_classes) for multi-class.",
        "  2. Initialize `test_preds` array of zeros with shape (n_test, n_classes) for multi-class.",
        "  2b. **SHAPE CHECKS (MUST)**:",
        "     - Set `n_train = len(train_df)` and `n_test = len(test_df)` (or len(sample_submission) for test).",
        "     - Before saving: assert oof_preds.shape[0] == n_train and test_preds.shape[0] == n_test.",
        "     - If mismatch, raise ValueError (do NOT save corrupted arrays).",
        "  3. **CLASS ORDER ALIGNMENT (CRITICAL FOR ENSEMBLE - PREVENTS DEGRADATION)**:",
        "     - **STEP A**: Fit LabelEncoder on FULL y BEFORE the CV loop (NOT inside!):",
        "       ```python",
        "       from sklearn.preprocessing import LabelEncoder",
        "       le = LabelEncoder()",
        "       y_encoded = le.fit_transform(y)  # Fit on FULL training data",
        "       n_classes = len(le.classes_)",
        "       print(f'[LOG:INFO] Classes: {le.classes_} (n={n_classes})')",
        "       ```",
        "     - **STEP B**: Determine class order (HANDLE BOTH FORMATS!):",
        "       ```python",
        "       sample_sub = pd.read_csv(sample_submission_path)",
        "       submission_cols = sample_sub.columns[1:].tolist()",
        "       ",
        "       # CRITICAL: Detect submission format!",
        "       # Wide format (multi-column probabilities): ['1', '2', '3', '4', '5', '6', '7']",
        "       # Label format (single column): ['Cover_Type'] or ['target']",
        "       if len(submission_cols) > 1:",
        "           # Wide format - use column names as class order",
        "           class_order = submission_cols",
        "           print(f'[LOG:INFO] Wide format submission - class_order from columns: {class_order}')",
        "       else:",
        "           # Label format - use LabelEncoder classes as class order",
        "           class_order = le.classes_.tolist()",
        "           print(f'[LOG:INFO] Label format submission - class_order from LabelEncoder: {class_order}')",
        "       ```",
        "     - **STEP C**: Compute reordering indices (ONLY for wide format!):",
        "       ```python",
        "       le_classes = le.classes_.tolist()  # Model's LabelEncoder order",
        "       ",
        "       # For label format, no reordering needed (already aligned)",
        "       if len(submission_cols) > 1:",
        "           # Wide format: map LabelEncoder order to submission column order",
        "           reorder_idx = [le_classes.index(c) for c in class_order]",
        "       else:",
        "           # Label format: identity mapping (no reorder)",
        "           reorder_idx = list(range(len(le_classes)))",
        "       ```",
        "     - BEFORE saving, reorder predictions to match sample_submission:",
        "       ```python",
        "       oof_preds_aligned = oof_preds[:, reorder_idx]",
        "       test_preds_aligned = test_preds[:, reorder_idx]",
        "       ```",
        "     - **MANDATORY VERIFICATION (DEBUG PRINTS - DO NOT SKIP)**:",
        "       ```python",
        "       # Verify class order alignment BEFORE saving",
        "       print(f'DEBUG: First 3 LabelEncoder classes: {le.classes_[:3].tolist()}')",
        "       print(f'DEBUG: First 3 sample_submission cols: {sample_sub.columns[1:4].tolist()}')",
        "       print(f'DEBUG: Reorder indices (first 5): {reorder_idx[:5]}')",
        "       print(f'DEBUG: OOF shape after reorder: {oof_preds_aligned.shape}')",
        "       assert oof_preds_aligned.shape[1] == len(class_order), \\",
        "           f'Class count mismatch: {oof_preds_aligned.shape[1]} vs {len(class_order)}'",
        "       ```",
        "     - Save canonical class order for validation:",
        f"       `np.save(str(Path('{working_dir}') / 'models' / 'class_order.npy'), class_order)`",
        "  4. During CV loop:",
        "     - Fill `oof_preds[val_idx]` with predictions for validation fold.",
        "     - Predict on test set and accumulate:",
        "       - Binary: `test_preds += model.predict_proba(X_test)[:, 1] / n_folds`",
        "       - Multi-class: `test_preds += model.predict_proba(X_test) / n_folds`",
        "       - Regression: `test_preds += model.predict(X_test) / n_folds`",
        "  4b. **OOF VALIDATION (MANDATORY BEFORE SAVE - RAISES ERROR IF INVALID)**:",
        "     ```python",
        "     # CRITICAL: Validate OOF BEFORE saving - broken OOF breaks ensemble",
        "     def validate_oof_before_save(oof_preds, test_preds, n_train, n_test):",
        "         # Check shapes",
        "         if oof_preds.shape[0] != n_train:",
        "             raise ValueError(f'OOF shape mismatch: {oof_preds.shape[0]} vs expected {n_train}')",
        "         if test_preds.shape[0] != n_test:",
        "             raise ValueError(f'Test shape mismatch: {test_preds.shape[0]} vs expected {n_test}')",
        "         ",
        "         # Check NaN - MUST raise error, not just warn",
        "         if np.isnan(oof_preds).any():",
        "             nan_count = np.isnan(oof_preds).sum()",
        "             nan_pct = nan_count / oof_preds.size * 100",
        "             raise ValueError(f'OOF contains {nan_count} NaN values ({nan_pct:.1f}%)! Fix model training.')",
        "         if np.isnan(test_preds).any():",
        "             nan_count = np.isnan(test_preds).sum()",
        "             raise ValueError(f'Test contains {nan_count} NaN values! Fix model training.')",
        "         ",
        "         # Check Inf",
        "         if np.isinf(oof_preds).any():",
        "             raise ValueError('OOF contains Inf values!')",
        "         if np.isinf(test_preds).any():",
        "             raise ValueError('Test contains Inf values!')",
        "         ",
        "         # Check zero variance (constant predictions = useless model)",
        "         if oof_preds.std() < 1e-10:",
        "             raise ValueError('OOF has zero variance (constant predictions) - model is broken!')",
        "         ",
        "         print(f'[VALIDATE] OOF passed: shape={oof_preds.shape}, no NaN/Inf, var={oof_preds.std():.4f}')",
        "         return True",
        "     ",
        "     # Call BEFORE np.save()",
        "     validate_oof_before_save(oof_preds_aligned, test_preds_aligned, n_train, n_test)",
        "     ```",
        f"  5. Save OOF predictions (AFTER validation): `np.save(str(Path('{working_dir}') / 'models' / 'oof_{component_name}.npy'), oof_preds_aligned)`",
        f"  6. Save Test predictions (AFTER validation): `np.save(str(Path('{working_dir}') / 'models' / 'test_{component_name}.npy'), test_preds_aligned)`",
        "  7. **SAVE ALIGNMENT METADATA (CRITICAL FOR ENSEMBLE VALIDATION)**:",
        "     - Save train IDs (row order) for alignment validation:",
        "       ```python",
        "       train_ids = train_df['id'].values if 'id' in train_df.columns else train_df.index.values",
        f"       np.save(str(Path('{working_dir}') / 'models' / 'train_ids_{component_name}.npy'), train_ids)",
        "       ```",
        "     - Save class order per model (enables per-model validation):",
        f"       `np.save(str(Path('{working_dir}') / 'models' / 'class_order_{component_name}.npy'), class_order)`",
        "     - Ensemble will use these files to validate compatibility before combining models.",
        "  8. Ensemble will ONLY run if BOTH oof_{name}.npy AND test_{name}.npy exist for at least 2 models.",
        "  9. This enables the Ensemble Agent to use Stacking/Blending later.",
        "  10. **MANDATORY VERIFICATION BLOCK (DO NOT REMOVE - ADD AT END OF SCRIPT)**:",
        "     ```python",
        "     # === VERIFICATION (CRITICAL - PREVENTS SILENT FAILURES) ===",
        "     from pathlib import Path",
        "     import numpy as np",
        "     ",
        f"     oof_path = Path('{working_dir}') / 'models' / 'oof_{component_name}.npy'",
        f"     test_path = Path('{working_dir}') / 'models' / 'test_{component_name}.npy'",
        f"     class_order_path = Path('{working_dir}') / 'models' / 'class_order_{component_name}.npy'",
        "     ",
        "     # 1. Check files exist",
        "     assert oof_path.exists(), f'CRITICAL ERROR: OOF file not saved at {oof_path}'",
        "     assert test_path.exists(), f'CRITICAL ERROR: Test file not saved at {test_path}'",
        "     print(f'[VERIFY] OOF file: {oof_path.name} exists')",
        "     print(f'[VERIFY] Test file: {test_path.name} exists')",
        "     ",
        "     # 2. Load and validate shapes",
        "     oof = np.load(oof_path)",
        "     test = np.load(test_path)",
        "     print(f'[VERIFY] OOF shape: {oof.shape}, Test shape: {test.shape}')",
        "     ",
        "     # 3. Validate probability range (classification)",
        "     if oof.min() < 0 or oof.max() > 1:",
        "         print(f'[VERIFY] WARNING: OOF has values outside [0,1]: min={oof.min():.4f}, max={oof.max():.4f}')",
        "     if test.min() < 0 or test.max() > 1:",
        "         print(f'[VERIFY] WARNING: Test has values outside [0,1]: min={test.min():.4f}, max={test.max():.4f}')",
        "     ",
        "     # 4. Check for empty rows (unfilled OOF = CRITICAL BUG)",
        "     if oof.ndim > 1:",
        "         empty_oof = (oof.sum(axis=1) == 0).sum()",
        "     else:",
        "         empty_oof = (np.abs(oof) < 1e-10).sum()",
        "     if empty_oof > 0:",
        "         print(f'[VERIFY] CRITICAL WARNING: {empty_oof} OOF rows are empty/zero (unfilled predictions!)')",
        "     ",
        "     # 5. Check for NaN/Inf",
        "     if np.any(~np.isfinite(oof)):",
        "         print('[VERIFY] CRITICAL WARNING: OOF contains NaN or Inf values!')",
        "     if np.any(~np.isfinite(test)):",
        "         print('[VERIFY] CRITICAL WARNING: Test contains NaN or Inf values!')",
        "     ",
        "     # 6. Verify class order (multiclass)",
        "     if class_order_path.exists():",
        "         class_order = np.load(class_order_path, allow_pickle=True).tolist()",
        "         print(f'[VERIFY] Class order: {class_order[:3]}... ({len(class_order)} classes)')",
        "     else:",
        "         print('[VERIFY] WARNING: class_order file not found - ensemble alignment may fail')",
        "     ",
        "     print('[VERIFY] All artifact checks completed')",
        "     # === END VERIFICATION ===",
        "     ```",
    ]
    instructions.extend(build_oof_hygiene_instructions(working_dir, component_name))
    return instructions


def build_multi_seed_instructions(working_dir: str, component_name: str) -> list[str]:
    """Build multi-seed training instructions for ensemble diversity."""
    return [
        "\nðŸŽ² MULTI-SEED TRAINING (ENSEMBLE DIVERSITY):",
        "  - Train the SAME model architecture with DIFFERENT random seeds",
        "  - KEEP folds.csv FIXED - only change model's random_state",
        "  - VALIDATE complete OOF before including in average",
        "    ```python",
        "    seeds = [42, 1337, 2024, 7, 123]",
        "    folds = pd.read_csv('folds.csv')  # SAME folds for all seeds",
        "    valid_oof, valid_test = [], []",
        "",
        "    for seed in seeds:",
        "        try:",
        "            model = LGBMClassifier(random_state=seed, ...)  # Only change seed",
        "            oof, test = train_cv(model, folds)  # SAME folds",
        "",
        "            # VALIDATE: OOF must have all rows filled",
        "            if oof.ndim > 1:",
        "                oof_sum = oof.sum(axis=1)",
        "            else:",
        "                oof_sum = np.abs(oof)",
        "            n_empty = (oof_sum == 0).sum()",
        "",
        "            if n_empty > 0:",
        "                print(f'   âš ï¸ Seed {seed}: {n_empty} empty rows, discarding')",
        "                continue",
        "",
        "            valid_oof.append(oof)",
        "            valid_test.append(test)",
        "            print(f'   âœ… Seed {seed}: complete OOF, included in average')",
        "        except Exception as e:",
        "            print(f'   âš ï¸ Seed {seed} failed: {e}')",
        "            continue",
        "",
        "    if len(valid_oof) == 0:",
        "        raise ValueError('No seed produced valid OOF')",
        "",
        "    # Average only valid seeds",
        "    final_oof = np.mean(valid_oof, axis=0)",
        "    final_test = np.mean(valid_test, axis=0)",
        f"    np.save('models/oof_{component_name}.npy', final_oof)",
        f"    np.save('models/test_{component_name}.npy', final_test)",
        "    print(f'   Multi-seed: average of {len(valid_oof)}/{len(seeds)} seeds')",
        "    ```",
        "  - DO NOT create separate folds.csv per seed (complexity + misalignment risk)",
    ]


def build_oof_hygiene_instructions(working_dir: str, component_name: str) -> list[str]:
    """Build OOF hygiene instructions for robust stacking."""
    return [
        "\nOOF HYGIENE (STACKING SAFETY):",
        "  - Validate OOF arrays BEFORE saving: no NaN/inf, correct shapes, no empty rows.",
        "  - Save fold assignments used for each row (enables leakage checks):",
        "    ```python",
        "    # folds.csv must align with train rows",
        "    folds = pd.read_csv('folds.csv')",
        "    fold_assignment = folds['fold'].values",
        f"    np.save(str(Path('{working_dir}') / 'models' / 'fold_assignment_{component_name}.npy'), fold_assignment)",
        "    ```",
        "  - Ensure train row order is consistent: use the same index/order for X, y, and OOF.",
        "  - If you drop rows, reset index for train and folds so alignment stays exact.",
    ]


def build_calibration_instructions() -> list[str]:
    """Build probability calibration instructions."""
    return [
        "\nPROBABILITY CALIBRATION (RECOMMENDED BEFORE ENSEMBLE):",
        "  - Calibrate OOF probabilities per model before blending.",
        "  - Prefer Platt scaling (logistic) as default; use isotonic if reliability curves are concave.",
        "  - Save both raw and calibrated OOF: oof_raw_{name}.npy and oof_cal_{name}.npy.",
        "  - Choose calibrated only if Brier/log_loss improves; otherwise keep raw.",
    ]
