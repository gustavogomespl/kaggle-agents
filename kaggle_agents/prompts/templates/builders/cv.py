"""
Cross-validation and OOF (Out-of-Fold) instruction builders.
"""


def build_cv_instructions(working_dir: str, component_name: str) -> list[str]:
    """Build cross-validation instructions."""
    return [
        "\nüîÑ CONSISTENT CROSS-VALIDATION (CRITICAL):",
        f"  - Check if '{working_dir}/folds.csv' exists.",
        "  - IF EXISTS: Load it and use the 'fold' column for splitting.",
        "    ```python",
        "    folds = pd.read_csv('folds.csv')",
        "    # Assuming X is aligned with folds (reset_index if needed)",
        "    for fold in sorted(folds['fold'].unique()):",
        "        val_idx = folds[folds['fold'] == fold].index",
        "        train_idx = folds[folds['fold'] != fold].index",
        "        # ... train/val split ...",
        "    ```",
        "  - IF NOT EXISTS: Use StratifiedKFold(n_splits=int(os.getenv('KAGGLE_AGENTS_CV_FOLDS','5')), shuffle=True, random_state=42)",
        "  - CRITICAL: Fit preprocessing/scalers INSIDE each CV fold (fit on X_train, transform X_val/X_test)",
        f"  - CRITICAL: MUST save Out-of-Fold (OOF) predictions during CV to models/oof_{component_name}.npy",
        "  - OOF predictions enable proper stacking ensemble (meta-model trained on OOF)",
        "  - MUST print 'Final Validation Performance: {score}'",
        "  - If metric is NaN/inf, replace with 0.0 before printing Final Validation Performance",
        "  - Multiclass log_loss: after clipping, renormalize rows to sum to 1",
        "  - If OOF rows are empty due to early stop, compute log_loss on rows with sum>0",
        "  - MUST handle class imbalance with class_weight='balanced'",
    ]


def build_stacking_oof_instructions(working_dir: str, component_name: str) -> list[str]:
    """Build stacking/OOF instructions."""
    return [
        "\nSTACKING & OOF REQUIREMENTS (CRITICAL):",
        "  1. Initialize `oof_preds` array of zeros with shape (n_train, n_classes) for multi-class.",
        "  2. Initialize `test_preds` array of zeros with shape (n_test, n_classes) for multi-class.",
        "  3. **CLASS ORDER ALIGNMENT (CRITICAL FOR ENSEMBLE - PREVENTS DEGRADATION)**:",
        "     - Read sample_submission.csv to get canonical class order:",
        "       ```python",
        "       sample_sub = pd.read_csv(sample_submission_path)",
        "       class_order = sample_sub.columns[1:].tolist()  # Canonical order from submission",
        "       ```",
        "     - After fitting LabelEncoder, compute reordering indices:",
        "       ```python",
        "       le_classes = le.classes_.tolist()  # Model's LabelEncoder order",
        "       reorder_idx = [le_classes.index(c) for c in class_order]  # Map to submission order",
        "       ```",
        "     - BEFORE saving, reorder predictions to match sample_submission:",
        "       ```python",
        "       oof_preds_aligned = oof_preds[:, reorder_idx]",
        "       test_preds_aligned = test_preds[:, reorder_idx]",
        "       ```",
        "     - Save canonical class order for validation:",
        f"       `np.save(str(Path('{working_dir}') / 'models' / 'class_order.npy'), class_order)`",
        "  4. During CV loop:",
        "     - Fill `oof_preds[val_idx]` with predictions for validation fold.",
        "     - Predict on test set and accumulate:",
        "       - Binary: `test_preds += model.predict_proba(X_test)[:, 1] / n_folds`",
        "       - Multi-class: `test_preds += model.predict_proba(X_test) / n_folds`",
        "       - Regression: `test_preds += model.predict(X_test) / n_folds`",
        f"  5. Save OOF predictions (AFTER reordering): `np.save(str(Path('{working_dir}') / 'models' / 'oof_{component_name}.npy'), oof_preds_aligned)`",
        f"  6. Save Test predictions (AFTER reordering): `np.save(str(Path('{working_dir}') / 'models' / 'test_{component_name}.npy'), test_preds_aligned)`",
        "  7. **SAVE ALIGNMENT METADATA (CRITICAL FOR ENSEMBLE VALIDATION)**:",
        "     - Save train IDs (row order) for alignment validation:",
        "       ```python",
        "       train_ids = train_df['id'].values if 'id' in train_df.columns else train_df.index.values",
        f"       np.save(str(Path('{working_dir}') / 'models' / 'train_ids_{component_name}.npy'), train_ids)",
        "       ```",
        "     - Save class order per model (enables per-model validation):",
        f"       `np.save(str(Path('{working_dir}') / 'models' / 'class_order_{component_name}.npy'), class_order)`",
        "     - Ensemble will use these files to validate compatibility before combining models.",
        "  8. Ensemble will ONLY run if BOTH oof_{name}.npy AND test_{name}.npy exist for at least 2 models.",
        "  9. This enables the Ensemble Agent to use Stacking/Blending later.",
    ]


def build_multi_seed_instructions(working_dir: str, component_name: str) -> list[str]:
    """Build multi-seed training instructions for ensemble diversity."""
    return [
        "\nüé≤ MULTI-SEED TRAINING (ENSEMBLE DIVERSITY):",
        "  - Train the SAME model architecture with DIFFERENT random seeds",
        "  - KEEP folds.csv FIXED - only change model's random_state",
        "  - VALIDATE complete OOF before including in average",
        "    ```python",
        "    seeds = [42, 1337, 2024, 7, 123]",
        "    folds = pd.read_csv('folds.csv')  # SAME folds for all seeds",
        "    valid_oof, valid_test = [], []",
        "",
        "    for seed in seeds:",
        "        try:",
        "            model = LGBMClassifier(random_state=seed, ...)  # Only change seed",
        "            oof, test = train_cv(model, folds)  # SAME folds",
        "",
        "            # VALIDATE: OOF must have all rows filled",
        "            if oof.ndim > 1:",
        "                oof_sum = oof.sum(axis=1)",
        "            else:",
        "                oof_sum = np.abs(oof)",
        "            n_empty = (oof_sum == 0).sum()",
        "",
        "            if n_empty > 0:",
        "                print(f'   ‚ö†Ô∏è Seed {seed}: {n_empty} empty rows, discarding')",
        "                continue",
        "",
        "            valid_oof.append(oof)",
        "            valid_test.append(test)",
        "            print(f'   ‚úÖ Seed {seed}: complete OOF, included in average')",
        "        except Exception as e:",
        "            print(f'   ‚ö†Ô∏è Seed {seed} failed: {e}')",
        "            continue",
        "",
        "    if len(valid_oof) == 0:",
        "        raise ValueError('No seed produced valid OOF')",
        "",
        "    # Average only valid seeds",
        "    final_oof = np.mean(valid_oof, axis=0)",
        "    final_test = np.mean(valid_test, axis=0)",
        f"    np.save('models/oof_{component_name}.npy', final_oof)",
        f"    np.save('models/test_{component_name}.npy', final_test)",
        "    print(f'   Multi-seed: average of {len(valid_oof)}/{len(seeds)} seeds')",
        "    ```",
        "  - DO NOT create separate folds.csv per seed (complexity + misalignment risk)",
    ]
