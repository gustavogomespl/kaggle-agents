"""
Feature engineering instruction builder.

Updated to prevent data corruption issues:
- Preserves all original features
- Validates row counts and ID uniqueness
- Ensures target column is preserved
"""


def build_feature_engineering_instructions() -> list[str]:
    """Build feature engineering instructions with data integrity checks."""
    return [
        "\n## FEATURE ENGINEERING REQUIREMENTS (CRITICAL):",
        "",
        "### DATA INTEGRITY CHECKS (MANDATORY - DO THESE FIRST):",
        "  - The 'id' column MUST remain exactly as in the original CSV",
        "  - DO NOT cast id to different type (int -> str or vice versa)",
        "  - DO NOT reindex the DataFrame",
        "  - DO NOT drop or modify id values",
        "  - PRESERVE the target column in train data",
        "",
        "### CORRECT PATTERN FOR FEATURE ENGINEERING:",
        "  ```python",
        "  import pandas as pd",
        "  ",
        "  # Load original data",
        "  train_orig = pd.read_csv('train.csv')",
        "  test_orig = pd.read_csv('test.csv')",
        "  ",
        "  # Backup original IDs for validation",
        "  original_train_ids = train_orig['id'].copy()",
        "  original_test_ids = test_orig['id'].copy()",
        "  original_train_len = len(train_orig)",
        "  original_test_len = len(test_orig)",
        "  ",
        "  # Create copies to work with (PRESERVES all original columns)",
        "  train_df = train_orig.copy()",
        "  test_df = test_orig.copy()",
        "  ",
        "  # Add NEW engineered features (don't replace existing ones!)",
        "  train_df['new_feature'] = ...",
        "  test_df['new_feature'] = ...",
        "  ",
        "  # VALIDATE BEFORE SAVING (MANDATORY):",
        "  assert len(train_df) == original_train_len, \\",
        "      f'CRITICAL: Row count changed! {len(train_df)} vs {original_train_len}'",
        "  assert len(test_df) == original_test_len, \\",
        "      f'CRITICAL: Row count changed! {len(test_df)} vs {original_test_len}'",
        "  assert train_df['id'].is_unique, 'CRITICAL: Duplicate IDs in train!'",
        "  assert test_df['id'].is_unique, 'CRITICAL: Duplicate IDs in test!'",
        "  assert train_df['id'].equals(original_train_ids), 'CRITICAL: ID column was modified!'",
        "  assert test_df['id'].equals(original_test_ids), 'CRITICAL: ID column was modified!'",
        "  ",
        "  # Save (with ALL original columns + new features)",
        "  train_df.to_csv('train_engineered.csv', index=False)",
        "  test_df.to_csv('test_engineered.csv', index=False)",
        "  print(f'Saved {len(train_df)} train rows, {len(test_df)} test rows')",
        "  print(f'Train columns: {len(train_df.columns)}, Test columns: {len(test_df.columns)}')",
        "  ```",
        "",
        "### ANTI-PATTERNS (CRITICAL - THESE CAUSE COMPETITION FAILURE):",
        "  - DO NOT use pd.concat() in ways that duplicate rows",
        "  - DO NOT drop original feature columns (add new ones instead)",
        "  - DO NOT drop the target column from train data",
        "  - DO NOT save only the engineered features (save ALL columns)",
        "  - DO NOT use drop_duplicates() - THIS DESTROYS VALID DATA",
        "  - DO NOT use .sample() or .head() to reduce dataset size - USE ALL DATA",
        "  - DO NOT append data instead of assigning (train_df = pd.concat([train_df, new_data]))",
        "  - FOR LARGE DATASETS (>1M rows): Use chunked processing if memory is an issue, NEVER sampling",
        "",
        "### FEATURE ENGINEERING TECHNIQUES (OPTIONAL):",
        "  - Target Encoding: MUST be done inside CV (fit on train folds, transform val)",
        "  - Frequency Encoding: Map categorical features to their frequency/count",
        "  - Aggregations: Mean/Count of numeric features grouped by categorical",
        "  - Polynomial features: Interactions between top numeric features",
        "",
        "### FEATURE SELECTION (OPTIONAL - ONLY IF NEEDED):",
        "  If you want to remove low-importance features:",
        "  1. Train a quick LightGBM on the feature set",
        "  2. Calculate feature importance",
        "  3. DROP only the new features with importance < 1e-4",
        "  4. KEEP all original features from train.csv",
        "  5. Print list of dropped features",
        "",
        "### OUTPUT REQUIREMENTS:",
        "  - Save to 'train_engineered.csv' and 'test_engineered.csv'",
        "  - NO model training in this component",
        "  - Print 'Final Validation Performance: 1.0' on successful completion",
    ]
