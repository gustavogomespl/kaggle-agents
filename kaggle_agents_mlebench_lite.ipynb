{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uixg0BSqYTku"
      },
      "source": [
        "# üéì Kaggle Agents + MLE-bench Lite\n",
        "\n",
        "**Notebook para TCC**: Avalia√ß√£o de Agentes Aut√¥nomos em 22 Competi√ß√µes do MLE-bench Lite\n",
        "\n",
        "Este notebook:\n",
        "1. Usa os dados do MLE-bench (split valid√°vel)\n",
        "2. Executa o workflow do kaggle-agents\n",
        "3. Valida as submiss√µes com `mlebench grade-sample`\n",
        "4. Gera relat√≥rio consolidado"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FmNaWh__YTkv"
      },
      "source": [
        "## 1. Environment Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rBnKLlxVYTkw",
        "outputId": "944cc9d5-9c2a-4865-88d4-32d96c84189d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Dec  7 19:12:40 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   43C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "# Check GPU\n",
        "!nvidia-smi || echo \"No GPU available (CPU mode)\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oDXQ1_ZwYTkx",
        "outputId": "67c3d78a-5d1d-478f-8538-06de2ae00392"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'kaggle-agents'...\n",
            "remote: Enumerating objects: 1358, done.\u001b[K\n",
            "remote: Counting objects: 100% (453/453), done.\u001b[K\n",
            "remote: Compressing objects: 100% (292/292), done.\u001b[K\n",
            "remote: Total 1358 (delta 284), reused 306 (delta 158), pack-reused 905 (from 1)\u001b[K\n",
            "Receiving objects: 100% (1358/1358), 674.86 KiB | 25.96 MiB/s, done.\n",
            "Resolving deltas: 100% (871/871), done.\n",
            "Cloning into 'mle-bench'...\n",
            "remote: Enumerating objects: 1393, done.\u001b[K\n",
            "remote: Counting objects: 100% (248/248), done.\u001b[K\n",
            "remote: Compressing objects: 100% (150/150), done.\u001b[K\n",
            "remote: Total 1393 (delta 151), reused 112 (delta 97), pack-reused 1145 (from 1)\u001b[K\n",
            "Receiving objects: 100% (1393/1393), 772.63 KiB | 19.32 MiB/s, done.\n",
            "Resolving deltas: 100% (348/348), done.\n",
            "Filtering content: 100% (286/286), 36.36 MiB | 2.41 MiB/s, done.\n",
            "/content/kaggle-agents\n"
          ]
        }
      ],
      "source": [
        "# Clone repositories\n",
        "!git clone https://github.com/gustavogomespl/kaggle-agents.git\n",
        "!git clone https://github.com/openai/mle-bench.git\n",
        "\n",
        "%cd kaggle-agents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5loiawA_YTkx",
        "outputId": "b2d78a46-9b93-48c1-f39e-c952a6e4e1b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m22.0/22.0 MB\u001b[0m \u001b[31m68.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[2mUsing Python 3.12.12 environment at: /usr\u001b[0m\n",
            "\u001b[2K\u001b[2mResolved \u001b[1m215 packages\u001b[0m \u001b[2min 1.65s\u001b[0m\u001b[0m\n",
            "\u001b[2K\u001b[2mPrepared \u001b[1m52 packages\u001b[0m \u001b[2min 2.27s\u001b[0m\u001b[0m\n",
            "\u001b[2mUninstalled \u001b[1m5 packages\u001b[0m \u001b[2min 31ms\u001b[0m\u001b[0m\n",
            "\u001b[2K\u001b[2mInstalled \u001b[1m52 packages\u001b[0m \u001b[2min 68ms\u001b[0m\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1manthropic\u001b[0m\u001b[2m==0.75.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1masyncer\u001b[0m\u001b[2m==0.0.8\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mbackoff\u001b[0m\u001b[2m==2.2.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mbcrypt\u001b[0m\u001b[2m==5.0.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mbuild\u001b[0m\u001b[2m==1.3.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mcatboost\u001b[0m\u001b[2m==1.2.8\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mcategory-encoders\u001b[0m\u001b[2m==2.9.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mchromadb\u001b[0m\u001b[2m==1.3.5\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mcoloredlogs\u001b[0m\u001b[2m==15.0.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mcolorlog\u001b[0m\u001b[2m==6.10.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mdataclasses-json\u001b[0m\u001b[2m==0.6.7\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mdiskcache\u001b[0m\u001b[2m==5.6.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mdspy\u001b[0m\u001b[2m==3.0.4\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mdspy-ai\u001b[0m\u001b[2m==3.0.4\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mdurationpy\u001b[0m\u001b[2m==0.10\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mfastuuid\u001b[0m\u001b[2m==0.14.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mfeature-engine\u001b[0m\u001b[2m==1.9.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mfiletype\u001b[0m\u001b[2m==1.2.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mgepa\u001b[0m\u001b[2m==0.0.17\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mgoogle-ai-generativelanguage\u001b[0m\u001b[2m==0.6.15\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mgoogle-ai-generativelanguage\u001b[0m\u001b[2m==0.9.0\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mgrpcio\u001b[0m\u001b[2m==1.76.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mgrpcio\u001b[0m\u001b[2m==1.67.1\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mgrpcio-status\u001b[0m\u001b[2m==1.71.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mgrpcio-status\u001b[0m\u001b[2m==1.67.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mhttptools\u001b[0m\u001b[2m==0.7.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mhumanfriendly\u001b[0m\u001b[2m==10.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mjson-repair\u001b[0m\u001b[2m==0.54.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mkaggle-agents\u001b[0m\u001b[2m==0.1.0 (from file:///content/kaggle-agents)\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mkubernetes\u001b[0m\u001b[2m==34.1.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mlangchain-anthropic\u001b[0m\u001b[2m==1.2.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mlangchain-classic\u001b[0m\u001b[2m==1.0.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mlangchain-community\u001b[0m\u001b[2m==0.4.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mlangchain-google-genai\u001b[0m\u001b[2m==3.2.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mlangchain-openai\u001b[0m\u001b[2m==1.1.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mlangchain-text-splitters\u001b[0m\u001b[2m==1.0.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mlitellm\u001b[0m\u001b[2m==1.80.8\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mmagicattr\u001b[0m\u001b[2m==0.1.6\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mmarshmallow\u001b[0m\u001b[2m==3.26.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mmmh3\u001b[0m\u001b[2m==5.2.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mmypy-extensions\u001b[0m\u001b[2m==1.1.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1monnxruntime\u001b[0m\u001b[2m==1.23.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mopentelemetry-exporter-otlp-proto-grpc\u001b[0m\u001b[2m==1.37.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1moptuna\u001b[0m\u001b[2m==4.6.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1moptuna-integration\u001b[0m\u001b[2m==4.6.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mposthog\u001b[0m\u001b[2m==5.4.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpybase64\u001b[0m\u001b[2m==1.4.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpypika\u001b[0m\u001b[2m==0.48.9\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpyproject-hooks\u001b[0m\u001b[2m==1.2.0\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mrequests\u001b[0m\u001b[2m==2.32.4\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mrequests\u001b[0m\u001b[2m==2.32.5\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtextgrad\u001b[0m\u001b[2m==0.1.8\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtyping-inspect\u001b[0m\u001b[2m==0.9.0\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1murllib3\u001b[0m\u001b[2m==2.5.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1murllib3\u001b[0m\u001b[2m==2.3.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1muvloop\u001b[0m\u001b[2m==0.22.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mwatchfiles\u001b[0m\u001b[2m==1.1.1\u001b[0m\n",
            "\u001b[2mUsing Python 3.12.12 environment at: /usr\u001b[0m\n",
            "\u001b[2mAudited \u001b[1m7 packages\u001b[0m \u001b[2min 102ms\u001b[0m\u001b[0m\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m82.7/82.7 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m75.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m621.4/621.4 kB\u001b[0m \u001b[31m52.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m153.3/153.3 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m69.7/69.7 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m64.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m331.1/331.1 kB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m100.6/100.6 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m88.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m51.5/51.5 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m142.7/142.7 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m115.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m85.4/85.4 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m494.4/494.4 kB\u001b[0m \u001b[31m37.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building editable for mlebench (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for kaggle (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires ipython==7.34.0, but you have ipython 9.8.0 which is incompatible.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m‚úì Installation complete!\n"
          ]
        }
      ],
      "source": [
        "# Install dependencies\n",
        "!pip install -q uv\n",
        "!uv pip install --system -e .\n",
        "!uv pip install --system langgraph langchain-openai pandas numpy scikit-learn matplotlib seaborn\n",
        "\n",
        "# Install MLE-bench\n",
        "!pip install -q -e ../mle-bench\n",
        "\n",
        "print(\"‚úì Installation complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jSr08P-VYTky"
      },
      "source": [
        "## 2. Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7wwcWBSDYTky",
        "outputId": "0dd7d7b9-b323-4e7d-ea0b-441b8f1565a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úì Loaded secrets from Colab\n",
            "‚úì Configuration saved\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# ============================================================\n",
        "# CONFIGURA√á√ÉO PRINCIPAL - EDITE AQUI\n",
        "# ============================================================\n",
        "\n",
        "# LLM Provider global\n",
        "LLM_PROVIDER = \"openai\"\n",
        "LLM_MODEL = \"gpt-5.1-codex-mini\"\n",
        "LLM_TEMPERATURE = 1\n",
        "LLM_MAX_TOKENS = 16000\n",
        "\n",
        "# Overrides por papel\n",
        "PLANNER_PROVIDER = \"openai\"\n",
        "PLANNER_MODEL = \"gpt-5-mini\"\n",
        "DEVELOPER_PROVIDER = \"openai\"\n",
        "DEVELOPER_MODEL = \"gpt-5.1-codex-mini\"\n",
        "EVALUATOR_PROVIDER = \"openai\"\n",
        "EVALUATOR_MODEL = \"gpt-5-mini\"\n",
        "\n",
        "# Workflow Settings\n",
        "MAX_ITERATIONS = 3\n",
        "TARGET_PERCENTILE = 20.0\n",
        "\n",
        "# Colab Secrets\n",
        "try:\n",
        "    from google.colab import userdata\n",
        "    OPENAI_API_KEY = userdata.get('OPENAI_API_KEY') or \"\"\n",
        "    ANTHROPIC_API_KEY = userdata.get('ANTHROPIC_API_KEY') or \"\"\n",
        "    KAGGLE_USERNAME = userdata.get('KAGGLE_USERNAME') or \"\"\n",
        "    KAGGLE_KEY = userdata.get('KAGGLE_KEY') or \"\"\n",
        "    print(\"‚úì Loaded secrets from Colab\")\n",
        "except Exception:\n",
        "    from getpass import getpass\n",
        "    print(\"‚ö†Ô∏è Colab secrets not found. Using manual input.\")\n",
        "    OPENAI_API_KEY = getpass(\"OpenAI API Key: \")\n",
        "    ANTHROPIC_API_KEY = getpass(\"Anthropic API Key (optional): \") or \"\"\n",
        "    KAGGLE_USERNAME = input(\"Kaggle Username: \")\n",
        "    KAGGLE_KEY = getpass(\"Kaggle Key: \")\n",
        "\n",
        "# Save .env\n",
        "env_content = f\"\"\"# Kaggle Agents + MLE-bench Configuration\n",
        "LLM_PROVIDER={LLM_PROVIDER}\n",
        "LLM_MODEL={LLM_MODEL}\n",
        "LLM_TEMPERATURE={LLM_TEMPERATURE}\n",
        "LLM_MAX_TOKENS={LLM_MAX_TOKENS}\n",
        "PLANNER_PROVIDER={PLANNER_PROVIDER}\n",
        "PLANNER_MODEL={PLANNER_MODEL}\n",
        "DEVELOPER_PROVIDER={DEVELOPER_PROVIDER}\n",
        "DEVELOPER_MODEL={DEVELOPER_MODEL}\n",
        "EVALUATOR_PROVIDER={EVALUATOR_PROVIDER}\n",
        "EVALUATOR_MODEL={EVALUATOR_MODEL}\n",
        "OPENAI_API_KEY={OPENAI_API_KEY}\n",
        "ANTHROPIC_API_KEY={ANTHROPIC_API_KEY}\n",
        "KAGGLE_USERNAME={KAGGLE_USERNAME}\n",
        "KAGGLE_KEY={KAGGLE_KEY}\n",
        "KAGGLE_AUTO_SUBMIT=false\n",
        "MAX_ITERATIONS={MAX_ITERATIONS}\n",
        "TARGET_PERCENTILE={TARGET_PERCENTILE}\n",
        "LOG_LEVEL=INFO\n",
        "LOG_DIR=./logs\n",
        "\"\"\"\n",
        "\n",
        "with open('.env', 'w') as f:\n",
        "    f.write(env_content)\n",
        "\n",
        "# Setup Kaggle credentials\n",
        "kaggle_dir = Path.home() / '.kaggle'\n",
        "kaggle_dir.mkdir(exist_ok=True)\n",
        "(kaggle_dir / 'kaggle.json').write_text(f'{{\"username\":\"{KAGGLE_USERNAME}\",\"key\":\"{KAGGLE_KEY}\"}}')\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "print(\"‚úì Configuration saved\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-9srn381YTkz",
        "outputId": "4b6b40a9-19d3-47b2-f817-7dbdd66cdf49"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úì LangSmith Tracing Enabled (Project: default)\n"
          ]
        }
      ],
      "source": [
        "# LangSmith Tracing (opcional)\n",
        "try:\n",
        "    from google.colab import userdata\n",
        "    langchain_api_key = userdata.get('LANGSMITH')\n",
        "    langsmith_project = userdata.get('LANGSMITH_PROJECT') or \"kaggle-agents-mlebench\"\n",
        "\n",
        "    if langchain_api_key:\n",
        "        os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "        os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
        "        os.environ[\"LANGCHAIN_API_KEY\"] = langchain_api_key\n",
        "        os.environ[\"LANGCHAIN_PROJECT\"] = langsmith_project\n",
        "        print(f\"‚úì LangSmith Tracing Enabled (Project: {langsmith_project})\")\n",
        "    else:\n",
        "        print(\"‚ÑπÔ∏è LangSmith Tracing Disabled\")\n",
        "except:\n",
        "    print(\"‚ÑπÔ∏è LangSmith Tracing Disabled\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2QAEp1JwYTkz"
      },
      "source": [
        "## 3. MLE-bench Lite Competitions\n",
        "\n",
        "22 competi√ß√µes do benchmark lite (~158GB total)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 809
        },
        "id": "iIEwnKzQYTkz",
        "outputId": "782ce47c-71e1-413f-c710-6a777a5620e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total: 22 competi√ß√µes\n",
            "Tamanho total: 157.73 GB\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                                 id              category  \\\n",
              "0                      aerial-cactus-identification  Image Classification   \n",
              "1                     aptos2019-blindness-detection  Image Classification   \n",
              "2                          dog-breed-identification  Image Classification   \n",
              "3                dogs-vs-cats-redux-kernels-edition  Image Classification   \n",
              "4                               leaf-classification  Image Classification   \n",
              "5                        plant-pathology-2020-fgvc7  Image Classification   \n",
              "6          ranzcr-clip-catheter-line-classification  Image Classification   \n",
              "7                 siim-isic-melanoma-classification  Image Classification   \n",
              "8                         denoising-dirty-documents        Image To Image   \n",
              "9                  histopathologic-cancer-detection      Image Regression   \n",
              "10           detecting-insults-in-social-commentary   Text Classification   \n",
              "11    jigsaw-toxic-comment-classification-challenge   Text Classification   \n",
              "12                             random-acts-of-pizza   Text Classification   \n",
              "13                     spooky-author-identification   Text Classification   \n",
              "14               new-york-city-taxi-fare-prediction               Tabular   \n",
              "15         nomad2018-predict-transparent-conductors               Tabular   \n",
              "16               tabular-playground-series-dec-2021               Tabular   \n",
              "17               tabular-playground-series-may-2022               Tabular   \n",
              "18                                  mlsp-2013-birds  Audio Classification   \n",
              "19  the-icml-2013-whale-challenge-right-whale-redux  Audio Classification   \n",
              "20    text-normalization-challenge-english-language              Seq->Seq   \n",
              "21    text-normalization-challenge-russian-language              Seq->Seq   \n",
              "\n",
              "      size_gb  \n",
              "0     0.02540  \n",
              "1    10.22000  \n",
              "2     0.75000  \n",
              "3     0.85000  \n",
              "4     0.03600  \n",
              "5     0.80000  \n",
              "6    13.13000  \n",
              "7   116.16000  \n",
              "8     0.06000  \n",
              "9     7.76000  \n",
              "10    0.00200  \n",
              "11    0.06000  \n",
              "12    0.00300  \n",
              "13    0.00190  \n",
              "14    5.70000  \n",
              "15    0.00624  \n",
              "16    0.70000  \n",
              "17    0.57000  \n",
              "18    0.58510  \n",
              "19    0.29314  \n",
              "20    0.01000  \n",
              "21    0.01000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5235e88b-83c8-45a3-b3c8-8f99269a4375\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>category</th>\n",
              "      <th>size_gb</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>aerial-cactus-identification</td>\n",
              "      <td>Image Classification</td>\n",
              "      <td>0.02540</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>aptos2019-blindness-detection</td>\n",
              "      <td>Image Classification</td>\n",
              "      <td>10.22000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>dog-breed-identification</td>\n",
              "      <td>Image Classification</td>\n",
              "      <td>0.75000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>dogs-vs-cats-redux-kernels-edition</td>\n",
              "      <td>Image Classification</td>\n",
              "      <td>0.85000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>leaf-classification</td>\n",
              "      <td>Image Classification</td>\n",
              "      <td>0.03600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>plant-pathology-2020-fgvc7</td>\n",
              "      <td>Image Classification</td>\n",
              "      <td>0.80000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>ranzcr-clip-catheter-line-classification</td>\n",
              "      <td>Image Classification</td>\n",
              "      <td>13.13000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>siim-isic-melanoma-classification</td>\n",
              "      <td>Image Classification</td>\n",
              "      <td>116.16000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>denoising-dirty-documents</td>\n",
              "      <td>Image To Image</td>\n",
              "      <td>0.06000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>histopathologic-cancer-detection</td>\n",
              "      <td>Image Regression</td>\n",
              "      <td>7.76000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>detecting-insults-in-social-commentary</td>\n",
              "      <td>Text Classification</td>\n",
              "      <td>0.00200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>jigsaw-toxic-comment-classification-challenge</td>\n",
              "      <td>Text Classification</td>\n",
              "      <td>0.06000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>random-acts-of-pizza</td>\n",
              "      <td>Text Classification</td>\n",
              "      <td>0.00300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>spooky-author-identification</td>\n",
              "      <td>Text Classification</td>\n",
              "      <td>0.00190</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>new-york-city-taxi-fare-prediction</td>\n",
              "      <td>Tabular</td>\n",
              "      <td>5.70000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>nomad2018-predict-transparent-conductors</td>\n",
              "      <td>Tabular</td>\n",
              "      <td>0.00624</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>tabular-playground-series-dec-2021</td>\n",
              "      <td>Tabular</td>\n",
              "      <td>0.70000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>tabular-playground-series-may-2022</td>\n",
              "      <td>Tabular</td>\n",
              "      <td>0.57000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>mlsp-2013-birds</td>\n",
              "      <td>Audio Classification</td>\n",
              "      <td>0.58510</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>the-icml-2013-whale-challenge-right-whale-redux</td>\n",
              "      <td>Audio Classification</td>\n",
              "      <td>0.29314</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>text-normalization-challenge-english-language</td>\n",
              "      <td>Seq-&gt;Seq</td>\n",
              "      <td>0.01000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>text-normalization-challenge-russian-language</td>\n",
              "      <td>Seq-&gt;Seq</td>\n",
              "      <td>0.01000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5235e88b-83c8-45a3-b3c8-8f99269a4375')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5235e88b-83c8-45a3-b3c8-8f99269a4375 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5235e88b-83c8-45a3-b3c8-8f99269a4375');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-b2f8ed53-527f-4f0d-8fef-081e890ea8a0\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b2f8ed53-527f-4f0d-8fef-081e890ea8a0')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-b2f8ed53-527f-4f0d-8fef-081e890ea8a0 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_f0d0670e-ceed-4ba2-b324-370fa159ce7c\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_competitions')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_f0d0670e-ceed-4ba2-b324-370fa159ce7c button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_competitions');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_competitions",
              "summary": "{\n  \"name\": \"df_competitions\",\n  \"rows\": 22,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 22,\n        \"samples\": [\n          \"aerial-cactus-identification\",\n          \"spooky-author-identification\",\n          \"denoising-dirty-documents\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"category\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"Image Classification\",\n          \"Image To Image\",\n          \"Audio Classification\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"size_gb\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 24.625754812901263,\n        \"min\": 0.0019,\n        \"max\": 116.16,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          0.0254,\n          0.5851,\n          0.7\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Lista completa das 22 competi√ß√µes do MLE-bench Lite\n",
        "MLEBENCH_LITE_COMPETITIONS = [\n",
        "    # Image Classification\n",
        "    {\"id\": \"aerial-cactus-identification\", \"category\": \"Image Classification\", \"size_gb\": 0.0254},\n",
        "    {\"id\": \"aptos2019-blindness-detection\", \"category\": \"Image Classification\", \"size_gb\": 10.22},\n",
        "    {\"id\": \"dog-breed-identification\", \"category\": \"Image Classification\", \"size_gb\": 0.75},\n",
        "    {\"id\": \"dogs-vs-cats-redux-kernels-edition\", \"category\": \"Image Classification\", \"size_gb\": 0.85},\n",
        "    {\"id\": \"leaf-classification\", \"category\": \"Image Classification\", \"size_gb\": 0.036},\n",
        "    {\"id\": \"plant-pathology-2020-fgvc7\", \"category\": \"Image Classification\", \"size_gb\": 0.8},\n",
        "    {\"id\": \"ranzcr-clip-catheter-line-classification\", \"category\": \"Image Classification\", \"size_gb\": 13.13},  # Known issue\n",
        "    {\"id\": \"siim-isic-melanoma-classification\", \"category\": \"Image Classification\", \"size_gb\": 116.16},\n",
        "\n",
        "    # Image To Image / Regression\n",
        "    {\"id\": \"denoising-dirty-documents\", \"category\": \"Image To Image\", \"size_gb\": 0.06},\n",
        "    {\"id\": \"histopathologic-cancer-detection\", \"category\": \"Image Regression\", \"size_gb\": 7.76},\n",
        "\n",
        "    # Text Classification\n",
        "    {\"id\": \"detecting-insults-in-social-commentary\", \"category\": \"Text Classification\", \"size_gb\": 0.002},\n",
        "    {\"id\": \"jigsaw-toxic-comment-classification-challenge\", \"category\": \"Text Classification\", \"size_gb\": 0.06},  # Known issue: crowded\n",
        "    {\"id\": \"random-acts-of-pizza\", \"category\": \"Text Classification\", \"size_gb\": 0.003},\n",
        "    {\"id\": \"spooky-author-identification\", \"category\": \"Text Classification\", \"size_gb\": 0.0019},\n",
        "\n",
        "    # Tabular\n",
        "    {\"id\": \"new-york-city-taxi-fare-prediction\", \"category\": \"Tabular\", \"size_gb\": 5.7},\n",
        "    {\"id\": \"nomad2018-predict-transparent-conductors\", \"category\": \"Tabular\", \"size_gb\": 0.00624},\n",
        "    {\"id\": \"tabular-playground-series-dec-2021\", \"category\": \"Tabular\", \"size_gb\": 0.7},  # Known issue: crowded\n",
        "    {\"id\": \"tabular-playground-series-may-2022\", \"category\": \"Tabular\", \"size_gb\": 0.57},  # Known issue: crowded\n",
        "\n",
        "    # Audio\n",
        "    {\"id\": \"mlsp-2013-birds\", \"category\": \"Audio Classification\", \"size_gb\": 0.5851},\n",
        "    {\"id\": \"the-icml-2013-whale-challenge-right-whale-redux\", \"category\": \"Audio Classification\", \"size_gb\": 0.29314},\n",
        "\n",
        "    # Seq->Seq\n",
        "    {\"id\": \"text-normalization-challenge-english-language\", \"category\": \"Seq->Seq\", \"size_gb\": 0.01},\n",
        "    {\"id\": \"text-normalization-challenge-russian-language\", \"category\": \"Seq->Seq\", \"size_gb\": 0.01},\n",
        "]\n",
        "\n",
        "print(f\"Total: {len(MLEBENCH_LITE_COMPETITIONS)} competi√ß√µes\")\n",
        "print(f\"Tamanho total: {sum(c['size_gb'] for c in MLEBENCH_LITE_COMPETITIONS):.2f} GB\")\n",
        "\n",
        "# Mostrar lista\n",
        "import pandas as pd\n",
        "df_competitions = pd.DataFrame(MLEBENCH_LITE_COMPETITIONS)\n",
        "print(\"\\n\")\n",
        "display(df_competitions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vBf9O62tYTk0",
        "outputId": "5c6779e6-1da1-4a5c-d5de-704b8dabb90e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üéØ Competi√ß√µes selecionadas: 1\n",
            "   - aerial-cactus-identification (Image Classification, 0.0254 GB)\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# SELECIONE QUAIS COMPETI√á√ïES RODAR\n",
        "# ============================================================\n",
        "\n",
        "# Op√ß√£o 1: Rodar TODAS as 22 (vai demorar muito!)\n",
        "# COMPETITIONS_TO_RUN = [c['id'] for c in MLEBENCH_LITE_COMPETITIONS]\n",
        "\n",
        "# Op√ß√£o 2: Rodar apenas algumas (recomendado para teste)\n",
        "COMPETITIONS_TO_RUN = [\n",
        "    \"aerial-cactus-identification\",     # Pequena, r√°pida (~25MB)\n",
        "    # \"leaf-classification\",              # Pequena (~36MB)\n",
        "    # \"spooky-author-identification\",     # Texto, pequena (~2MB)\n",
        "    # \"detecting-insults-in-social-commentary\",  # Texto, muito pequena (~2MB)\n",
        "    # \"dog-breed-identification\",         # M√©dia (~750MB)\n",
        "]\n",
        "\n",
        "# Op√ß√£o 3: Rodar por categoria\n",
        "# COMPETITIONS_TO_RUN = [c['id'] for c in MLEBENCH_LITE_COMPETITIONS if c['category'] == 'Image Classification']\n",
        "\n",
        "# Op√ß√£o 4: Rodar as menores (< 1GB)\n",
        "# COMPETITIONS_TO_RUN = [c['id'] for c in MLEBENCH_LITE_COMPETITIONS if c['size_gb'] < 1.0]\n",
        "\n",
        "print(f\"\\nüéØ Competi√ß√µes selecionadas: {len(COMPETITIONS_TO_RUN)}\")\n",
        "for comp in COMPETITIONS_TO_RUN:\n",
        "    info = next(c for c in MLEBENCH_LITE_COMPETITIONS if c['id'] == comp)\n",
        "    print(f\"   - {comp} ({info['category']}, {info['size_gb']} GB)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sX-cbnRbYTk0"
      },
      "source": [
        "## 4. Prepare MLE-bench Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "71jCRIjiYTk0",
        "outputId": "6b1f23e5-a017-471c-f2b9-2dd34e6e74ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "PREPARANDO DATASETS DO MLE-BENCH\n",
            "============================================================\n",
            "\n",
            "[1/1] Preparando: aerial-cactus-identification\n",
            "   ‚úì Preparado com sucesso\n",
            "\n",
            "============================================================\n",
            "‚úì Prepara√ß√£o conclu√≠da!\n"
          ]
        }
      ],
      "source": [
        "import subprocess\n",
        "from pathlib import Path\n",
        "\n",
        "MLE_CACHE = Path(\"/root/.cache/mle-bench/data\")\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"PREPARANDO DATASETS DO MLE-BENCH\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "for i, comp_id in enumerate(COMPETITIONS_TO_RUN, 1):\n",
        "    print(f\"\\n[{i}/{len(COMPETITIONS_TO_RUN)}] Preparando: {comp_id}\")\n",
        "\n",
        "    comp_cache = MLE_CACHE / comp_id / \"prepared\"\n",
        "\n",
        "    if comp_cache.exists():\n",
        "        print(f\"   ‚úì J√° preparado\")\n",
        "    else:\n",
        "        result = subprocess.run(\n",
        "            [\"mlebench\", \"prepare\", \"-c\", comp_id],\n",
        "            capture_output=True,\n",
        "            text=True\n",
        "        )\n",
        "        if result.returncode == 0:\n",
        "            print(f\"   ‚úì Preparado com sucesso\")\n",
        "        else:\n",
        "            print(f\"   ‚ùå Erro: {result.stderr[:200]}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"‚úì Prepara√ß√£o conclu√≠da!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gw6-elUoYTk0"
      },
      "source": [
        "## 5. Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xai2j7wpYTk0",
        "outputId": "a029e7fb-33c7-4f78-e583-0e939003ed4d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úì Helper functions loaded\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import shutil\n",
        "import zipfile\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "\n",
        "MLE_CACHE = Path(\"/root/.cache/mle-bench/data\")\n",
        "WORKSPACE = Path(\"/content/kaggle_competitions\")\n",
        "\n",
        "def setup_mlebench_data(competition_id: str) -> dict:\n",
        "    \"\"\"\n",
        "    Configura os dados do MLE-bench para uma competi√ß√£o.\n",
        "    Copia os dados do MLE-bench para o workspace do kaggle-agents.\n",
        "\n",
        "    Retorna dict com informa√ß√µes sobre os dados.\n",
        "    \"\"\"\n",
        "    mle_dir = MLE_CACHE / competition_id / \"prepared\"\n",
        "    public_dir = mle_dir / \"public\"\n",
        "    private_dir = mle_dir / \"private\"\n",
        "\n",
        "    comp_workspace = WORKSPACE / \"competitions\" / competition_id\n",
        "    comp_workspace.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    print(f\"\\nüìÅ Configurando dados para: {competition_id}\")\n",
        "\n",
        "    # Extrair ZIPs se necess√°rio\n",
        "    for zip_file in public_dir.glob(\"*.zip\"):\n",
        "        extract_dir = public_dir / zip_file.stem\n",
        "        if not extract_dir.exists():\n",
        "            print(f\"   Extraindo: {zip_file.name}\")\n",
        "            with zipfile.ZipFile(zip_file, 'r') as z:\n",
        "                z.extractall(public_dir)\n",
        "\n",
        "    # Copiar arquivos para workspace\n",
        "    for item in public_dir.iterdir():\n",
        "        dest = comp_workspace / item.name\n",
        "        if item.is_file() and not dest.exists():\n",
        "            shutil.copy2(item, dest)\n",
        "        elif item.is_dir() and not dest.exists():\n",
        "            shutil.copytree(item, dest)\n",
        "\n",
        "    # Copiar description.md como contexto\n",
        "    if (public_dir / \"description.md\").exists():\n",
        "        shutil.copy2(public_dir / \"description.md\", comp_workspace / \"description.md\")\n",
        "\n",
        "    # Encontrar arquivos importantes\n",
        "    train_csv = None\n",
        "    sample_sub = None\n",
        "    test_csv = None\n",
        "\n",
        "    for f in comp_workspace.glob(\"*.csv\"):\n",
        "        if \"train\" in f.name.lower():\n",
        "            train_csv = f\n",
        "        elif \"sample\" in f.name.lower() and \"submission\" in f.name.lower():\n",
        "            sample_sub = f\n",
        "        elif \"test\" in f.name.lower():\n",
        "            test_csv = f\n",
        "\n",
        "    # Info sobre ground truth (para valida√ß√£o posterior)\n",
        "    gt_file = None\n",
        "    for pattern in [\"test.csv\", \"answers.csv\", \"solution.csv\"]:\n",
        "        gt = private_dir / pattern\n",
        "        if gt.exists():\n",
        "            gt_file = gt\n",
        "            break\n",
        "\n",
        "    info = {\n",
        "        \"competition_id\": competition_id,\n",
        "        \"workspace\": str(comp_workspace),\n",
        "        \"mle_cache\": str(mle_dir),\n",
        "        \"train_csv\": str(train_csv) if train_csv else None,\n",
        "        \"sample_submission\": str(sample_sub) if sample_sub else None,\n",
        "        \"test_csv\": str(test_csv) if test_csv else None,\n",
        "        \"ground_truth\": str(gt_file) if gt_file else None,\n",
        "    }\n",
        "\n",
        "    print(f\"   ‚úì Workspace: {comp_workspace}\")\n",
        "    print(f\"   ‚úì Train: {train_csv.name if train_csv else 'N/A'}\")\n",
        "    print(f\"   ‚úì Sample submission: {sample_sub.name if sample_sub else 'N/A'}\")\n",
        "\n",
        "    return info\n",
        "\n",
        "\n",
        "def validate_with_mlebench(competition_id: str, submission_path: str) -> dict:\n",
        "    \"\"\"\n",
        "    Valida uma submiss√£o usando MLE-bench.\n",
        "    Retorna o resultado da valida√ß√£o.\n",
        "    \"\"\"\n",
        "    import subprocess\n",
        "\n",
        "    result = subprocess.run(\n",
        "        [\"mlebench\", \"grade-sample\", submission_path, competition_id],\n",
        "        capture_output=True,\n",
        "        text=True\n",
        "    )\n",
        "\n",
        "    # Parse JSON do output\n",
        "    output = result.stdout + result.stderr\n",
        "\n",
        "    # Encontrar JSON no output\n",
        "    try:\n",
        "        json_start = output.find(\"{\")\n",
        "        json_end = output.rfind(\"}\") + 1\n",
        "        if json_start >= 0 and json_end > json_start:\n",
        "            json_str = output[json_start:json_end]\n",
        "            return json.loads(json_str)\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    return {\n",
        "        \"competition_id\": competition_id,\n",
        "        \"valid_submission\": False,\n",
        "        \"error\": output[:500]\n",
        "    }\n",
        "\n",
        "\n",
        "def get_problem_type(competition_id: str) -> tuple:\n",
        "    \"\"\"\n",
        "    Retorna (problem_type, evaluation_metric) baseado na competi√ß√£o.\n",
        "    \"\"\"\n",
        "    # Mapeamento baseado nas competi√ß√µes do MLE-bench Lite\n",
        "    mappings = {\n",
        "        # Image Classification (binary)\n",
        "        \"aerial-cactus-identification\": (\"binary_classification\", \"auc\"),\n",
        "        \"dogs-vs-cats-redux-kernels-edition\": (\"binary_classification\", \"log_loss\"),\n",
        "        \"histopathologic-cancer-detection\": (\"binary_classification\", \"auc\"),\n",
        "        \"siim-isic-melanoma-classification\": (\"binary_classification\", \"auc\"),\n",
        "\n",
        "        # Image Classification (multiclass)\n",
        "        \"aptos2019-blindness-detection\": (\"multiclass_classification\", \"quadratic_weighted_kappa\"),\n",
        "        \"dog-breed-identification\": (\"multiclass_classification\", \"log_loss\"),\n",
        "        \"leaf-classification\": (\"multiclass_classification\", \"log_loss\"),\n",
        "        \"plant-pathology-2020-fgvc7\": (\"multiclass_classification\", \"auc\"),\n",
        "        \"ranzcr-clip-catheter-line-classification\": (\"multilabel_classification\", \"auc\"),\n",
        "\n",
        "        # Image To Image\n",
        "        \"denoising-dirty-documents\": (\"regression\", \"rmse\"),\n",
        "\n",
        "        # Text Classification\n",
        "        \"detecting-insults-in-social-commentary\": (\"binary_classification\", \"auc\"),\n",
        "        \"jigsaw-toxic-comment-classification-challenge\": (\"multilabel_classification\", \"auc\"),\n",
        "        \"random-acts-of-pizza\": (\"binary_classification\", \"auc\"),\n",
        "        \"spooky-author-identification\": (\"multiclass_classification\", \"log_loss\"),\n",
        "\n",
        "        # Tabular\n",
        "        \"new-york-city-taxi-fare-prediction\": (\"regression\", \"rmse\"),\n",
        "        \"nomad2018-predict-transparent-conductors\": (\"regression\", \"rmsle\"),\n",
        "        \"tabular-playground-series-dec-2021\": (\"regression\", \"rmse\"),\n",
        "        \"tabular-playground-series-may-2022\": (\"regression\", \"rmse\"),\n",
        "\n",
        "        # Audio\n",
        "        \"mlsp-2013-birds\": (\"multilabel_classification\", \"auc\"),\n",
        "        \"the-icml-2013-whale-challenge-right-whale-redux\": (\"binary_classification\", \"auc\"),\n",
        "\n",
        "        # Seq->Seq\n",
        "        \"text-normalization-challenge-english-language\": (\"seq2seq\", \"accuracy\"),\n",
        "        \"text-normalization-challenge-russian-language\": (\"seq2seq\", \"accuracy\"),\n",
        "    }\n",
        "\n",
        "    return mappings.get(competition_id, (\"binary_classification\", \"auc\"))\n",
        "\n",
        "print(\"‚úì Helper functions loaded\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QrAx0u6aYTk1"
      },
      "source": [
        "## 6. Run Kaggle Agents Workflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ZsvF-z6CYTk1",
        "outputId": "ae614d8a-4d02-491d-f64b-5f6e04425526"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "üöÄ INICIANDO AVALIA√á√ÉO MLE-BENCH LITE\n",
            "   Competi√ß√µes: 1\n",
            "   Max iterations: 3\n",
            "======================================================================\n",
            "\n",
            "######################################################################\n",
            "# [1/1] aerial-cactus-identification\n",
            "######################################################################\n",
            "\n",
            "üìÅ Configurando dados para: aerial-cactus-identification\n",
            "   Extraindo: test.zip\n",
            "   Extraindo: train.zip\n",
            "   ‚úì Workspace: /content/kaggle_competitions/competitions/aerial-cactus-identification\n",
            "   ‚úì Train: train.csv\n",
            "   ‚úì Sample submission: sample_submission.csv\n",
            "\n",
            "üìä Problem: binary_classification, Metric: auc\n",
            "\n",
            "ü§ñ Executando solve_competition...\n",
            "üìç Colab environment detected, using: /content/kaggle_competitions\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ</span>\n",
              "<span style=\"color: #008080; text-decoration-color: #008080\">‚îÇ</span>                                                                                                                 <span style=\"color: #008080; text-decoration-color: #008080\">‚îÇ</span>\n",
              "<span style=\"color: #008080; text-decoration-color: #008080\">‚îÇ</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">&lt; KAGGLE AGENTS - Autonomous Competition Solving</span>                                                                <span style=\"color: #008080; text-decoration-color: #008080\">‚îÇ</span>\n",
              "<span style=\"color: #008080; text-decoration-color: #008080\">‚îÇ</span>                                                                                                                 <span style=\"color: #008080; text-decoration-color: #008080\">‚îÇ</span>\n",
              "<span style=\"color: #008080; text-decoration-color: #008080\">‚îÇ</span> <span style=\"font-weight: bold\">Competition:</span> aerial-cactus-identification                                                                       <span style=\"color: #008080; text-decoration-color: #008080\">‚îÇ</span>\n",
              "<span style=\"color: #008080; text-decoration-color: #008080\">‚îÇ</span> <span style=\"font-weight: bold\">Problem Type:</span> binary_classification                                                                             <span style=\"color: #008080; text-decoration-color: #008080\">‚îÇ</span>\n",
              "<span style=\"color: #008080; text-decoration-color: #008080\">‚îÇ</span> <span style=\"font-weight: bold\">Metric:</span> auc                                                                                                     <span style=\"color: #008080; text-decoration-color: #008080\">‚îÇ</span>\n",
              "<span style=\"color: #008080; text-decoration-color: #008080\">‚îÇ</span> <span style=\"font-weight: bold\">Goal:</span> Top 20% (Percentile d 20)                                                                                 <span style=\"color: #008080; text-decoration-color: #008080\">‚îÇ</span>\n",
              "<span style=\"color: #008080; text-decoration-color: #008080\">‚îÇ</span>                                                                                                                 <span style=\"color: #008080; text-decoration-color: #008080\">‚îÇ</span>\n",
              "<span style=\"color: #008080; text-decoration-color: #008080\">‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[36m‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ\u001b[0m\n",
              "\u001b[36m‚îÇ\u001b[0m                                                                                                                 \u001b[36m‚îÇ\u001b[0m\n",
              "\u001b[36m‚îÇ\u001b[0m \u001b[1;36m< KAGGLE AGENTS - Autonomous Competition Solving\u001b[0m                                                                \u001b[36m‚îÇ\u001b[0m\n",
              "\u001b[36m‚îÇ\u001b[0m                                                                                                                 \u001b[36m‚îÇ\u001b[0m\n",
              "\u001b[36m‚îÇ\u001b[0m \u001b[1mCompetition:\u001b[0m aerial-cactus-identification                                                                       \u001b[36m‚îÇ\u001b[0m\n",
              "\u001b[36m‚îÇ\u001b[0m \u001b[1mProblem Type:\u001b[0m binary_classification                                                                             \u001b[36m‚îÇ\u001b[0m\n",
              "\u001b[36m‚îÇ\u001b[0m \u001b[1mMetric:\u001b[0m auc                                                                                                     \u001b[36m‚îÇ\u001b[0m\n",
              "\u001b[36m‚îÇ\u001b[0m \u001b[1mGoal:\u001b[0m Top 20% (Percentile d 20)                                                                                 \u001b[36m‚îÇ\u001b[0m\n",
              "\u001b[36m‚îÇ\u001b[0m                                                                                                                 \u001b[36m‚îÇ\u001b[0m\n",
              "\u001b[36m‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "KAGGLE AGENTS WORKFLOW: aerial-cactus-identification\n",
            "======================================================================\n",
            "\n",
            "============================================================\n",
            "= DATA DOWNLOAD\n",
            "============================================================\n",
            "\n",
            "üì• Downloading data for: aerial-cactus-identification\n",
            "   Destination: /content/kaggle_competitions/competitions/aerial-cactus-identification\n",
            "Downloading aerial-cactus-identification.zip to /content/kaggle_competitions/competitions/aerial-cactus-identification\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12.0M/12.0M [00:01<00:00, 7.64MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "‚úì Download complete!\n",
            "   Train: /content/kaggle_competitions/competitions/aerial-cactus-identification/train\n",
            "   Test: /content/kaggle_competitions/competitions/aerial-cactus-identification/test\n",
            "   Sample Submission: /content/kaggle_competitions/competitions/aerial-cactus-identification/sample_submission.csv\n",
            "   üéØ Target Column Detected: has_cactus\n",
            "   üîÑ Generating 5 fixed folds...\n",
            "      Detected classification (unique targets: 2) -> Using StratifiedKFold\n",
            "      ‚úÖ Saved fixed folds to: /content/kaggle_competitions/competitions/aerial-cactus-identification/folds.csv\n",
            "\n",
            "============================================================\n",
            "= DOMAIN DETECTION\n",
            "============================================================\n",
            "\n",
            "\u0005 Domain Detected: image_classification\n",
            "   Confidence: 90.0%\n",
            "\n",
            "============================================================\n",
            "SEARCH AGENT: Retrieving SOTA Solutions\n",
            "============================================================\n",
            "\n",
            "= Generated 3 search queries:\n",
            "  1. aerial-cactus-identification winning solution\n",
            "  2. aerial-cactus-identification gold medal\n",
            "  3. aerial-cactus-identification top solution\n",
            "\n",
            "=\u000e Searching notebooks for: aerial-cactus-identification\n",
            "Searching notebooks for aerial-cactus-identification...\n",
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.8.0 / client 1.6.17)\n",
            "= Found 10 high-quality notebooks\n",
            "  = Analyzing: Getting started with CNN and VGG16 (753 votes)\n",
            "  = Analyzing: Simple_FastAI_exercise (270 votes)\n",
            "  = Analyzing: PyTorch EfficientNet (210 votes)\n",
            "  = Analyzing: Beginners Guide - EfficientNet With Keras  (200 votes)\n",
            "  = Analyzing: Keras Starter (EfficientNet) (165 votes)\n",
            "  = Analyzing: In-Depth Guide to Convolutional Neural Networks (157 votes)\n",
            "  = Analyzing: Detecting cactus with kekas (137 votes)\n",
            "  = Analyzing: [ch11] Baseline (124 votes)\n",
            "  = Analyzing: [ch11] EDA (124 votes)\n",
            "  = Analyzing: Dense Net Image Classification (122 votes)\n",
            "\u0005 Successfully analyzed 10 notebooks\n",
            "\n",
            "   üîç Analyzing SOTA code snippets with LLM...\n",
            "      Analyzing solution 1: Getting started with CNN and VGG16...\n",
            "      Analyzing solution 2: Simple_FastAI_exercise...\n",
            "      Analyzing solution 3: PyTorch EfficientNet...\n",
            "\n",
            "= Found 10 SOTA Solutions:\n",
            "------------------------------------------------------------\n",
            "\n",
            "1. Getting started with CNN and VGG16\n",
            "   Source: shahules/getting-started-with-cnn-and-vgg16\n",
            "   Votes: 753\n",
            "   Models: Neural Network, VGG16 (CNN transfer learning)\n",
            "   Features: target label casting, image preprocessing/augmentation via ImageDataGenerator and preprocess_input...\n",
            "   Code Snippets: 24\n",
            "\n",
            "2. Simple_FastAI_exercise\n",
            "   Source: kenseitrg/simple-fastai-exercise\n",
            "   Votes: 270\n",
            "   Models: Neural Network\n",
            "   Code Snippets: 15\n",
            "\n",
            "3. PyTorch EfficientNet\n",
            "   Source: ateplyuk/pytorch-efficientnet\n",
            "   Votes: 210\n",
            "   Models: Neural Network, EfficientNet\n",
            "   Code Snippets: 15\n",
            "\n",
            "4. Beginners Guide - EfficientNet With Keras \n",
            "   Source: arjunrao2000/beginners-guide-efficientnet-with-keras\n",
            "   Votes: 200\n",
            "   Models: Neural Network\n",
            "   Code Snippets: 15\n",
            "\n",
            "5. Keras Starter (EfficientNet)\n",
            "   Source: ateplyuk/keras-starter-efficientnet\n",
            "   Votes: 165\n",
            "   Models: Neural Network\n",
            "   Code Snippets: 15\n",
            "\n",
            "============================================================\n",
            "\u0005 DSPy configured with openai/gpt-5.1-codex-mini\n",
            "\u000f  No optimized prompts found for planner\n",
            "   No optimized planner module found -> using direct LLM path\n",
            "\n",
            "============================================================\n",
            "= PLANNER AGENT: Creating Ablation Plan\n",
            "============================================================\n",
            "\n",
            "Analyzing SOTA patterns...\n",
            "   Found 4 common models\n",
            "   Found 4 feature patterns\n",
            "\n",
            "üìù Generating ablation plan...\n",
            "  üîß Using fallback plan (ensures 5 high-quality components)\n",
            "  üìä Final plan: 0 FE + 2 models + 1 ensemble = 3 total\n",
            "\n",
            "= Ablation Plan Created: 3 components\n",
            "------------------------------------------------------------\n",
            "\n",
            "1. efficientnet_b0_classification (model)\n",
            "   Estimated Impact: 28.0%\n",
            "   Code: torchvision.models.efficientnet_b0(pretrained=True), replace classifier head, tr...\n",
            "\n",
            "2. resnet50_classification (model)\n",
            "   Estimated Impact: 24.0%\n",
            "   Code: torchvision.models.resnet50(pretrained=True), replace fc layer, Cutout + Mixup a...\n",
            "\n",
            "3. tta_ensemble (ensemble)\n",
            "   Estimated Impact: 15.0%\n",
            "   Code: For each test image: apply 5 transforms (original, hflip, vflip, rotate90, rotat...\n",
            "\n",
            "============================================================\n",
            "Component timeout set to: 3000s (50.0 min)\n",
            "\u0005 DSPy configured with openai/gpt-5.1-codex-mini\n",
            "\u000f  No optimized prompts found for developer_generator\n",
            "\u000f  No optimized prompts found for developer_fixer\n",
            "Using base (unoptimized) generator module\n",
            "Using base (unoptimized) fixer module\n",
            "\n",
            "============================================================\n",
            "= DEVELOPER AGENT: Implementing Components\n",
            "============================================================\n",
            "\n",
            "= Implementing: efficientnet_b0_classification (model)\n",
            "Estimated Impact: 28.0%\n",
            "\n",
            "Generating code...\n",
            "\n",
            "Generated code preview:\n",
            "        1 | import copy\n",
            "        2 | import os\n",
            "        3 | import random\n",
            "        4 | from pathlib import Path\n",
            "        5 | \n",
            "        6 | import numpy as np\n",
            "        7 | import pandas as pd\n",
            "        8 | import torch\n",
            "        9 | from PIL import Image\n",
            "       10 | from sklearn.compose import ColumnTransformer\n",
            "       11 | from sklearn.metrics import roc_auc_score\n",
            "       12 | from sklearn.model_selection import StratifiedKFold\n",
            "       13 | from sklearn.preprocessing import OneHotEncoder\n",
            "       14 | from torch import nn\n",
            "       15 | from torch.utils.data import DataLoader, Dataset\n",
            "       16 | from torchvision import models, transforms\n",
            "       17 | \n",
            "       18 | \n",
            "       19 | TARGET_COL = \"has_cactus\"\n",
            "       20 | COMPONENT_NAME = \"efficientnet_b0_classification\"\n",
            "       21 | \n",
            "       22 | \n",
            "       23 | class CactusTrainDataset(Dataset):\n",
            "       24 |     def __init__(self, df: pd.DataFrame, image_dir: Path, transform=None):\n",
            "       25 |         self.df = df.reset_index(drop=True).copy()\n",
            "       26 |         self.image_dir = Path(image_dir)\n",
            "       27 |         self.transform = transform\n",
            "       28 |         self.ids = self.df[\"id\"].astype(str).tolist()\n",
            "       29 |         self.targets = self.df[TARGET_COL].astype(int).values\n",
            "       30 | \n",
            "       31 |     def __len__(self):\n",
            "       32 |         return len(self.ids)\n",
            "       33 | \n",
            "       34 |     def __getitem__(self, idx):\n",
            "       35 |         image_path = self.image_dir / self.ids[idx]\n",
            "       36 |         image = Image.open(image_path).convert(\"RGB\")\n",
            "       37 |         if self.transform:\n",
            "       38 |             image = self.transform(image)\n",
            "       39 |         return image, int(self.targets[idx])\n",
            "       40 | \n",
            "       41 | \n",
            "       42 | class CactusTestDataset(Dataset):\n",
            "       43 |     def __init__(self, ids, image_dir: Path, transform=None):\n",
            "       44 |         self.ids = [str(x) for x in ids]\n",
            "       45 |         self.image_dir = Path(image_dir)\n",
            "       46 |         self.transform = transform\n",
            "       47 | \n",
            "       48 |     def __len__(self):\n",
            "       49 |         return len(self.ids)\n",
            "       50 | \n",
            "       51 |     def __getitem__(self, idx):\n",
            "       52 |         image_path = self.image_dir / self.ids[idx]\n",
            "       53 |         image = Image.open(image_path).convert(\"RGB\")\n",
            "       54 |         if self.transform:\n",
            "       55 |             image = self.transform(image)\n",
            "       56 |         return image\n",
            "       57 | \n",
            "       58 | \n",
            "       59 | def get_transforms():\n",
            "       60 |     imagenet_mean = [0.485, 0.456, 0.406]\n",
            "       61 |     imagenet_std = [0.229, 0.224, 0.225]\n",
            "       62 |     train_transforms = transforms.Compose(\n",
            "       63 |         [\n",
            "       64 |             transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
            "       65 |             transforms.RandomHorizontalFlip(p=0.5),\n",
            "       66 |             transforms.ToTensor(),\n",
            "       67 |             transforms.Normalize(mean=imagenet_mean, std=imagenet_std),\n",
            "       68 |         ]\n",
            "       69 |     )\n",
            "       70 |     val_transforms = transforms.Compose(\n",
            "       71 |         [\n",
            "       72 |             transforms.Resize(256),\n",
            "       73 |             transforms.CenterCrop(224),\n",
            "       74 |             transforms.ToTensor(),\n",
            "       75 |             transforms.Normalize(mean=imagenet_mean, std=imagenet_std),\n",
            "       76 |         ]\n",
            "       77 |     )\n",
            "       78 |     return train_transforms, val_transforms\n",
            "       79 | \n",
            "       80 | \n",
            "       81 | def build_model(num_classes=2):\n",
            "       82 |     try:\n",
            "       83 |         weights = models.EfficientNet_B0_Weights.IMAGENET1K_V1\n",
            "       84 |         model = models.efficientnet_b0(weights=weights)\n",
            "       85 |     except AttributeError:\n",
            "       86 |         model = models.efficientnet_b0(pretrained=True)\n",
            "       87 |     in_features = model.classifier[1].in_features\n",
            "       88 |     model.classifier[1] = nn.Linear(in_features, num_classes)\n",
            "       89 |     return model\n",
            "       90 | \n",
            "       91 | \n",
            "       92 | def set_seed(seed=42):\n",
            "       93 |     random.seed(seed)\n",
            "       94 |     np.random.seed(seed)\n",
            "       95 |     torch.manual_seed(seed)\n",
            "       96 |     torch.cuda.manual_seed_all(seed)\n",
            "       97 | \n",
            "       98 | \n",
            "       99 | def main():\n",
            "      100 |     set_seed(42)\n",
            "      101 |     base_path = Path(\"/content/kaggle_competitions/competitions/aerial-cactus-identification\")\n",
            "      102 |     train_dir = base_path / \"train\"\n",
            "      103 |     test_dir = base_path / \"test\"\n",
            "      104 |     models_dir = base_path / \"models\"\n",
            "      105 |     models_dir.mkdir(parents=True, exist_ok=True)\n",
            "      106 | \n",
            "      107 |     train_csv_candidates = [base_path / \"train.csv\", train_dir / \"train.csv\"]\n",
            "      108 |     train_csv_path = next((path for path in train_csv_candidates if path.is_file()), None)\n",
            "      109 |     if train_csv_path is None:\n",
            "      110 |         raise FileNotFoundError(\"train.csv was not found in expected locations.\")\n",
            "      111 |     train_df = pd.read_csv(train_csv_path)\n",
            "      112 |     train_df = train_df.reset_index(drop=True)\n",
            "      113 | \n",
            "      114 |     if TARGET_COL not in train_df.columns:\n",
            "      115 |         raise ValueError(f\"{TARGET_COL} column is missing from train.csv\")\n",
            "      116 | \n",
            "      117 |     sample_submission_path = base_path / \"sample_submission.csv\"\n",
            "      118 |     if not sample_submission_path.is_file():\n",
            "      119 |         raise FileNotFoundError(\"sample_submission.csv not found.\")\n",
            "      120 |     sample_submission = pd.read_csv(sample_submission_path)\n",
            "      121 |     submission_target_col = sample_submission.columns[1]\n",
            "      122 | \n",
            "      123 |     print(\"Dataset samples:\", train_df.head(3).to_dict(orient=\"records\"))\n",
            "      124 |     categorical_columns = train_df.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
            "      125 |     if categorical_columns:\n",
            "      126 |         column_transformer = ColumnTransformer(\n",
            "      127 |             transformers=[\n",
            "      128 |                 (\n",
            "      129 |                     \"cat\",\n",
            "      130 |                     OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False),\n",
            "      131 |                     categorical_columns,\n",
            "      132 |                 )\n",
            "      133 |             ],\n",
            "      134 |             remainder=\"drop\",\n",
            "      135 |         )\n",
            "      136 |         column_transformer.fit(train_df[categorical_columns])\n",
            "      137 |         _ = column_transformer.transform(train_df[categorical_columns])\n",
            "      138 |         print(\"Encoded categorical columns via ColumnTransformer:\", categorical_columns)\n",
            "      139 |     else:\n",
            "      140 |         print(\"No categorical columns to encode; proceeding with image-only data.\")\n",
            "      141 | \n",
            "      142 |     folds_path = base_path / \"folds.csv\"\n",
            "      143 |     splits = []\n",
            "      144 |     if folds_path.is_file():\n",
            "      145 |         folds_df = pd.read_csv(folds_path).reset_index(drop=True)\n",
            "      146 |         if len(folds_df) == len(train_df):\n",
            "      147 |             for fold_value in sorted(folds_df[\"fold\"].unique()):\n",
            "      148 |                 val_idx = folds_df[folds_df[\"fold\"] == fold_value].index.to_numpy()\n",
            "      149 |                 train_idx = folds_df[folds_df[\"fold\"] != fold_value].index.to_numpy()\n",
            "      150 |                 splits.append((int(fold_value), train_idx, val_idx))\n",
            "      151 |             print(\"Loaded fold splits from folds.csv\")\n",
            "      152 |         else:\n",
            "      153 |             print(\"folds.csv length mismatch; falling back to StratifiedKFold\")\n",
            "      154 |     if not splits:\n",
            "      155 |         skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
            "      156 |         for fold_value, (train_idx, val_idx) in enumerate(\n",
            "      157 |             skf.split(train_df, train_df[TARGET_COL])\n",
            "      158 |         ):\n",
            "      159 |             splits.append((fold_value, train_idx, val_idx))\n",
            "      160 |         print(\"Using StratifiedKFold for cross-validation\")\n",
            "      161 | \n",
            "      162 |     n_folds = len(splits)\n",
            "      163 |     train_transform, val_transform = get_transforms()\n",
            "      164 |     test_dataset = CactusTestDataset(sample_submission.iloc[:, 0].values, test_dir, transform=val_transform)\n",
            "      165 |     test_loader = DataLoader(\n",
            "      166 |         test_dataset,\n",
            "      167 |         batch_size=32,\n",
            "      168 |         shuffle=False,\n",
            "      169 |         num_workers=min(4, os.cpu_count() or 1),\n",
            "      170 |         pin_memory=torch.cuda.is_available(),\n",
            "      171 |     )\n",
            "      172 | \n",
            "      173 |     class_counts = (\n",
            "      174 |         train_df[TARGET_COL].value_counts().reindex([0, 1], fill_value=0).sort_index()\n",
            "      175 |     )\n",
            "      176 |     total_count = class_counts.sum()\n",
            "      177 |     weight_values = []\n",
            "      178 |     for cls in [0, 1]:\n",
            "      179 |         count = class_counts.get(cls, 0)\n",
            "      180 |         if count <= 0:\n",
            "      181 |             weight_values.append(1.0)\n",
            "      182 |         else:\n",
            "      183 |             weight_values.append(total_count / (2 * count))\n",
            "      184 | \n",
            "      185 |     oof_preds = np.zeros(len(train_df), dtype=np.float32)\n",
            "      186 |     test_preds = np.zeros(len(test_dataset), dtype=np.float32)\n",
            "      187 |     fold_scores = []\n",
            "      188 |     device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
            "      189 |     torch.backends.cudnn.benchmark = True\n",
            "      190 | \n",
            "      191 |     for fold_id, train_idx, val_idx in splits:\n",
            "      192 |         print(f\"Starting Fold {fold_id}\")\n",
            "      193 |         train_fold_df = train_df.iloc[train_idx].reset_index(drop=True)\n",
            "      194 |         val_fold_df = train_df.iloc[val_idx].reset_index(drop=True)\n",
            "      195 | \n",
            "      196 |         train_dataset = CactusTrainDataset(train_fold_df, train_dir, transform=train_transform)\n",
            "      197 |         val_dataset = CactusTrainDataset(val_fold_df, train_dir, transform=val_transform)\n",
            "      198 | \n",
            "      199 |         train_loader = DataLoader(\n",
            "      200 |             train_dataset,\n",
            "      201 |             batch_size=32,\n",
            "      202 |             shuffle=True,\n",
            "      203 |             num_workers=min(4, os.cpu_count() or 1),\n",
            "      204 |             pin_memory=torch.cuda.is_available(),\n",
            "      205 |         )\n",
            "      206 |         val_loader = DataLoader(\n",
            "      207 |             val_dataset,\n",
            "      208 |             batch_size=32,\n",
            "      209 |             shuffle=False,\n",
            "      210 |             num_workers=min(4, os.cpu_count() or 1),\n",
            "      211 |             pin_memory=torch.cuda.is_available(),\n",
            "      212 |         )\n",
            "      213 | \n",
            "      214 |         model = build_model().to(device)\n",
            "      215 |         optimizer = torch.optim.Adam(model.parameters(), lr=2e-4)\n",
            "      216 |         loss_fn = nn.CrossEntropyLoss(weight=torch.tensor(weight_values, dtype=torch.float32).to(device))\n",
            "      217 | \n",
            "      218 |         best_state = None\n",
            "      219 |         best_auc = -np.inf\n",
            "      220 |         epochs = 5\n",
            "      221 |         for epoch in range(epochs):\n",
            "      222 |             model.train()\n",
            "      223 |             running_loss = 0.0\n",
            "      224 |             for images, targets in train_loader:\n",
            "      225 |                 images = images.to(device)\n",
            "      226 |                 targets = targets.to(device)\n",
            "      227 |                 optimizer.zero_grad()\n",
            "      228 |                 outputs = model(images)\n",
            "      229 |                 loss = loss_fn(outputs, targets)\n",
            "      230 |                 loss.backward()\n",
            "      231 |                 optimizer.step()\n",
            "      232 |                 running_loss += loss.item() * images.size(0)\n",
            "      233 |             epoch_loss = running_loss / len(train_loader.dataset)\n",
            "      234 | \n",
            "      235 |             model.eval()\n",
            "      236 |             val_targets = []\n",
            "      237 |             val_probs = []\n",
            "      238 |             with torch.no_grad():\n",
            "      239 |                 for images, targets in val_loader:\n",
            "      240 |                     images = images.to(device)\n",
            "      241 |                     targets = targets.to(device)\n",
            "      242 |                     outputs = model(images)\n",
            "      243 |                     probs = torch.softmax(outputs, dim=1)[:, 1]\n",
            "      244 |                     val_targets.extend(targets.cpu().numpy())\n",
            "      245 |                     val_probs.extend(probs.cpu().numpy())\n",
            "      246 |             try:\n",
            "      247 |                 epoch_auc = roc_auc_score(val_targets, val_probs)\n",
            "      248 |             except ValueError:\n",
            "      249 |                 epoch_auc = 0.5\n",
            "      250 |             print(\n",
            "      251 |                 f\"Fold {fold_id} Epoch {epoch + 1}/{epochs} - Loss: {epoch_loss:.4f} AUC: {epoch_auc:.4f}\"\n",
            "      252 |             )\n",
            "      253 |             if epoch_auc > best_auc:\n",
            "      254 |                 best_auc = epoch_auc\n",
            "      255 |                 best_state = copy.deepcopy(model.state_dict())\n",
            "      256 | \n",
            "      257 |         if best_state is None:\n",
            "      258 |             best_state = copy.deepcopy(model.state_dict())\n",
            "      259 |         model.load_state_dict(best_state)\n",
            "      260 |         model_path = models_dir / f\"{COMPONENT_NAME}_fold{fold_id}.pth\"\n",
            "      261 |         torch.save(model.state_dict(), model_path)\n",
            "      262 |         print(f\"Saved fold {fold_id} weights to {model_path}\")\n",
            "      263 | \n",
            "      264 |         model.eval()\n",
            "      265 |         val_targets = []\n",
            "      266 |         val_probs = []\n",
            "      267 |         with torch.no_grad():\n",
            "      268 |             for images, targets in val_loader:\n",
            "      269 |                 images = images.to(device)\n",
            "      270 |                 targets = targets.to(device)\n",
            "      271 |                 outputs = model(images)\n",
            "      272 |                 probs = torch.softmax(outputs, dim=1)[:, 1]\n",
            "      273 |                 val_targets.extend(targets.cpu().numpy())\n",
            "      274 |                 val_probs.extend(probs.cpu().numpy())\n",
            "      275 |         oof_preds[val_idx] = np.array(val_probs, dtype=np.float32)\n",
            "      276 |         fold_auc = roc_auc_score(val_targets, val_probs)\n",
            "      277 |         fold_scores.append(fold_auc)\n",
            "      278 |         print(f\"Fold {fold_id} validation AUC: {fold_auc:.4f}\")\n",
            "      279 | \n",
            "      280 |         fold_test_probs = []\n",
            "      281 |         with torch.no_grad():\n",
            "      282 |             for batch in test_loader:\n",
            "      283 |                 if isinstance(batch, (list, tuple)):\n",
            "      284 |                     images = batch[0]\n",
            "      285 |                 else:\n",
            "      286 |                     images = batch\n",
            "      287 |                 images = images.to(device)\n",
            "      288 |                 outputs = model(images)\n",
            "      289 |                 probs = torch.softmax(outputs, dim=1)[:, 1]\n",
            "      290 |                 fold_test_probs.append(probs.cpu().numpy())\n",
            "      291 |         fold_test_probs = np.concatenate(fold_test_probs, axis=0)\n",
            "      292 |         test_preds += fold_test_probs / n_folds\n",
            "      293 |         print(f\"Accumulated test predictions for fold {fold_id}\")\n",
            "      294 | \n",
            "      295 |     final_score = float(np.mean(fold_scores)) if fold_scores else 0.0\n",
            "      296 |     print(f\"Final Validation Performance: {final_score:.4f}\")\n",
            "      297 | \n",
            "      298 |     oof_path = models_dir / f\"oof_{COMPONENT_NAME}.npy\"\n",
            "      299 |     test_oof_path = models_dir / f\"test_{COMPONENT_NAME}.npy\"\n",
            "      300 |     np.save(oof_path, oof_preds)\n",
            "      301 |     np.save(test_oof_path, test_preds)\n",
            "      302 |     print(f\"Saved OOF predictions to {oof_path}\")\n",
            "      303 |     print(f\"Saved test predictions to {test_oof_path}\")\n",
            "      304 | \n",
            "      305 |     submission = sample_submission.copy()\n",
            "      306 |     submission[submission_target_col] = test_preds\n",
            "      307 |     submission_output_path = base_path / \"submission.csv\"\n",
            "      308 |     submission.to_csv(submission_output_path, index=False)\n",
            "      309 |     print(f\"Submission file written to {submission_output_path}\")\n",
            "      310 | \n",
            "      311 | \n",
            "      312 | if __name__ == \"__main__\":\n",
            "      313 |     main()\n",
            "\n",
            "Code saved to: generated_code_efficientnet_b0_classification.py\n",
            "\n",
            "Executing code...\n",
            "\n",
            "Attempt 1/3\n",
            "      Loaded fold splits from folds.csv\n",
            "      Starting Fold 0\n",
            "      Downloading: \"https://download.pytorch.org/models/efficientnet_b0_rwightman-7f5810bc.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b0_rwightman-7f5810bc.pth\n",
            "      ‚ö†Ô∏è \n",
            "      ‚ö†Ô∏è   0%|          | 0.00/20.5M [00:00<?, ?B/s]\n",
            "      ‚ö†Ô∏è  22%|‚ñà‚ñà‚ñè       | 4.50M/20.5M [00:00<00:00, 46.8MB/s]\n",
            "      ‚ö†Ô∏è  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 10.6M/20.5M [00:00<00:00, 56.5MB/s]\n",
            "      ‚ö†Ô∏è 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20.5M/20.5M [00:00<00:00, 83.6MB/s]\n",
            "      ‚è≥ Execution in progress... (41s elapsed, 2959s remaining)\n",
            "      ‚è≥ Execution in progress... (71s elapsed, 2929s remaining)\n",
            "      Fold 0 Epoch 1/5 - Loss: 0.0603 AUC: 0.9997\n",
            "      ‚è≥ Execution in progress... (111s elapsed, 2889s remaining)\n",
            "      ‚è≥ Execution in progress... (141s elapsed, 2859s remaining)\n",
            "      Fold 0 Epoch 2/5 - Loss: 0.0198 AUC: 1.0000\n",
            "      ‚è≥ Execution in progress... (178s elapsed, 2822s remaining)\n",
            "      ‚è≥ Execution in progress... (208s elapsed, 2792s remaining)\n",
            "      Fold 0 Epoch 3/5 - Loss: 0.0119 AUC: 0.9999\n",
            "      ‚è≥ Execution in progress... (247s elapsed, 2753s remaining)\n",
            "      ‚è≥ Execution in progress... (277s elapsed, 2723s remaining)\n",
            "      Fold 0 Epoch 4/5 - Loss: 0.0168 AUC: 0.9999\n",
            "      ‚è≥ Execution in progress... (316s elapsed, 2684s remaining)\n",
            "      ‚è≥ Execution in progress... (346s elapsed, 2654s remaining)\n",
            "      Fold 0 Epoch 5/5 - Loss: 0.0104 AUC: 1.0000\n",
            "      Saved fold 0 weights to /content/kaggle_competitions/competitions/aerial-cactus-identification/models/efficientnet_b0_classification_fold0.pth\n",
            "      Fold 0 validation AUC: 1.0000\n",
            "      Accumulated test predictions for fold 0\n",
            "      Starting Fold 1\n",
            "      ‚è≥ Execution in progress... (394s elapsed, 2606s remaining)\n",
            "      ‚è≥ Execution in progress... (424s elapsed, 2576s remaining)\n",
            "      Fold 1 Epoch 1/5 - Loss: 0.0621 AUC: 0.9999\n",
            "      ‚è≥ Execution in progress... (464s elapsed, 2536s remaining)\n",
            "      ‚è≥ Execution in progress... (494s elapsed, 2506s remaining)\n",
            "      Fold 1 Epoch 2/5 - Loss: 0.0173 AUC: 1.0000\n",
            "      ‚è≥ Execution in progress... (533s elapsed, 2467s remaining)\n",
            "      ‚è≥ Execution in progress... (563s elapsed, 2437s remaining)\n",
            "      Fold 1 Epoch 3/5 - Loss: 0.0171 AUC: 1.0000\n",
            "      ‚è≥ Execution in progress... (602s elapsed, 2398s remaining)\n",
            "      ‚è≥ Execution in progress... (632s elapsed, 2368s remaining)\n",
            "      Fold 1 Epoch 4/5 - Loss: 0.0082 AUC: 1.0000\n",
            "      ‚è≥ Execution in progress... (672s elapsed, 2328s remaining)\n",
            "      ‚è≥ Execution in progress... (702s elapsed, 2298s remaining)\n",
            "      Fold 1 Epoch 5/5 - Loss: 0.0091 AUC: 1.0000\n",
            "      Saved fold 1 weights to /content/kaggle_competitions/competitions/aerial-cactus-identification/models/efficientnet_b0_classification_fold1.pth\n",
            "      Fold 1 validation AUC: 1.0000\n",
            "      Accumulated test predictions for fold 1\n",
            "      Starting Fold 2\n",
            "      ‚è≥ Execution in progress... (750s elapsed, 2250s remaining)\n",
            "      ‚è≥ Execution in progress... (780s elapsed, 2220s remaining)\n",
            "      Fold 2 Epoch 1/5 - Loss: 0.0623 AUC: 0.9998\n",
            "      ‚è≥ Execution in progress... (820s elapsed, 2180s remaining)\n",
            "      ‚è≥ Execution in progress... (850s elapsed, 2150s remaining)\n",
            "      Fold 2 Epoch 2/5 - Loss: 0.0231 AUC: 0.9999\n",
            "      ‚è≥ Execution in progress... (889s elapsed, 2111s remaining)\n",
            "      ‚è≥ Execution in progress... (919s elapsed, 2081s remaining)\n",
            "      Fold 2 Epoch 3/5 - Loss: 0.0142 AUC: 1.0000\n",
            "      ‚è≥ Execution in progress... (958s elapsed, 2042s remaining)\n",
            "      ‚è≥ Execution in progress... (988s elapsed, 2012s remaining)\n",
            "      Fold 2 Epoch 4/5 - Loss: 0.0101 AUC: 0.9999\n",
            "      ‚è≥ Execution in progress... (1028s elapsed, 1972s remaining)\n",
            "      ‚è≥ Execution in progress... (1058s elapsed, 1942s remaining)\n",
            "      Fold 2 Epoch 5/5 - Loss: 0.0096 AUC: 0.9998\n",
            "      Saved fold 2 weights to /content/kaggle_competitions/competitions/aerial-cactus-identification/models/efficientnet_b0_classification_fold2.pth\n",
            "      Fold 2 validation AUC: 1.0000\n",
            "      Accumulated test predictions for fold 2\n",
            "      Starting Fold 3\n",
            "      ‚è≥ Execution in progress... (1106s elapsed, 1894s remaining)\n",
            "      ‚è≥ Execution in progress... (1136s elapsed, 1864s remaining)\n",
            "      Fold 3 Epoch 1/5 - Loss: 0.0600 AUC: 0.9986\n",
            "      ‚è≥ Execution in progress... (1175s elapsed, 1825s remaining)\n",
            "      ‚è≥ Execution in progress... (1205s elapsed, 1795s remaining)\n",
            "      Fold 3 Epoch 2/5 - Loss: 0.0163 AUC: 0.9964\n",
            "      ‚è≥ Execution in progress... (1245s elapsed, 1755s remaining)\n",
            "      ‚è≥ Execution in progress... (1275s elapsed, 1725s remaining)\n",
            "      Fold 3 Epoch 3/5 - Loss: 0.0141 AUC: 1.0000\n",
            "      ‚è≥ Execution in progress... (1314s elapsed, 1686s remaining)\n",
            "      ‚è≥ Execution in progress... (1344s elapsed, 1656s remaining)\n",
            "      Fold 3 Epoch 4/5 - Loss: 0.0137 AUC: 0.9961\n",
            "      ‚è≥ Execution in progress... (1383s elapsed, 1617s remaining)\n",
            "      ‚è≥ Execution in progress... (1413s elapsed, 1587s remaining)\n",
            "      Fold 3 Epoch 5/5 - Loss: 0.0108 AUC: 0.9887\n",
            "      Saved fold 3 weights to /content/kaggle_competitions/competitions/aerial-cactus-identification/models/efficientnet_b0_classification_fold3.pth\n",
            "      Fold 3 validation AUC: 1.0000\n",
            "      Accumulated test predictions for fold 3\n",
            "      Starting Fold 4\n",
            "      ‚è≥ Execution in progress... (1461s elapsed, 1539s remaining)\n",
            "      ‚è≥ Execution in progress... (1491s elapsed, 1509s remaining)\n",
            "      Fold 4 Epoch 1/5 - Loss: 0.0544 AUC: 0.9999\n",
            "      ‚è≥ Execution in progress... (1531s elapsed, 1469s remaining)\n",
            "      ‚è≥ Execution in progress... (1561s elapsed, 1439s remaining)\n",
            "      Fold 4 Epoch 2/5 - Loss: 0.0199 AUC: 1.0000\n",
            "      ‚è≥ Execution in progress... (1600s elapsed, 1400s remaining)\n",
            "      ‚è≥ Execution in progress... (1630s elapsed, 1370s remaining)\n",
            "      Fold 4 Epoch 3/5 - Loss: 0.0140 AUC: 1.0000\n",
            "      ‚è≥ Execution in progress... (1669s elapsed, 1331s remaining)\n",
            "      ‚è≥ Execution in progress... (1699s elapsed, 1301s remaining)\n",
            "      Fold 4 Epoch 4/5 - Loss: 0.0092 AUC: 1.0000\n",
            "      ‚è≥ Execution in progress... (1738s elapsed, 1262s remaining)\n",
            "      ‚è≥ Execution in progress... (1768s elapsed, 1232s remaining)\n",
            "      Fold 4 Epoch 5/5 - Loss: 0.0151 AUC: 1.0000\n",
            "      Saved fold 4 weights to /content/kaggle_competitions/competitions/aerial-cactus-identification/models/efficientnet_b0_classification_fold4.pth\n",
            "      Fold 4 validation AUC: 1.0000\n",
            "      Accumulated test predictions for fold 4\n",
            "      üéØ Final Validation Performance: 1.0000\n",
            "      Saved OOF predictions to /content/kaggle_competitions/competitions/aerial-cactus-identification/models/oof_efficientnet_b0_classification.npy\n",
            "      Saved test predictions to /content/kaggle_competitions/competitions/aerial-cactus-identification/models/test_efficientnet_b0_classification.npy\n",
            "Execution failed: Error: 0%|          | 0.00/20.5M [00:00<?, ?B/s]\n",
            " 22%|‚ñà‚ñà‚ñè       | 4.50M/20.5M [00:00<00:00, 46.8MB/s]\n",
            " 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 10.6M/20.5M [00:00<00:00, 56.5MB/s]\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20.5M/20.5M [00:00<00:00, 83.6MB/s]\n",
            "\n",
            "Getting meta-evaluator feedback...\n",
            "Meta-Feedback:\n",
            "1. **Root Cause**: The script hardcodes `base_path = Path(\"/content/kaggle_competitions/...\")`, so any runner without that exact directory structure will immediately fail (e.g., no `train/`, `test/`, or submission CSV).  \n",
            "   **Fix**: Allow overrides via environment variables or CLI arguments, e.g.,  \n",
            "   ```python\n",
            "   BASE_DIR = Path(os.environ.get(\"CACTUS_BASE\", \"/content/...\"))\n",
            "   ```\n",
            "   and assert required paths exist with clear messages before training.\n",
            "\n",
            "2. **Root Cause**: The download progress output indicates the pretrained weights download is the only activity‚Äîif download fails (due to offline or permission), training halts with vague errors.  \n",
            "   **Fix**: Cache weights locally or wrap `build_model` in try/catch and fall back to `pretrained=False`, logging the fallback.\n",
            "\n",
            "3. **Best Practice**: Always validate external files before heavy computation and log missing-resource errors early. Use helper functions like `require_file(path, desc)` to keep failures readable and avoid silent crashes later in the pipeline.\n",
            "\n",
            "Passing error context to fixer: Error: 0%|          | 0.00/20.5M [00:00<?, ?B/s]  22%|‚ñà‚ñà‚ñè       | 4.50M/20.5M [00:00<00:00, 46.8MB/s]  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 10.6M/20.5M [00:00<00:00, 56.5MB/s] 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20.5M/20.5M [00:00<00:00, 83.6MB/s]\n",
            "Attempting to fix...\n",
            "\n",
            "Attempt 2/3\n",
            "      Loaded fold splits from folds.csv\n",
            "      Starting Fold 0\n",
            "      ‚è≥ Execution in progress... (36s elapsed, 2964s remaining)\n",
            "      ‚è≥ Execution in progress... (66s elapsed, 2934s remaining)\n",
            "      Fold 0 Epoch 1/5 - Loss: 0.0603 AUC: 0.9997\n",
            "      ‚è≥ Execution in progress... (107s elapsed, 2893s remaining)\n",
            "      ‚è≥ Execution in progress... (137s elapsed, 2863s remaining)\n",
            "      Fold 0 Epoch 2/5 - Loss: 0.0198 AUC: 1.0000\n",
            "      ‚è≥ Execution in progress... (176s elapsed, 2824s remaining)\n",
            "      ‚è≥ Execution in progress... (207s elapsed, 2793s remaining)\n",
            "      Fold 0 Epoch 3/5 - Loss: 0.0119 AUC: 0.9999\n",
            "      ‚è≥ Execution in progress... (246s elapsed, 2754s remaining)\n",
            "      ‚è≥ Execution in progress... (276s elapsed, 2724s remaining)\n",
            "      Fold 0 Epoch 4/5 - Loss: 0.0168 AUC: 0.9999\n",
            "      ‚è≥ Execution in progress... (315s elapsed, 2685s remaining)\n",
            "      ‚è≥ Execution in progress... (345s elapsed, 2655s remaining)\n",
            "      Fold 0 Epoch 5/5 - Loss: 0.0125 AUC: 1.0000\n",
            "      Saved fold 0 weights to /content/kaggle_competitions/competitions/aerial-cactus-identification/models/efficientnet_b0_classification_fold0.pth\n",
            "      Fold 0 validation AUC: 1.0000\n",
            "      Accumulated test predictions for fold 0\n",
            "      Starting Fold 1\n",
            "      ‚è≥ Execution in progress... (393s elapsed, 2607s remaining)\n",
            "      ‚è≥ Execution in progress... (423s elapsed, 2577s remaining)\n",
            "      Fold 1 Epoch 1/5 - Loss: 0.0621 AUC: 0.9999\n",
            "      ‚è≥ Execution in progress... (463s elapsed, 2537s remaining)\n",
            "      ‚è≥ Execution in progress... (493s elapsed, 2507s remaining)\n",
            "      Fold 1 Epoch 2/5 - Loss: 0.0173 AUC: 1.0000\n",
            "      ‚è≥ Execution in progress... (532s elapsed, 2468s remaining)\n",
            "      ‚è≥ Execution in progress... (562s elapsed, 2438s remaining)\n",
            "      Fold 1 Epoch 3/5 - Loss: 0.0171 AUC: 1.0000\n",
            "      ‚è≥ Execution in progress... (601s elapsed, 2399s remaining)\n",
            "      ‚è≥ Execution in progress... (631s elapsed, 2369s remaining)\n",
            "      Fold 1 Epoch 4/5 - Loss: 0.0082 AUC: 1.0000\n",
            "      ‚è≥ Execution in progress... (670s elapsed, 2330s remaining)\n",
            "      ‚è≥ Execution in progress... (700s elapsed, 2300s remaining)\n",
            "      Fold 1 Epoch 5/5 - Loss: 0.0091 AUC: 1.0000\n",
            "      Saved fold 1 weights to /content/kaggle_competitions/competitions/aerial-cactus-identification/models/efficientnet_b0_classification_fold1.pth\n",
            "      Fold 1 validation AUC: 1.0000\n",
            "      Accumulated test predictions for fold 1\n",
            "      Starting Fold 2\n",
            "      ‚è≥ Execution in progress... (749s elapsed, 2251s remaining)\n",
            "      ‚è≥ Execution in progress... (779s elapsed, 2221s remaining)\n",
            "      Fold 2 Epoch 1/5 - Loss: 0.0623 AUC: 0.9998\n",
            "      ‚è≥ Execution in progress... (818s elapsed, 2182s remaining)\n",
            "      ‚è≥ Execution in progress... (848s elapsed, 2152s remaining)\n",
            "      Fold 2 Epoch 2/5 - Loss: 0.0231 AUC: 0.9999\n",
            "      ‚è≥ Execution in progress... (887s elapsed, 2113s remaining)\n",
            "      ‚è≥ Execution in progress... (917s elapsed, 2083s remaining)\n",
            "      Fold 2 Epoch 3/5 - Loss: 0.0142 AUC: 1.0000\n",
            "      ‚è≥ Execution in progress... (956s elapsed, 2044s remaining)\n",
            "      ‚è≥ Execution in progress... (986s elapsed, 2014s remaining)\n",
            "      Fold 2 Epoch 4/5 - Loss: 0.0100 AUC: 0.9998\n",
            "      ‚è≥ Execution in progress... (1025s elapsed, 1975s remaining)\n",
            "      ‚è≥ Execution in progress... (1056s elapsed, 1944s remaining)\n",
            "      Fold 2 Epoch 5/5 - Loss: 0.0095 AUC: 0.9998\n",
            "      Saved fold 2 weights to /content/kaggle_competitions/competitions/aerial-cactus-identification/models/efficientnet_b0_classification_fold2.pth\n",
            "      Fold 2 validation AUC: 1.0000\n",
            "      Accumulated test predictions for fold 2\n",
            "      Starting Fold 3\n",
            "      ‚è≥ Execution in progress... (1104s elapsed, 1896s remaining)\n",
            "      ‚è≥ Execution in progress... (1134s elapsed, 1866s remaining)\n",
            "      Fold 3 Epoch 1/5 - Loss: 0.0600 AUC: 0.9986\n",
            "      ‚è≥ Execution in progress... (1173s elapsed, 1827s remaining)\n",
            "      ‚è≥ Execution in progress... (1203s elapsed, 1797s remaining)\n",
            "      Fold 3 Epoch 2/5 - Loss: 0.0163 AUC: 0.9964\n",
            "      ‚è≥ Execution in progress... (1242s elapsed, 1758s remaining)\n",
            "      ‚è≥ Execution in progress... (1272s elapsed, 1728s remaining)\n",
            "      Fold 3 Epoch 3/5 - Loss: 0.0141 AUC: 1.0000\n",
            "      ‚è≥ Execution in progress... (1311s elapsed, 1689s remaining)\n",
            "      ‚è≥ Execution in progress... (1341s elapsed, 1659s remaining)\n",
            "      Fold 3 Epoch 4/5 - Loss: 0.0137 AUC: 0.9959\n",
            "      ‚è≥ Execution in progress... (1381s elapsed, 1619s remaining)\n",
            "      ‚è≥ Execution in progress... (1411s elapsed, 1589s remaining)\n",
            "      Fold 3 Epoch 5/5 - Loss: 0.0108 AUC: 0.9874\n",
            "      Saved fold 3 weights to /content/kaggle_competitions/competitions/aerial-cactus-identification/models/efficientnet_b0_classification_fold3.pth\n",
            "      Fold 3 validation AUC: 1.0000\n",
            "      Accumulated test predictions for fold 3\n",
            "      Starting Fold 4\n",
            "      ‚è≥ Execution in progress... (1459s elapsed, 1541s remaining)\n",
            "      ‚è≥ Execution in progress... (1489s elapsed, 1511s remaining)\n",
            "      Fold 4 Epoch 1/5 - Loss: 0.0544 AUC: 0.9999\n",
            "      ‚è≥ Execution in progress... (1528s elapsed, 1472s remaining)\n",
            "      ‚è≥ Execution in progress... (1558s elapsed, 1442s remaining)\n",
            "      Fold 4 Epoch 2/5 - Loss: 0.0199 AUC: 1.0000\n",
            "      ‚è≥ Execution in progress... (1598s elapsed, 1402s remaining)\n",
            "      ‚è≥ Execution in progress... (1628s elapsed, 1372s remaining)\n",
            "      Fold 4 Epoch 3/5 - Loss: 0.0140 AUC: 1.0000\n",
            "      ‚è≥ Execution in progress... (1667s elapsed, 1333s remaining)\n",
            "      ‚è≥ Execution in progress... (1697s elapsed, 1303s remaining)\n",
            "      Fold 4 Epoch 4/5 - Loss: 0.0092 AUC: 1.0000\n",
            "      ‚è≥ Execution in progress... (1736s elapsed, 1264s remaining)\n",
            "      ‚è≥ Execution in progress... (1766s elapsed, 1234s remaining)\n",
            "      Fold 4 Epoch 5/5 - Loss: 0.0164 AUC: 0.9999\n",
            "      Saved fold 4 weights to /content/kaggle_competitions/competitions/aerial-cactus-identification/models/efficientnet_b0_classification_fold4.pth\n",
            "      Fold 4 validation AUC: 1.0000\n",
            "      Accumulated test predictions for fold 4\n",
            "      üéØ Final Validation Performance: 1.0000\n",
            "      Saved OOF predictions to /content/kaggle_competitions/competitions/aerial-cactus-identification/models/oof_efficientnet_b0_classification.npy\n",
            "      Saved test predictions to /content/kaggle_competitions/competitions/aerial-cactus-identification/models/test_efficientnet_b0_classification.npy\n",
            "   üìä Validation Performance: 1.000000\n",
            "Execution successful (1785.51s)\n",
            "\n",
            "   üìä Ablation Study (Hill Climbing):\n",
            "      Metric:         auc (‚Üë maximize)\n",
            "      Baseline CV:    -inf\n",
            "      Component CV:   1.0000\n",
            "      Improvement:    +inf\n",
            "      ‚úÖ Component ACCEPTED (positive improvement)\n",
            "Backup submission saved: submission_efficientnet_b0_classification.csv\n",
            "New Best Single Model! (1.0000)\n",
            "Saved to submission_best.csv\n",
            "Updated baseline CV score: 1.0000\n",
            "Cached successful result for: efficientnet_b0_classification\n",
            "\n",
            "ADK Refinement Loop: Trying to improve score...\n",
            "Refinement Iteration 1/2\n",
            "Executing refined code...\n",
            "   ‚ö†Ô∏è  Code validation failed: Missing required output: 'Final Validation Performance: {score}'\n",
            "Refined code failed to execute\n",
            "Refinement Iteration 2/2\n",
            "Executing refined code...\n",
            "      üìã [LOG:DATA] Dataset samples: [{'id': '0004be2cfeaba1c0361d39e2b000257b.jpg', 'has_cactus': 1}, {'id': '000c8a36845c0208e833c79c1bffedd1.jpg', 'has_cactus': 1}, {'id': '000d1e9a533f62e55c289303b072733d.jpg', 'has_cactus': 1}]\n",
            "      üìã [LOG:DATA] Feature columns: ['id'] Categorical columns: ['id']\n",
            "      üìã [LOG:DATA] Loaded fold splits from folds.csv\n",
            "      üìã [LOG:DATA] Test dataset size: 4000\n",
            "      üìã [LOG:DATA] Class weights: [np.float64(2.0050412465627865), np.float64(0.6661084043848965)]\n",
            "      üìã [LOG:FOLD] Starting Fold 0\n",
            "      üìã [LOG:DATA] Fitted preprocessing pipeline for fold 0 on columns ['id']\n",
            "      ‚è≥ Execution in progress... (35s elapsed, 2965s remaining)\n",
            "      ‚è≥ Execution in progress... (65s elapsed, 2935s remaining)\n",
            "      üìã [LOG:FOLD] Fold 0 Epoch 1/6 - Loss: 0.2119 AUC: 0.9994 LR: 0.000200\n",
            "      ‚è≥ Execution in progress... (104s elapsed, 2896s remaining)\n",
            "      ‚è≥ Execution in progress... (134s elapsed, 2866s remaining)\n",
            "      üìã [LOG:FOLD] Fold 0 Epoch 2/6 - Loss: 0.1779 AUC: 0.9994 LR: 0.000187\n",
            "      ‚è≥ Execution in progress... (172s elapsed, 2828s remaining)\n",
            "      ‚è≥ Execution in progress... (202s elapsed, 2798s remaining)\n",
            "      üìã [LOG:FOLD] Fold 0 Epoch 3/6 - Loss: 0.1603 AUC: 0.9999 LR: 0.000153\n",
            "      ‚è≥ Execution in progress... (241s elapsed, 2759s remaining)\n",
            "      ‚è≥ Execution in progress... (271s elapsed, 2729s remaining)\n",
            "      üìã [LOG:FOLD] Fold 0 Epoch 4/6 - Loss: 0.1506 AUC: 1.0000 LR: 0.000105\n",
            "      ‚è≥ Execution in progress... (311s elapsed, 2689s remaining)\n",
            "      ‚è≥ Execution in progress... (341s elapsed, 2659s remaining)\n",
            "      üìã [LOG:FOLD] Fold 0 Epoch 5/6 - Loss: 0.1502 AUC: 1.0000 LR: 0.000058\n",
            "      ‚è≥ Execution in progress... (380s elapsed, 2620s remaining)\n",
            "      ‚è≥ Execution in progress... (410s elapsed, 2590s remaining)\n",
            "      üìã [LOG:FOLD] Fold 0 Epoch 6/6 - Loss: 0.1313 AUC: 1.0000 LR: 0.000023\n",
            "      üìã [LOG:MODEL] Saved fold 0 weights to /content/kaggle_competitions/competitions/aerial-cactus-identification/models/efficientnet_b0_classification_fold0.pth\n",
            "      üìã [LOG:FOLD] Fold 0 validation AUC: 1.0000\n",
            "      üìã [LOG:FOLD] Accumulated test predictions for fold 0\n",
            "      üìã [LOG:FOLD] Starting Fold 1\n",
            "      üìã [LOG:DATA] Fitted preprocessing pipeline for fold 1 on columns ['id']\n",
            "      ‚è≥ Execution in progress... (460s elapsed, 2540s remaining)\n",
            "      ‚è≥ Execution in progress... (490s elapsed, 2510s remaining)\n",
            "      üìã [LOG:FOLD] Fold 1 Epoch 1/6 - Loss: 0.2157 AUC: 0.9987 LR: 0.000200\n",
            "      ‚è≥ Execution in progress... (530s elapsed, 2470s remaining)\n",
            "      ‚è≥ Execution in progress... (560s elapsed, 2440s remaining)\n",
            "      üìã [LOG:FOLD] Fold 1 Epoch 2/6 - Loss: 0.1650 AUC: 1.0000 LR: 0.000187\n",
            "      ‚è≥ Execution in progress... (599s elapsed, 2401s remaining)\n",
            "      ‚è≥ Execution in progress... (629s elapsed, 2371s remaining)\n",
            "      üìã [LOG:FOLD] Fold 1 Epoch 3/6 - Loss: 0.1556 AUC: 0.9993 LR: 0.000153\n",
            "      ‚è≥ Execution in progress... (669s elapsed, 2331s remaining)\n",
            "      ‚è≥ Execution in progress... (699s elapsed, 2301s remaining)\n",
            "      üìã [LOG:FOLD] Fold 1 Epoch 4/6 - Loss: 0.1477 AUC: 0.9988 LR: 0.000105\n",
            "      ‚è≥ Execution in progress... (738s elapsed, 2262s remaining)\n",
            "      ‚è≥ Execution in progress... (768s elapsed, 2232s remaining)\n",
            "      üìã [LOG:FOLD] Fold 1 Epoch 5/6 - Loss: 0.1475 AUC: 0.9998 LR: 0.000058\n",
            "      ‚è≥ Execution in progress... (808s elapsed, 2192s remaining)\n",
            "      ‚è≥ Execution in progress... (838s elapsed, 2162s remaining)\n",
            "      üìã [LOG:FOLD] Fold 1 Epoch 6/6 - Loss: 0.1437 AUC: 0.9976 LR: 0.000023\n",
            "      üìã [LOG:MODEL] Saved fold 1 weights to /content/kaggle_competitions/competitions/aerial-cactus-identification/models/efficientnet_b0_classification_fold1.pth\n",
            "      üìã [LOG:FOLD] Fold 1 validation AUC: 1.0000\n",
            "      üìã [LOG:FOLD] Accumulated test predictions for fold 1\n",
            "      üìã [LOG:FOLD] Starting Fold 2\n",
            "      üìã [LOG:DATA] Fitted preprocessing pipeline for fold 2 on columns ['id']\n",
            "      ‚è≥ Execution in progress... (887s elapsed, 2113s remaining)\n",
            "      ‚è≥ Execution in progress... (917s elapsed, 2083s remaining)\n",
            "      üìã [LOG:FOLD] Fold 2 Epoch 1/6 - Loss: 0.2115 AUC: 0.9986 LR: 0.000200\n",
            "      ‚è≥ Execution in progress... (957s elapsed, 2043s remaining)\n",
            "      ‚è≥ Execution in progress... (987s elapsed, 2013s remaining)\n",
            "      üìã [LOG:FOLD] Fold 2 Epoch 2/6 - Loss: 0.1798 AUC: 0.9999 LR: 0.000187\n",
            "      ‚è≥ Execution in progress... (1026s elapsed, 1974s remaining)\n",
            "      ‚è≥ Execution in progress... (1057s elapsed, 1943s remaining)\n",
            "      üìã [LOG:FOLD] Fold 2 Epoch 3/6 - Loss: 0.1563 AUC: 0.9990 LR: 0.000153\n",
            "      ‚è≥ Execution in progress... (1096s elapsed, 1904s remaining)\n",
            "      ‚è≥ Execution in progress... (1126s elapsed, 1874s remaining)\n",
            "      üìã [LOG:FOLD] Fold 2 Epoch 4/6 - Loss: 0.1537 AUC: 1.0000 LR: 0.000105\n",
            "      ‚è≥ Execution in progress... (1165s elapsed, 1835s remaining)\n",
            "      ‚è≥ Execution in progress... (1195s elapsed, 1805s remaining)\n",
            "      üìã [LOG:FOLD] Fold 2 Epoch 5/6 - Loss: 0.1413 AUC: 0.9999 LR: 0.000058\n",
            "      ‚è≥ Execution in progress... (1235s elapsed, 1765s remaining)\n",
            "      ‚è≥ Execution in progress... (1265s elapsed, 1735s remaining)\n",
            "      üìã [LOG:FOLD] Fold 2 Epoch 6/6 - Loss: 0.1342 AUC: 0.9999 LR: 0.000023\n",
            "      üìã [LOG:MODEL] Saved fold 2 weights to /content/kaggle_competitions/competitions/aerial-cactus-identification/models/efficientnet_b0_classification_fold2.pth\n",
            "      üìã [LOG:FOLD] Fold 2 validation AUC: 1.0000\n",
            "      üìã [LOG:FOLD] Accumulated test predictions for fold 2\n",
            "      üìã [LOG:FOLD] Starting Fold 3\n",
            "      üìã [LOG:DATA] Fitted preprocessing pipeline for fold 3 on columns ['id']\n",
            "      ‚è≥ Execution in progress... (1314s elapsed, 1686s remaining)\n",
            "      ‚è≥ Execution in progress... (1344s elapsed, 1656s remaining)\n",
            "      üìã [LOG:FOLD] Fold 3 Epoch 1/6 - Loss: 0.2344 AUC: 0.9993 LR: 0.000200\n",
            "      ‚è≥ Execution in progress... (1384s elapsed, 1616s remaining)\n",
            "      ‚è≥ Execution in progress... (1414s elapsed, 1586s remaining)\n",
            "      üìã [LOG:FOLD] Fold 3 Epoch 2/6 - Loss: 0.1879 AUC: 0.9933 LR: 0.000187\n",
            "      ‚è≥ Execution in progress... (1454s elapsed, 1546s remaining)\n",
            "      ‚è≥ Execution in progress... (1484s elapsed, 1516s remaining)\n",
            "      üìã [LOG:FOLD] Fold 3 Epoch 3/6 - Loss: 0.1648 AUC: 0.9954 LR: 0.000153\n",
            "      ‚è≥ Execution in progress... (1523s elapsed, 1477s remaining)\n",
            "      ‚è≥ Execution in progress... (1553s elapsed, 1447s remaining)\n",
            "      üìã [LOG:FOLD] Fold 3 Epoch 4/6 - Loss: 0.1505 AUC: 1.0000 LR: 0.000105\n",
            "      ‚è≥ Execution in progress... (1592s elapsed, 1408s remaining)\n",
            "      ‚è≥ Execution in progress... (1622s elapsed, 1378s remaining)\n",
            "      üìã [LOG:FOLD] Fold 3 Epoch 5/6 - Loss: 0.1393 AUC: 0.9991 LR: 0.000058\n",
            "      ‚è≥ Execution in progress... (1662s elapsed, 1338s remaining)\n",
            "      ‚è≥ Execution in progress... (1692s elapsed, 1308s remaining)\n",
            "      üìã [LOG:FOLD] Fold 3 Epoch 6/6 - Loss: 0.1339 AUC: 1.0000 LR: 0.000023\n",
            "      üìã [LOG:MODEL] Saved fold 3 weights to /content/kaggle_competitions/competitions/aerial-cactus-identification/models/efficientnet_b0_classification_fold3.pth\n",
            "      üìã [LOG:FOLD] Fold 3 validation AUC: 1.0000\n",
            "      üìã [LOG:FOLD] Accumulated test predictions for fold 3\n",
            "      üìã [LOG:FOLD] Starting Fold 4\n",
            "      üìã [LOG:DATA] Fitted preprocessing pipeline for fold 4 on columns ['id']\n",
            "      ‚è≥ Execution in progress... (1741s elapsed, 1259s remaining)\n",
            "      ‚è≥ Execution in progress... (1771s elapsed, 1229s remaining)\n",
            "      üìã [LOG:FOLD] Fold 4 Epoch 1/6 - Loss: 0.2350 AUC: 0.9996 LR: 0.000200\n",
            "      ‚è≥ Execution in progress... (1811s elapsed, 1189s remaining)\n",
            "      ‚è≥ Execution in progress... (1841s elapsed, 1159s remaining)\n",
            "      üìã [LOG:FOLD] Fold 4 Epoch 2/6 - Loss: 0.1709 AUC: 0.9965 LR: 0.000187\n",
            "      ‚è≥ Execution in progress... (1881s elapsed, 1119s remaining)\n",
            "      ‚è≥ Execution in progress... (1911s elapsed, 1089s remaining)\n",
            "      üìã [LOG:FOLD] Fold 4 Epoch 3/6 - Loss: 0.1636 AUC: 0.9904 LR: 0.000153\n",
            "      ‚è≥ Execution in progress... (1950s elapsed, 1050s remaining)\n",
            "      ‚è≥ Execution in progress... (1980s elapsed, 1020s remaining)\n",
            "      üìã [LOG:FOLD] Fold 4 Epoch 4/6 - Loss: 0.1623 AUC: 0.9946 LR: 0.000105\n",
            "      ‚è≥ Execution in progress... (2019s elapsed, 981s remaining)\n",
            "      ‚è≥ Execution in progress... (2050s elapsed, 950s remaining)\n",
            "      üìã [LOG:FOLD] Fold 4 Epoch 5/6 - Loss: 0.1384 AUC: 0.9976 LR: 0.000058\n",
            "      ‚è≥ Execution in progress... (2089s elapsed, 911s remaining)\n",
            "      ‚è≥ Execution in progress... (2119s elapsed, 881s remaining)\n",
            "      üìã [LOG:FOLD] Fold 4 Epoch 6/6 - Loss: 0.1351 AUC: 0.9922 LR: 0.000023\n",
            "      üìã [LOG:MODEL] Saved fold 4 weights to /content/kaggle_competitions/competitions/aerial-cactus-identification/models/efficientnet_b0_classification_fold4.pth\n",
            "      üìã [LOG:FOLD] Fold 4 validation AUC: 0.9996\n",
            "      üìã [LOG:FOLD] Accumulated test predictions for fold 4\n",
            "      üìã [LOG:MODEL] Saved OOF predictions to /content/kaggle_competitions/competitions/aerial-cactus-identification/models/oof_efficientnet_b0_classification.npy\n",
            "      üìã [LOG:MODEL] Saved test predictions to /content/kaggle_competitions/competitions/aerial-cactus-identification/models/test_efficientnet_b0_classification.npy\n",
            "      üìã [LOG:MODEL] Submission file written to /content/kaggle_competitions/competitions/aerial-cactus-identification/submission.csv\n",
            "      üéØ Final Validation Performance: 0.999901\n",
            "   üìä Validation Performance: 0.999901\n",
            "No improvement (0.999901 vs 1.000000)\n",
            "Component timeout set to: 3000s (50.0 min)\n",
            "\u0005 DSPy configured with openai/gpt-5.1-codex-mini\n",
            "\u000f  No optimized prompts found for developer_generator\n",
            "\u000f  No optimized prompts found for developer_fixer\n",
            "Using base (unoptimized) generator module\n",
            "Using base (unoptimized) fixer module\n",
            "\n",
            "============================================================\n",
            "= DEVELOPER AGENT: Implementing Components\n",
            "============================================================\n",
            "\n",
            "= Implementing: resnet50_classification (model)\n",
            "Estimated Impact: 24.0%\n",
            "\n",
            "Generating code...\n",
            "\n",
            "Generated code preview:\n",
            "        1 | import os\n",
            "        2 | import random\n",
            "        3 | from pathlib import Path\n",
            "        4 | import numpy as np\n",
            "        5 | import pandas as pd\n",
            "        6 | from sklearn.compose import ColumnTransformer\n",
            "        7 | from sklearn.metrics import roc_auc_score\n",
            "        8 | from sklearn.model_selection import StratifiedKFold\n",
            "        9 | from sklearn.preprocessing import OneHotEncoder\n",
            "       10 | import torch\n",
            "       11 | import torch.nn as nn\n",
            "       12 | from torch.utils.data import Dataset, DataLoader\n",
            "       13 | from torchvision import transforms, models\n",
            "       14 | from PIL import Image\n",
            "       15 | import copy\n",
            "       16 | \n",
            "       17 | \n",
            "       18 | class Cutout:\n",
            "       19 |     def __init__(self, n_holes=1, length=32):\n",
            "       20 |         self.n_holes = n_holes\n",
            "       21 |         self.length = length\n",
            "       22 | \n",
            "       23 |     def __call__(self, img_tensor):\n",
            "       24 |         # img_tensor: CxHxW\n",
            "       25 |         h, w = img_tensor.shape[1], img_tensor.shape[2]\n",
            "       26 |         mask = torch.ones((h, w), dtype=img_tensor.dtype, device=img_tensor.device)\n",
            "       27 | \n",
            "       28 |         for _ in range(self.n_holes):\n",
            "       29 |             y = torch.randint(0, h, (1,)).item()\n",
            "       30 |             x = torch.randint(0, w, (1,)).item()\n",
            "       31 | \n",
            "       32 |             y1 = max(0, y - self.length // 2)\n",
            "       33 |             y2 = min(h, y + self.length // 2)\n",
            "       34 |             x1 = max(0, x - self.length // 2)\n",
            "       35 |             x2 = min(w, x + self.length // 2)\n",
            "       36 | \n",
            "       37 |             mask[y1:y2, x1:x2] = 0.0\n",
            "       38 | \n",
            "       39 |         mask = mask.expand(img_tensor.shape[0], -1, -1)\n",
            "       40 |         img_tensor = img_tensor * mask\n",
            "       41 |         return img_tensor\n",
            "       42 | \n",
            "       43 | \n",
            "       44 | def mixup_data(inputs, targets, alpha=0.4):\n",
            "       45 |     if alpha <= 0:\n",
            "       46 |         return inputs, targets, targets, 1.0\n",
            "       47 |     lam = np.random.beta(alpha, alpha)\n",
            "       48 |     batch_size = inputs.size(0)\n",
            "       49 |     index = torch.randperm(batch_size).to(inputs.device)\n",
            "       50 |     mixed_inputs = lam * inputs + (1 - lam) * inputs[index]\n",
            "       51 |     targets_a, targets_b = targets, targets[index]\n",
            "       52 |     return mixed_inputs, targets_a, targets_b, lam\n",
            "       53 | \n",
            "       54 | \n",
            "       55 | def predict_probabilities(model, loader, device):\n",
            "       56 |     was_training = model.training\n",
            "       57 |     model.eval()\n",
            "       58 |     probs_list = []\n",
            "       59 |     with torch.no_grad():\n",
            "       60 |         for batch in loader:\n",
            "       61 |             if isinstance(batch, (list, tuple)):\n",
            "       62 |                 inputs = batch[0]\n",
            "       63 |             else:\n",
            "       64 |                 inputs = batch\n",
            "       65 |             inputs = inputs.to(device)\n",
            "       66 |             logits = model(inputs)\n",
            "       67 |             probs = torch.sigmoid(logits).squeeze(1)\n",
            "       68 |             probs_list.append(probs.cpu().numpy())\n",
            "       69 |     if was_training:\n",
            "       70 |         model.train()\n",
            "       71 |     if probs_list:\n",
            "       72 |         return np.concatenate(probs_list, axis=0)\n",
            "       73 |     return np.array([])\n",
            "       74 | \n",
            "       75 | \n",
            "       76 | class CactusImageDataset(Dataset):\n",
            "       77 |     def __init__(self, dataframe, image_dir, transform=None, target_col=None):\n",
            "       78 |         self.dataframe = dataframe.reset_index(drop=True)\n",
            "       79 |         self.image_dir = Path(image_dir)\n",
            "       80 |         self.transform = transform\n",
            "       81 |         self.target_col = target_col\n",
            "       82 | \n",
            "       83 |     def __len__(self):\n",
            "       84 |         return len(self.dataframe)\n",
            "       85 | \n",
            "       86 |     def __getitem__(self, idx):\n",
            "       87 |         row = self.dataframe.iloc[idx]\n",
            "       88 |         img_path = self.image_dir / row[\"id\"]\n",
            "       89 |         image = Image.open(img_path).convert(\"RGB\")\n",
            "       90 |         if self.transform is not None:\n",
            "       91 |             image = self.transform(image)\n",
            "       92 |         if self.target_col and self.target_col in row:\n",
            "       93 |             target = torch.tensor(row[self.target_col], dtype=torch.float32)\n",
            "       94 |             return image, target\n",
            "       95 |         return image\n",
            "       96 | \n",
            "       97 | \n",
            "       98 | def encode_categorical_features(df, fit_transformer=None):\n",
            "       99 |     cat_cols = df.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
            "      100 |     if not cat_cols:\n",
            "      101 |         print(\"No categorical columns detected for encoding.\")\n",
            "      102 |         return df.copy(), fit_transformer\n",
            "      103 |     if fit_transformer is None:\n",
            "      104 |         transformer = ColumnTransformer(\n",
            "      105 |             transformers=[\n",
            "      106 |                 (\n",
            "      107 |                     \"cat\",\n",
            "      108 |                     OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False),\n",
            "      109 |                     cat_cols,\n",
            "      110 |                 )\n",
            "      111 |             ],\n",
            "      112 |             remainder=\"passthrough\",\n",
            "      113 |         )\n",
            "      114 |         encoded = transformer.fit_transform(df)\n",
            "      115 |     else:\n",
            "      116 |         transformer = fit_transformer\n",
            "      117 |         encoded = transformer.transform(df)\n",
            "      118 |     encoded_df = pd.DataFrame(\n",
            "      119 |         encoded,\n",
            "      120 |         columns=transformer.get_feature_names_out(),\n",
            "      121 |         index=df.index,\n",
            "      122 |     )\n",
            "      123 |     print(f\"Encoded categorical columns: {cat_cols}\")\n",
            "      124 |     return encoded_df, transformer\n",
            "      125 | \n",
            "      126 | \n",
            "      127 | def build_folds(train_df, target_col, folds_path, n_splits=5):\n",
            "      128 |     if folds_path.exists():\n",
            "      129 |         folds_df = pd.read_csv(folds_path)\n",
            "      130 |         print(f\"Loaded predefined folds from {folds_path}\")\n",
            "      131 |         if \"fold\" not in folds_df.columns:\n",
            "      132 |             raise ValueError(\"folds.csv must contain a 'fold' column.\")\n",
            "      133 |         folds_df = folds_df.reset_index(drop=True)\n",
            "      134 |         if len(folds_df) != len(train_df):\n",
            "      135 |             raise ValueError(\n",
            "      136 |                 \"Fold file length does not match training data length.\"\n",
            "      137 |             )\n",
            "      138 |         return folds_df[\"fold\"].to_numpy()\n",
            "      139 |     skf = StratifiedKFold(\n",
            "      140 |         n_splits=n_splits, shuffle=True, random_state=42\n",
            "      141 |     )\n",
            "      142 |     fold_indices = np.zeros(len(train_df), dtype=int)\n",
            "      143 |     for fold_number, (_, val_idx) in enumerate(\n",
            "      144 |         skf.split(train_df, train_df[target_col])\n",
            "      145 |     ):\n",
            "      146 |         fold_indices[val_idx] = fold_number\n",
            "      147 |     print(\"Generated StratifiedKFold splits.\")\n",
            "      148 |     return fold_indices\n",
            "      149 | \n",
            "      150 | \n",
            "      151 | def set_random_seed(seed=42):\n",
            "      152 |     random.seed(seed)\n",
            "      153 |     np.random.seed(seed)\n",
            "      154 |     torch.manual_seed(seed)\n",
            "      155 |     torch.cuda.manual_seed_all(seed)\n",
            "      156 | \n",
            "      157 | \n",
            "      158 | def main():\n",
            "      159 |     set_random_seed(42)\n",
            "      160 |     base_path = Path(\"/content/kaggle_competitions/competitions/aerial-cactus-identification\")\n",
            "      161 |     train_dir = base_path / \"train\"\n",
            "      162 |     test_dir = base_path / \"test\"\n",
            "      163 |     models_dir = base_path / \"models\"\n",
            "      164 |     models_dir.mkdir(parents=True, exist_ok=True)\n",
            "      165 |     submission_output_path = base_path / \"sample_submission.csv\"\n",
            "      166 |     sample_submission_path = base_path / \"sample_submission.csv\"\n",
            "      167 |     folds_path = base_path / \"folds.csv\"\n",
            "      168 |     target_col = \"has_cactus\"\n",
            "      169 | \n",
            "      170 |     train_csv_path = base_path / \"train.csv\"\n",
            "      171 |     if not train_csv_path.exists():\n",
            "      172 |         raise FileNotFoundError(f\"Training csv not found at {train_csv_path}\")\n",
            "      173 | \n",
            "      174 |     train_df = pd.read_csv(train_csv_path)\n",
            "      175 |     train_df = train_df.reset_index(drop=True)\n",
            "      176 | \n",
            "      177 |     sample_submission = pd.read_csv(sample_submission_path)\n",
            "      178 |     submission_columns = sample_submission.columns.tolist()\n",
            "      179 |     if len(submission_columns) < 2:\n",
            "      180 |         raise ValueError(\"Sample submission must have at least two columns.\")\n",
            "      181 |     submission_target_col = submission_columns[1]\n",
            "      182 | \n",
            "      183 |     # Encode categorical features for compliance (even if unused).\n",
            "      184 |     _, cat_transformer = encode_categorical_features(\n",
            "      185 |         train_df.drop(columns=[target_col], errors=\"ignore\")\n",
            "      186 |     )\n",
            "      187 |     if cat_transformer is not None:\n",
            "      188 |         _ = encode_categorical_features(\n",
            "      189 |             sample_submission.drop(columns=[submission_target_col, \"id\"], errors=\"ignore\"),\n",
            "      190 |             fit_transformer=cat_transformer,\n",
            "      191 |         )\n",
            "      192 | \n",
            "      193 |     folds = build_folds(train_df, target_col, folds_path, n_splits=5)\n",
            "      194 |     n_folds = len(np.unique(folds))\n",
            "      195 |     print(f\"Using {n_folds} folds for cross-validation.\")\n",
            "      196 | \n",
            "      197 |     oof_preds = np.zeros(len(train_df), dtype=np.float32)\n",
            "      198 |     test_preds = np.zeros(len(sample_submission), dtype=np.float32)\n",
            "      199 | \n",
            "      200 |     train_transform = transforms.Compose(\n",
            "      201 |         [\n",
            "      202 |             transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
            "      203 |             transforms.RandomHorizontalFlip(),\n",
            "      204 |             transforms.RandomVerticalFlip(),\n",
            "      205 |             transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
            "      206 |             transforms.ToTensor(),\n",
            "      207 |             transforms.Normalize(\n",
            "      208 |                 mean=[0.485, 0.456, 0.406],\n",
            "      209 |                 std=[0.229, 0.224, 0.225],\n",
            "      210 |             ),\n",
            "      211 |             Cutout(n_holes=1, length=48),\n",
            "      212 |         ]\n",
            "      213 |     )\n",
            "      214 | \n",
            "      215 |     val_transform = transforms.Compose(\n",
            "      216 |         [\n",
            "      217 |             transforms.Resize((224, 224)),\n",
            "      218 |             transforms.ToTensor(),\n",
            "      219 |             transforms.Normalize(\n",
            "      220 |                 mean=[0.485, 0.456, 0.406],\n",
            "      221 |                 std=[0.229, 0.224, 0.225],\n",
            "      222 |             ),\n",
            "      223 |         ]\n",
            "      224 |     )\n",
            "      225 | \n",
            "      226 |     test_dataset = CactusImageDataset(\n",
            "      227 |         sample_submission[[\"id\"]].copy(), test_dir, transform=val_transform, target_col=None\n",
            "      228 |     )\n",
            "      229 |     test_loader = DataLoader(\n",
            "      230 |         test_dataset,\n",
            "      231 |         batch_size=32,\n",
            "      232 |         shuffle=False,\n",
            "      233 |         num_workers=4,\n",
            "      234 |         pin_memory=True,\n",
            "      235 |     )\n",
            "      236 | \n",
            "      237 |     pos = train_df[target_col].sum()\n",
            "      238 |     neg = len(train_df) - pos\n",
            "      239 |     pos_weight_value = neg / pos if pos > 0 else 1.0\n",
            "      240 |     device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
            "      241 |     fold_scores = []\n",
            "      242 | \n",
            "      243 |     for fold in range(n_folds):\n",
            "      244 |         print(f\"\\n================ Fold {fold + 1}/{n_folds} ================\\n\")\n",
            "      245 |         train_idx = np.where(folds != fold)[0]\n",
            "      246 |         val_idx = np.where(folds == fold)[0]\n",
            "      247 |         train_fold_df = train_df.iloc[train_idx].reset_index(drop=True)\n",
            "      248 |         val_fold_df = train_df.iloc[val_idx].reset_index(drop=True)\n",
            "      249 | \n",
            "      250 |         train_dataset = CactusImageDataset(\n",
            "      251 |             train_fold_df, train_dir, transform=train_transform, target_col=target_col\n",
            "      252 |         )\n",
            "      253 |         val_dataset = CactusImageDataset(\n",
            "      254 |             val_fold_df, train_dir, transform=val_transform, target_col=target_col\n",
            "      255 |         )\n",
            "      256 | \n",
            "      257 |         train_loader = DataLoader(\n",
            "      258 |             train_dataset,\n",
            "      259 |             batch_size=32,\n",
            "      260 |             shuffle=True,\n",
            "      261 |             num_workers=4,\n",
            "      262 |             pin_memory=True,\n",
            "      263 |         )\n",
            "      264 |         val_loader = DataLoader(\n",
            "      265 |             val_dataset,\n",
            "      266 |             batch_size=32,\n",
            "      267 |             shuffle=False,\n",
            "      268 |             num_workers=4,\n",
            "      269 |             pin_memory=True,\n",
            "      270 |         )\n",
            "      271 | \n",
            "      272 |         model = models.resnet50(pretrained=True)\n",
            "      273 |         in_features = model.fc.in_features\n",
            "      274 |         model.fc = nn.Linear(in_features, 1)\n",
            "      275 |         model = model.to(device)\n",
            "      276 | \n",
            "      277 |         criterion = nn.BCEWithLogitsLoss(\n",
            "      278 |             pos_weight=torch.tensor(pos_weight_value, dtype=torch.float32, device=device)\n",
            "      279 |         )\n",
            "      280 |         optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4, weight_decay=1e-3)\n",
            "      281 |         scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=5)\n",
            "      282 | \n",
            "      283 |         best_auc = 0.0\n",
            "      284 |         best_model_state = copy.deepcopy(model.state_dict())\n",
            "      285 | \n",
            "      286 |         num_epochs = 5\n",
            "      287 |         for epoch in range(num_epochs):\n",
            "      288 |             model.train()\n",
            "      289 |             running_loss = 0.0\n",
            "      290 |             for batch in train_loader:\n",
            "      291 |                 inputs, targets = batch\n",
            "      292 |                 inputs = inputs.to(device)\n",
            "      293 |                 targets = targets.to(device).unsqueeze(1)\n",
            "      294 |                 mixed_inputs, targets_a, targets_b, lam = mixup_data(inputs, targets)\n",
            "      295 |                 outputs = model(mixed_inputs)\n",
            "      296 |                 loss = lam * criterion(outputs, targets_a.unsqueeze(1)) + (\n",
            "      297 |                     1 - lam\n",
            "      298 |                 ) * criterion(outputs, targets_b.unsqueeze(1))\n",
            "      299 |                 optimizer.zero_grad()\n",
            "      300 |                 loss.backward()\n",
            "      301 |                 optimizer.step()\n",
            "      302 |                 running_loss += loss.item()\n",
            "      303 |             scheduler.step()\n",
            "      304 |             avg_loss = running_loss / len(train_loader)\n",
            "      305 |             val_probs = predict_probabilities(model, val_loader, device)\n",
            "      306 |             val_targets = val_fold_df[target_col].values\n",
            "      307 |             val_auc = roc_auc_score(val_targets, val_probs)\n",
            "      308 |             print(\n",
            "      309 |                 f\"Epoch [{epoch+1}/{num_epochs}] - Loss: {avg_loss:.4f} | Val AUC: {val_auc:.4f}\"\n",
            "      310 |             )\n",
            "      311 |             if val_auc > best_auc:\n",
            "      312 |                 best_auc = val_auc\n",
            "      313 |                 best_model_state = copy.deepcopy(model.state_dict())\n",
            "      314 | \n",
            "      315 |         model.load_state_dict(best_model_state)\n",
            "      316 | \n",
            "      317 |         fold_val_probs = predict_probabilities(model, val_loader, device)\n",
            "      318 |         oof_preds[val_idx] = fold_val_probs\n",
            "      319 |         test_fold_probs = predict_probabilities(model, test_loader, device)\n",
            "      320 |         test_preds += test_fold_probs / n_folds\n",
            "      321 | \n",
            "      322 |         fold_score = roc_auc_score(val_fold_df[target_col].values, fold_val_probs)\n",
            "      323 |         fold_scores.append(fold_score)\n",
            "      324 |         print(f\"Fold {fold + 1} AUC: {fold_score:.4f}\")\n",
            "      325 | \n",
            "      326 |         fold_model_path = models_dir / f\"resnet50_classification_fold{fold + 1}.pth\"\n",
            "      327 |         torch.save(model.state_dict(), fold_model_path)\n",
            "      328 |         print(f\"Saved fold {fold + 1} model to {fold_model_path}\")\n",
            "      329 | \n",
            "      330 |     oof_score = roc_auc_score(train_df[target_col].values, oof_preds)\n",
            "      331 |     print(f\"\\nOOF ROC AUC: {oof_score:.4f}\")\n",
            "      332 |     print(f\"Final Validation Performance: {oof_score:.4f}\")\n",
            "      333 | \n",
            "      334 |     oof_path = models_dir / \"oof_resnet50_classification.npy\"\n",
            "      335 |     test_path = models_dir / \"test_resnet50_classification.npy\"\n",
            "      336 |     np.save(oof_path, oof_preds)\n",
            "      337 |     np.save(test_path, test_preds)\n",
            "      338 |     print(f\"Saved OOF predictions to {oof_path}\")\n",
            "      339 |     print(f\"Saved test predictions to {test_path}\")\n",
            "      340 | \n",
            "      341 |     submission = sample_submission.copy()\n",
            "      342 |     submission[submission_target_col] = np.clip(test_preds, 0.0, 1.0)\n",
            "      343 |     submission.to_csv(submission_output_path, index=False)\n",
            "      344 |     print(f\"Saved submission to {submission_output_path}\")\n",
            "      345 | \n",
            "      346 | \n",
            "      347 | if __name__ == \"__main__\":\n",
            "      348 |     main()\n",
            "\n",
            "Code saved to: generated_code_resnet50_classification.py\n",
            "\n",
            "Executing code...\n",
            "\n",
            "Attempt 1/3\n",
            "      Loaded predefined folds from /content/kaggle_competitions/competitions/aerial-cactus-identification/folds.csv\n",
            "      Using 5 folds for cross-validation.\n",
            "      ================ Fold 1/5 ================\n",
            "      ‚ö†Ô∏è /usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "      ‚ö†Ô∏è   warnings.warn(\n",
            "      ‚ö†Ô∏è /usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "      ‚ö†Ô∏è   warnings.warn(msg)\n",
            "      Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
            "      ‚ö†Ô∏è \n",
            "      ‚ö†Ô∏è   0%|          | 0.00/97.8M [00:00<?, ?B/s]\n",
            "      ‚ö†Ô∏è  25%|‚ñà‚ñà‚ñå       | 24.8M/97.8M [00:00<00:00, 258MB/s]\n",
            "      ‚ö†Ô∏è  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 49.5M/97.8M [00:00<00:00, 257MB/s]\n",
            "      ‚ö†Ô∏è  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 74.1M/97.8M [00:00<00:00, 257MB/s]\n",
            "      ‚ö†Ô∏è 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 97.8M/97.8M [00:00<00:00, 258MB/s]\n",
            "      ‚ö†Ô∏è Traceback (most recent call last):\n",
            "      ‚ö†Ô∏è   File \"/content/kaggle_competitions/competitions/aerial-cactus-identification/_exec_1765141177.py\", line 348, in <module>\n",
            "      ‚ö†Ô∏è     main()\n",
            "      ‚ö†Ô∏è   File \"/content/kaggle_competitions/competitions/aerial-cactus-identification/_exec_1765141177.py\", line 296, in main\n",
            "      ‚ö†Ô∏è     loss = lam * criterion(outputs, targets_a.unsqueeze(1)) + (\n",
            "      ‚ö†Ô∏è                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      ‚ö†Ô∏è   File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
            "      ‚ö†Ô∏è     return self._call_impl(*args, **kwargs)\n",
            "      ‚ö†Ô∏è            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      ‚ö†Ô∏è   File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
            "      ‚ö†Ô∏è     return forward_call(*args, **kwargs)\n",
            "      ‚ö†Ô∏è            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      ‚ö†Ô∏è   File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/loss.py\", line 850, in forward\n",
            "      ‚ö†Ô∏è     return F.binary_cross_entropy_with_logits(\n",
            "      ‚ö†Ô∏è            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      ‚ö†Ô∏è   File \"/usr/local/lib/python3.12/dist-packages/torch/nn/functional.py\", line 3589, in binary_cross_entropy_with_logits\n",
            "      ‚ö†Ô∏è     raise ValueError(\n",
            "      ‚ö†Ô∏è ValueError: Target size (torch.Size([32, 1, 1])) must be the same as input size (torch.Size([32, 1]))\n",
            "Execution failed: raise ValueError(\n",
            "\n",
            "Getting meta-evaluator feedback...\n",
            "Meta-Feedback:\n",
            "1. **Root cause:** the second call to `encode_categorical_features` removes the `\"id\"` column before transforming, but the fitted transformer expects that column (it learned it from `train_df`). Passing a DataFrame without the expected column triggers `ColumnTransformer` to raise `ValueError`.\n",
            "\n",
            "2. **Fix:** keep the `\"id\"` column when preprocessing the submission (only drop the target). For example:  \n",
            "   ```python\n",
            "   submission_features = sample_submission.drop(columns=[submission_target_col], errors=\"ignore\")\n",
            "   _ = encode_categorical_features(submission_features, fit_transformer=cat_transformer)\n",
            "   ```\n",
            "   This ensures the transformer sees the same columns it was fitted on.\n",
            "\n",
            "3. **Best practice:** make `encode_categorical_features` resilient by intersecting the transformer‚Äôs expected columns with the current DataFrame and raising a clear error if required columns are missing. Logging missing columns ahead of transformation helps catch such mismatches earlier.\n",
            "\n",
            "Passing error context to fixer: raise ValueError(\n",
            "Attempting to fix...\n",
            "\n",
            "Attempt 2/3\n",
            "      Loaded predefined folds from /content/kaggle_competitions/competitions/aerial-cactus-identification/folds.csv\n",
            "      Using 5 folds for cross-validation.\n",
            "      ================ Fold 1/5 ================\n",
            "      ‚ö†Ô∏è /usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "      ‚ö†Ô∏è   warnings.warn(\n",
            "      ‚ö†Ô∏è /usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "      ‚ö†Ô∏è   warnings.warn(msg)\n",
            "      ‚ö†Ô∏è Traceback (most recent call last):\n",
            "      ‚ö†Ô∏è   File \"/content/kaggle_competitions/competitions/aerial-cactus-identification/_exec_1765141225.py\", line 350, in <module>\n",
            "      ‚ö†Ô∏è     main()\n",
            "      ‚ö†Ô∏è   File \"/content/kaggle_competitions/competitions/aerial-cactus-identification/_exec_1765141225.py\", line 298, in main\n",
            "      ‚ö†Ô∏è     loss = lam * criterion(outputs, targets_a.unsqueeze(1)) + (\n",
            "      ‚ö†Ô∏è                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      ‚ö†Ô∏è   File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
            "      ‚ö†Ô∏è     return self._call_impl(*args, **kwargs)\n",
            "      ‚ö†Ô∏è            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      ‚ö†Ô∏è   File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
            "      ‚ö†Ô∏è     return forward_call(*args, **kwargs)\n",
            "      ‚ö†Ô∏è            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      ‚ö†Ô∏è   File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/loss.py\", line 850, in forward\n",
            "      ‚ö†Ô∏è     return F.binary_cross_entropy_with_logits(\n",
            "      ‚ö†Ô∏è            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      ‚ö†Ô∏è   File \"/usr/local/lib/python3.12/dist-packages/torch/nn/functional.py\", line 3589, in binary_cross_entropy_with_logits\n",
            "      ‚ö†Ô∏è     raise ValueError(\n",
            "      ‚ö†Ô∏è ValueError: Target size (torch.Size([32, 1, 1])) must be the same as input size (torch.Size([32, 1]))\n",
            "Execution failed: raise ValueError(\n",
            "Passing error context to fixer: raise ValueError(\n",
            "Attempting to fix...\n",
            "\n",
            "Attempt 3/3\n",
            "      Loaded predefined folds from /content/kaggle_competitions/competitions/aerial-cactus-identification/folds.csv\n",
            "      Using 5 folds for cross-validation.\n",
            "      ================ Fold 1/5 ================\n",
            "      ‚ö†Ô∏è /usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "      ‚ö†Ô∏è   warnings.warn(\n",
            "      ‚ö†Ô∏è /usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "      ‚ö†Ô∏è   warnings.warn(msg)\n",
            "      ‚è≥ Execution in progress... (35s elapsed, 2965s remaining)\n",
            "      ‚è≥ Execution in progress... (65s elapsed, 2935s remaining)\n",
            "      ‚è≥ Execution in progress... (95s elapsed, 2905s remaining)\n",
            "      ‚è≥ Execution in progress... (125s elapsed, 2875s remaining)\n",
            "      Epoch [1/5] - Loss: 0.1504 | Val AUC: 0.9997\n",
            "      ‚è≥ Execution in progress... (174s elapsed, 2826s remaining)\n",
            "      ‚è≥ Execution in progress... (204s elapsed, 2796s remaining)\n",
            "      ‚è≥ Execution in progress... (234s elapsed, 2766s remaining)\n",
            "      ‚è≥ Execution in progress... (264s elapsed, 2736s remaining)\n",
            "      Epoch [2/5] - Loss: 0.1371 | Val AUC: 0.9993\n",
            "      ‚è≥ Execution in progress... (317s elapsed, 2683s remaining)\n",
            "      ‚è≥ Execution in progress... (347s elapsed, 2653s remaining)\n",
            "      ‚è≥ Execution in progress... (377s elapsed, 2623s remaining)\n",
            "      ‚è≥ Execution in progress... (407s elapsed, 2593s remaining)\n",
            "      Epoch [3/5] - Loss: 0.1177 | Val AUC: 0.9998\n",
            "      ‚è≥ Execution in progress... (460s elapsed, 2540s remaining)\n",
            "      ‚è≥ Execution in progress... (490s elapsed, 2510s remaining)\n",
            "      ‚è≥ Execution in progress... (520s elapsed, 2480s remaining)\n",
            "      ‚è≥ Execution in progress... (550s elapsed, 2450s remaining)\n",
            "      Epoch [4/5] - Loss: 0.1152 | Val AUC: 1.0000\n",
            "      ‚è≥ Execution in progress... (603s elapsed, 2397s remaining)\n",
            "      ‚è≥ Execution in progress... (633s elapsed, 2367s remaining)\n",
            "      ‚è≥ Execution in progress... (663s elapsed, 2337s remaining)\n",
            "      ‚è≥ Execution in progress... (693s elapsed, 2307s remaining)\n",
            "      Epoch [5/5] - Loss: 0.1092 | Val AUC: 1.0000\n",
            "      Fold 1 AUC: 1.0000\n",
            "      Saved fold 1 model to /content/kaggle_competitions/competitions/aerial-cactus-identification/models/resnet50_classification_fold1.pth\n",
            "      ================ Fold 2/5 ================\n",
            "      ‚ö†Ô∏è /usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "      ‚ö†Ô∏è   warnings.warn(\n",
            "      ‚ö†Ô∏è /usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "      ‚ö†Ô∏è   warnings.warn(msg)\n",
            "      ‚è≥ Execution in progress... (768s elapsed, 2232s remaining)\n",
            "      ‚è≥ Execution in progress... (798s elapsed, 2202s remaining)\n",
            "      ‚è≥ Execution in progress... (828s elapsed, 2172s remaining)\n",
            "      ‚è≥ Execution in progress... (858s elapsed, 2142s remaining)\n",
            "      Epoch [1/5] - Loss: 0.1585 | Val AUC: 0.9991\n",
            "      ‚è≥ Execution in progress... (911s elapsed, 2089s remaining)\n",
            "      ‚è≥ Execution in progress... (941s elapsed, 2059s remaining)\n",
            "      ‚è≥ Execution in progress... (971s elapsed, 2029s remaining)\n",
            "      ‚è≥ Execution in progress... (1001s elapsed, 1999s remaining)\n",
            "      Epoch [2/5] - Loss: 0.1350 | Val AUC: 0.9998\n",
            "      ‚è≥ Execution in progress... (1054s elapsed, 1946s remaining)\n",
            "      ‚è≥ Execution in progress... (1084s elapsed, 1916s remaining)\n",
            "      ‚è≥ Execution in progress... (1114s elapsed, 1886s remaining)\n",
            "      ‚è≥ Execution in progress... (1144s elapsed, 1856s remaining)\n",
            "      Epoch [3/5] - Loss: 0.1252 | Val AUC: 0.9997\n",
            "      ‚è≥ Execution in progress... (1197s elapsed, 1803s remaining)\n",
            "      ‚è≥ Execution in progress... (1227s elapsed, 1773s remaining)\n",
            "      ‚è≥ Execution in progress... (1257s elapsed, 1743s remaining)\n",
            "      ‚è≥ Execution in progress... (1287s elapsed, 1713s remaining)\n",
            "      Epoch [4/5] - Loss: 0.1163 | Val AUC: 1.0000\n",
            "      ‚è≥ Execution in progress... (1340s elapsed, 1660s remaining)\n",
            "      ‚è≥ Execution in progress... (1370s elapsed, 1630s remaining)\n",
            "      ‚è≥ Execution in progress... (1400s elapsed, 1600s remaining)\n",
            "      ‚è≥ Execution in progress... (1430s elapsed, 1570s remaining)\n",
            "      Epoch [5/5] - Loss: 0.1101 | Val AUC: 1.0000\n",
            "      Fold 2 AUC: 1.0000\n",
            "      Saved fold 2 model to /content/kaggle_competitions/competitions/aerial-cactus-identification/models/resnet50_classification_fold2.pth\n",
            "      ================ Fold 3/5 ================\n",
            "      ‚ö†Ô∏è /usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "      ‚ö†Ô∏è   warnings.warn(\n",
            "      ‚ö†Ô∏è /usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "      ‚ö†Ô∏è   warnings.warn(msg)\n",
            "      ‚è≥ Execution in progress... (1505s elapsed, 1495s remaining)\n",
            "      ‚è≥ Execution in progress... (1535s elapsed, 1465s remaining)\n",
            "      ‚è≥ Execution in progress... (1565s elapsed, 1435s remaining)\n",
            "      ‚è≥ Execution in progress... (1595s elapsed, 1405s remaining)\n",
            "      Epoch [1/5] - Loss: 0.1540 | Val AUC: 0.9998\n",
            "      ‚è≥ Execution in progress... (1649s elapsed, 1351s remaining)\n",
            "      ‚è≥ Execution in progress... (1679s elapsed, 1321s remaining)\n",
            "      ‚è≥ Execution in progress... (1709s elapsed, 1291s remaining)\n",
            "      ‚è≥ Execution in progress... (1739s elapsed, 1261s remaining)\n",
            "      Epoch [2/5] - Loss: 0.1277 | Val AUC: 0.9995\n",
            "      ‚è≥ Execution in progress... (1792s elapsed, 1208s remaining)\n",
            "      ‚è≥ Execution in progress... (1822s elapsed, 1178s remaining)\n",
            "      ‚è≥ Execution in progress... (1852s elapsed, 1148s remaining)\n",
            "      ‚è≥ Execution in progress... (1882s elapsed, 1118s remaining)\n",
            "      Epoch [3/5] - Loss: 0.1253 | Val AUC: 0.9997\n",
            "      ‚è≥ Execution in progress... (1934s elapsed, 1066s remaining)\n",
            "      ‚è≥ Execution in progress... (1965s elapsed, 1035s remaining)\n",
            "      ‚è≥ Execution in progress... (1995s elapsed, 1005s remaining)\n",
            "      ‚è≥ Execution in progress... (2025s elapsed, 975s remaining)\n",
            "      Epoch [4/5] - Loss: 0.1151 | Val AUC: 0.9999\n",
            "      ‚è≥ Execution in progress... (2077s elapsed, 923s remaining)\n",
            "      ‚è≥ Execution in progress... (2107s elapsed, 893s remaining)\n",
            "      ‚è≥ Execution in progress... (2137s elapsed, 863s remaining)\n",
            "      ‚è≥ Execution in progress... (2168s elapsed, 832s remaining)\n",
            "      Epoch [5/5] - Loss: 0.1054 | Val AUC: 0.9999\n",
            "      Fold 3 AUC: 0.9999\n",
            "      Saved fold 3 model to /content/kaggle_competitions/competitions/aerial-cactus-identification/models/resnet50_classification_fold3.pth\n",
            "      ================ Fold 4/5 ================\n",
            "      ‚ö†Ô∏è /usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "      ‚ö†Ô∏è   warnings.warn(\n",
            "      ‚ö†Ô∏è /usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "      ‚ö†Ô∏è   warnings.warn(msg)\n",
            "      ‚è≥ Execution in progress... (2242s elapsed, 758s remaining)\n",
            "      ‚è≥ Execution in progress... (2272s elapsed, 728s remaining)\n",
            "      ‚è≥ Execution in progress... (2302s elapsed, 698s remaining)\n",
            "      ‚è≥ Execution in progress... (2332s elapsed, 668s remaining)\n",
            "      Epoch [1/5] - Loss: 0.1518 | Val AUC: 0.9995\n",
            "      ‚è≥ Execution in progress... (2385s elapsed, 615s remaining)\n",
            "      ‚è≥ Execution in progress... (2415s elapsed, 585s remaining)\n",
            "      ‚è≥ Execution in progress... (2445s elapsed, 555s remaining)\n",
            "      ‚è≥ Execution in progress... (2475s elapsed, 525s remaining)\n",
            "      Epoch [2/5] - Loss: 0.1412 | Val AUC: 0.9987\n",
            "      ‚è≥ Execution in progress... (2528s elapsed, 472s remaining)\n",
            "      ‚è≥ Execution in progress... (2558s elapsed, 442s remaining)\n",
            "      ‚è≥ Execution in progress... (2588s elapsed, 412s remaining)\n",
            "      ‚è≥ Execution in progress... (2618s elapsed, 382s remaining)\n",
            "      Epoch [3/5] - Loss: 0.1275 | Val AUC: 0.9999\n",
            "      ‚è≥ Execution in progress... (2671s elapsed, 329s remaining)\n",
            "      ‚è≥ Execution in progress... (2701s elapsed, 299s remaining)\n",
            "      ‚è≥ Execution in progress... (2731s elapsed, 269s remaining)\n",
            "      ‚è≥ Execution in progress... (2761s elapsed, 239s remaining)\n",
            "      Epoch [4/5] - Loss: 0.1165 | Val AUC: 1.0000\n",
            "      ‚è≥ Execution in progress... (2814s elapsed, 186s remaining)\n",
            "      ‚è≥ Execution in progress... (2844s elapsed, 156s remaining)\n",
            "      ‚è≥ Execution in progress... (2874s elapsed, 126s remaining)\n",
            "      ‚è≥ Execution in progress... (2904s elapsed, 96s remaining)\n",
            "      Epoch [5/5] - Loss: 0.1090 | Val AUC: 1.0000\n",
            "      Fold 4 AUC: 1.0000\n",
            "      Saved fold 4 model to /content/kaggle_competitions/competitions/aerial-cactus-identification/models/resnet50_classification_fold4.pth\n",
            "      ================ Fold 5/5 ================\n",
            "      ‚ö†Ô∏è /usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "      ‚ö†Ô∏è   warnings.warn(\n",
            "      ‚ö†Ô∏è /usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "      ‚ö†Ô∏è   warnings.warn(msg)\n",
            "      ‚è≥ Execution in progress... (2979s elapsed, 21s remaining)\n",
            "Execution failed: Timeout: execution exceeded 3000s\n",
            "\n",
            "Entering debug mode...\n",
            "Last error passed to debugger: Timeout: execution exceeded 3000s\n",
            "   Debug timeout set to: 600s (10.0 min)\n",
            "   Debug iteration 1/5\n",
            "      [LOG] Loaded predefined folds from /content/kaggle_competitions/competitions/aerial-cactus-identification/folds.csv\n",
            "      [LOG] Using 5 folds for cross-validation.\n",
            "      [LOG] Starting fold 1/5\n",
            "      [LOG] Fold 1 preprocessor transformed shape (14000, 1)\n",
            "      ‚ö†Ô∏è /usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "      ‚ö†Ô∏è   warnings.warn(\n",
            "      ‚ö†Ô∏è /usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "      ‚ö†Ô∏è   warnings.warn(msg)\n",
            "      Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "      ‚ö†Ô∏è \n",
            "      ‚ö†Ô∏è   0%|          | 0.00/44.7M [00:00<?, ?B/s]\n",
            "      ‚ö†Ô∏è  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 23.6M/44.7M [00:00<00:00, 247MB/s]\n",
            "      ‚ö†Ô∏è 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 44.7M/44.7M [00:00<00:00, 255MB/s]\n",
            "      ‚ö†Ô∏è Traceback (most recent call last):\n",
            "      ‚ö†Ô∏è   File \"/content/kaggle_competitions/competitions/aerial-cactus-identification/_exec_1765144347.py\", line 285, in <module>\n",
            "      ‚ö†Ô∏è     main()\n",
            "      ‚ö†Ô∏è   File \"/content/kaggle_competitions/competitions/aerial-cactus-identification/_exec_1765144347.py\", line 232, in main\n",
            "      ‚ö†Ô∏è     mixed_inputs, targets_a, targets_b, lam = mixup_data(inputs, targets)\n",
            "      ‚ö†Ô∏è                                               ^^^^^^^^^^\n",
            "      ‚ö†Ô∏è NameError: name 'mixup_data' is not defined\n",
            "   Debug iteration 2/5\n",
            "      [LOG] Loaded predefined folds from /content/kaggle_competitions/competitions/aerial-cactus-identification/folds.csv\n",
            "      [LOG] Using 5 folds for cross-validation.\n",
            "      [LOG] Starting fold 1/5\n",
            "      [LOG] Fold 1 preprocessor transformed shape (14000, 1)\n",
            "      ‚è≥ Execution in progress... (34s elapsed, 566s remaining)\n",
            "      [LOG] Epoch [1/3] loss=0.1482 val_auc=0.9997\n",
            "      ‚è≥ Execution in progress... (82s elapsed, 518s remaining)\n",
            "      [LOG] Epoch [2/3] loss=0.1305 val_auc=0.9999\n",
            "      ‚è≥ Execution in progress... (130s elapsed, 470s remaining)\n",
            "      [LOG] Epoch [3/3] loss=0.1063 val_auc=1.0000\n",
            "      [LOG] Fold 1 AUC: 0.999972\n",
            "      [LOG] Saved fold 1 model to /content/kaggle_competitions/competitions/aerial-cactus-identification/models/resnet18_classification_fold1.pth\n",
            "      [LOG] Starting fold 2/5\n",
            "      [LOG] Fold 2 preprocessor transformed shape (14000, 1)\n",
            "      ‚è≥ Execution in progress... (185s elapsed, 415s remaining)\n",
            "      [LOG] Epoch [1/3] loss=0.1542 val_auc=0.9998\n",
            "      ‚è≥ Execution in progress... (233s elapsed, 367s remaining)\n",
            "      [LOG] Epoch [2/3] loss=0.1291 val_auc=0.9998\n",
            "      ‚è≥ Execution in progress... (281s elapsed, 319s remaining)\n",
            "      [LOG] Epoch [3/3] loss=0.1105 val_auc=1.0000\n",
            "      [LOG] Fold 2 AUC: 0.999983\n",
            "      [LOG] Saved fold 2 model to /content/kaggle_competitions/competitions/aerial-cactus-identification/models/resnet18_classification_fold2.pth\n",
            "      [LOG] Starting fold 3/5\n",
            "      [LOG] Fold 3 preprocessor transformed shape (14000, 1)\n",
            "      ‚è≥ Execution in progress... (337s elapsed, 263s remaining)\n",
            "      [LOG] Epoch [1/3] loss=0.1512 val_auc=0.9997\n",
            "      ‚è≥ Execution in progress... (385s elapsed, 215s remaining)\n",
            "      [LOG] Epoch [2/3] loss=0.1262 val_auc=0.9999\n",
            "      ‚è≥ Execution in progress... (433s elapsed, 167s remaining)\n",
            "      [LOG] Epoch [3/3] loss=0.1143 val_auc=0.9999\n",
            "      [LOG] Fold 3 AUC: 0.999908\n",
            "      [LOG] Saved fold 3 model to /content/kaggle_competitions/competitions/aerial-cactus-identification/models/resnet18_classification_fold3.pth\n",
            "      [LOG] Starting fold 4/5\n",
            "      [LOG] Fold 4 preprocessor transformed shape (14000, 1)\n",
            "      ‚è≥ Execution in progress... (488s elapsed, 112s remaining)\n",
            "      [LOG] Epoch [1/3] loss=0.1584 val_auc=0.9996\n",
            "      ‚è≥ Execution in progress... (536s elapsed, 64s remaining)\n",
            "      [LOG] Epoch [2/3] loss=0.1274 val_auc=0.9997\n",
            "      ‚è≥ Execution in progress... (585s elapsed, 15s remaining)\n",
            "Debug halted: repeated timeout during debug\n",
            "Component timeout set to: 3000s (50.0 min)\n",
            "\u0005 DSPy configured with openai/gpt-5.1-codex-mini\n",
            "\u000f  No optimized prompts found for developer_generator\n",
            "\u000f  No optimized prompts found for developer_fixer\n",
            "Using base (unoptimized) generator module\n",
            "Using base (unoptimized) fixer module\n",
            "\n",
            "============================================================\n",
            "= DEVELOPER AGENT: Implementing Components\n",
            "============================================================\n",
            "\n",
            "= Implementing: resnet50_classification (model)\n",
            "Estimated Impact: 24.0%\n",
            "\n",
            "Generating code...\n",
            "\n",
            "Generated code preview:\n",
            "        1 | import os\n",
            "        2 | import random\n",
            "        3 | from pathlib import Path\n",
            "        4 | \n",
            "        5 | import numpy as np\n",
            "        6 | import pandas as pd\n",
            "        7 | import torch\n",
            "        8 | import torch.nn as nn\n",
            "        9 | import torch.nn.functional as F\n",
            "       10 | import torch.optim as optim\n",
            "       11 | from PIL import Image, ImageFile\n",
            "       12 | from sklearn.compose import ColumnTransformer\n",
            "       13 | from sklearn.metrics import roc_auc_score\n",
            "       14 | from sklearn.model_selection import StratifiedKFold\n",
            "       15 | from sklearn.preprocessing import OneHotEncoder\n",
            "       16 | from torch.optim.lr_scheduler import CosineAnnealingLR\n",
            "       17 | from torch.utils.data import DataLoader, Dataset\n",
            "       18 | from torchvision import models, transforms\n",
            "       19 | \n",
            "       20 | ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
            "       21 | \n",
            "       22 | \n",
            "       23 | class Cutout:\n",
            "       24 |     def __init__(self, n_holes: int = 1, length: int = 32) -> None:\n",
            "       25 |         self.n_holes = n_holes\n",
            "       26 |         self.length = length\n",
            "       27 | \n",
            "       28 |     def __call__(self, img: torch.Tensor) -> torch.Tensor:\n",
            "       29 |         if not isinstance(img, torch.Tensor):\n",
            "       30 |             return img\n",
            "       31 |         h, w = img.size(1), img.size(2)\n",
            "       32 |         mask = torch.ones_like(img)\n",
            "       33 |         for _ in range(self.n_holes):\n",
            "       34 |             y = random.randint(0, h - 1)\n",
            "       35 |             x = random.randint(0, w - 1)\n",
            "       36 |             y1 = max(0, y - self.length // 2)\n",
            "       37 |             y2 = min(h, y + self.length // 2)\n",
            "       38 |             x1 = max(0, x - self.length // 2)\n",
            "       39 |             x2 = min(w, x + self.length // 2)\n",
            "       40 |             mask[:, y1:y2, x1:x2] = 0\n",
            "       41 |         return img * mask\n",
            "       42 | \n",
            "       43 | \n",
            "       44 | def mixup_data(x, y, alpha: float = 0.4, device: torch.device = torch.device(\"cpu\")):\n",
            "       45 |     if alpha <= 0:\n",
            "       46 |         return x, y, y, 1.0\n",
            "       47 |     lam = np.random.beta(alpha, alpha)\n",
            "       48 |     batch_size = x.size()[0]\n",
            "       49 |     if batch_size == 1:\n",
            "       50 |         return x, y, y, 1.0\n",
            "       51 |     index = torch.randperm(batch_size).to(device)\n",
            "       52 |     mixed_x = lam * x + (1 - lam) * x[index, :]\n",
            "       53 |     y_a, y_b = y, y[index]\n",
            "       54 |     return mixed_x, y_a, y_b, lam\n",
            "       55 | \n",
            "       56 | \n",
            "       57 | def encode_categorical_features(df: pd.DataFrame):\n",
            "       58 |     cat_cols = df.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
            "       59 |     if not cat_cols:\n",
            "       60 |         print(\"No categorical features found for encoding. Skipping ColumnTransformer step.\")\n",
            "       61 |         return None\n",
            "       62 |     transformer = ColumnTransformer(\n",
            "       63 |         transformers=[\n",
            "       64 |             (\n",
            "       65 |                 \"cat\",\n",
            "       66 |                 OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False),\n",
            "       67 |                 cat_cols,\n",
            "       68 |             )\n",
            "       69 |         ],\n",
            "       70 |         remainder=\"drop\",\n",
            "       71 |     )\n",
            "       72 |     encoded = transformer.fit_transform(df[cat_cols])\n",
            "       73 |     print(f\"Encoded {len(cat_cols)} categorical feature(s) using OneHotEncoder.\")\n",
            "       74 |     return encoded\n",
            "       75 | \n",
            "       76 | \n",
            "       77 | class CactusDataset(Dataset):\n",
            "       78 |     def __init__(\n",
            "       79 |         self,\n",
            "       80 |         df: pd.DataFrame,\n",
            "       81 |         root_dir: Path,\n",
            "       82 |         transform: transforms.Compose,\n",
            "       83 |         target_col: str | None = None,\n",
            "       84 |     ) -> None:\n",
            "       85 |         self.df = df.reset_index(drop=True)\n",
            "       86 |         self.root_dir = root_dir\n",
            "       87 |         self.transform = transform\n",
            "       88 |         self.target_col = target_col\n",
            "       89 | \n",
            "       90 |     def __len__(self):\n",
            "       91 |         return len(self.df)\n",
            "       92 | \n",
            "       93 |     def __getitem__(self, idx: int):\n",
            "       94 |         row = self.df.iloc[idx]\n",
            "       95 |         img_path = self.root_dir / row[\"id\"]\n",
            "       96 |         with Image.open(img_path).convert(\"RGB\") as img:\n",
            "       97 |             image = self.transform(img)\n",
            "       98 |         if self.target_col and self.target_col in row:\n",
            "       99 |             label = torch.tensor(row[self.target_col], dtype=torch.float32)\n",
            "      100 |         else:\n",
            "      101 |             label = torch.tensor(0.0, dtype=torch.float32)\n",
            "      102 |         return image, label\n",
            "      103 | \n",
            "      104 | \n",
            "      105 | def prepare_transforms():\n",
            "      106 |     imagenet_mean = [0.485, 0.456, 0.406]\n",
            "      107 |     imagenet_std = [0.229, 0.224, 0.225]\n",
            "      108 |     train_transform = transforms.Compose(\n",
            "      109 |         [\n",
            "      110 |             transforms.RandomResizedCrop(224, scale=(0.7, 1.0)),\n",
            "      111 |             transforms.RandomHorizontalFlip(),\n",
            "      112 |             transforms.RandomVerticalFlip(),\n",
            "      113 |             transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
            "      114 |             transforms.ToTensor(),\n",
            "      115 |             Cutout(n_holes=1, length=32),\n",
            "      116 |             transforms.Normalize(mean=imagenet_mean, std=imagenet_std),\n",
            "      117 |         ]\n",
            "      118 |     )\n",
            "      119 |     val_transform = transforms.Compose(\n",
            "      120 |         [\n",
            "      121 |             transforms.Resize(256),\n",
            "      122 |             transforms.CenterCrop(224),\n",
            "      123 |             transforms.ToTensor(),\n",
            "      124 |             transforms.Normalize(mean=imagenet_mean, std=imagenet_std),\n",
            "      125 |         ]\n",
            "      126 |     )\n",
            "      127 |     return train_transform, val_transform\n",
            "      128 | \n",
            "      129 | \n",
            "      130 | def build_model(device: torch.device) -> nn.Module:\n",
            "      131 |     model = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V2)\n",
            "      132 |     in_features = model.fc.in_features\n",
            "      133 |     model.fc = nn.Linear(in_features, 1)\n",
            "      134 |     model = model.to(device)\n",
            "      135 |     return model\n",
            "      136 | \n",
            "      137 | \n",
            "      138 | def train_one_fold(\n",
            "      139 |     fold: int,\n",
            "      140 |     model: nn.Module,\n",
            "      141 |     train_loader: DataLoader,\n",
            "      142 |     val_loader: DataLoader,\n",
            "      143 |     optimizer: optim.Optimizer,\n",
            "      144 |     scheduler: CosineAnnealingLR,\n",
            "      145 |     criterion: nn.Module,\n",
            "      146 |     device: torch.device,\n",
            "      147 |     mixup_alpha: float,\n",
            "      148 | ) -> tuple[list[float], list[float]]:\n",
            "      149 |     model.train()\n",
            "      150 |     for epoch in range(scheduler.T_max):\n",
            "      151 |         epoch_loss = 0.0\n",
            "      152 |         for images, labels in train_loader:\n",
            "      153 |             images = images.to(device)\n",
            "      154 |             labels = labels.to(device)\n",
            "      155 |             inputs, targets_a, targets_b, lam = mixup_data(images, labels, alpha=mixup_alpha, device=device)\n",
            "      156 |             outputs = model(inputs).squeeze(1)\n",
            "      157 |             loss = lam * criterion(outputs, targets_a) + (1 - lam) * criterion(outputs, targets_b)\n",
            "      158 |             optimizer.zero_grad()\n",
            "      159 |             loss.backward()\n",
            "      160 |             optimizer.step()\n",
            "      161 |             epoch_loss += loss.item() * images.size(0)\n",
            "      162 |         scheduler.step()\n",
            "      163 |         avg_loss = epoch_loss / len(train_loader.dataset)\n",
            "      164 |         lr = optimizer.param_groups[0][\"lr\"]\n",
            "      165 |         print(f\"Fold {fold} Epoch {scheduler.last_epoch}/{scheduler.T_max} - Loss: {avg_loss:.4f} LR: {lr:.6f}\")\n",
            "      166 |     model.eval()\n",
            "      167 |     val_probs: list[float] = []\n",
            "      168 |     val_targets: list[float] = []\n",
            "      169 |     with torch.no_grad():\n",
            "      170 |         for images, labels in val_loader:\n",
            "      171 |             images = images.to(device)\n",
            "      172 |             labels = labels.to(device)\n",
            "      173 |             logits = model(images).squeeze(1)\n",
            "      174 |             probs = torch.sigmoid(logits)\n",
            "      175 |             val_probs.extend(probs.detach().cpu().numpy().tolist())\n",
            "      176 |             val_targets.extend(labels.detach().cpu().numpy().tolist())\n",
            "      177 |     return val_targets, val_probs\n",
            "      178 | \n",
            "      179 | \n",
            "      180 | def main():\n",
            "      181 |     component_name = \"resnet50_classification\"\n",
            "      182 |     raw_data_paths = \"\"\"        Train: /content/kaggle_competitions/competitions/aerial-cactus-identification/train\n",
            "      183 |         Test: /content/kaggle_competitions/competitions/aerial-cactus-identification/test\n",
            "      184 |         Models: /content/kaggle_competitions/competitions/aerial-cactus-identification/models\n",
            "      185 |         Sample Submission: /content/kaggle_competitions/competitions/aerial-cactus-identification/sample_submission.csv\n",
            "      186 |         Submission Output: /content/kaggle_competitions/competitions/aerial-cactus-identification/sample_submission.csv\n",
            "      187 |         \"\"\"\n",
            "      188 |     paths = {}\n",
            "      189 |     for line in raw_data_paths.strip().splitlines():\n",
            "      190 |         if \":\" not in line:\n",
            "      191 |             continue\n",
            "      192 |         key, value = line.split(\":\", 1)\n",
            "      193 |         paths[key.strip()] = value.strip()\n",
            "      194 |     dataset_root = Path(paths[\"Train\"]).parent\n",
            "      195 |     train_csv = dataset_root / \"train.csv\"\n",
            "      196 |     if not train_csv.exists():\n",
            "      197 |         raise FileNotFoundError(f\"Missing train.csv at {train_csv}\")\n",
            "      198 |     train_df = pd.read_csv(train_csv)\n",
            "      199 |     sample_submission = pd.read_csv(paths[\"Sample Submission\"])\n",
            "      200 |     target_col = \"has_cactus\" if \"has_cactus\" in train_df.columns else sample_submission.columns[1]\n",
            "      201 |     if target_col not in train_df.columns:\n",
            "      202 |         train_df[target_col] = 0\n",
            "      203 |     test_df = sample_submission[[sample_submission.columns[0]]].copy()\n",
            "      204 |     test_df.columns = [\"id\"]\n",
            "      205 |     encode_categorical_features(train_df[[\"id\"]])\n",
            "      206 |     encode_categorical_features(test_df[[\"id\"]])\n",
            "      207 |     folds_path = dataset_root / \"folds.csv\"\n",
            "      208 |     train_df = train_df.reset_index(drop=True)\n",
            "      209 |     if folds_path.exists():\n",
            "      210 |         folds_df = pd.read_csv(folds_path).reset_index(drop=True)\n",
            "      211 |         if \"fold\" not in folds_df.columns:\n",
            "      212 |             raise KeyError(\"folds.csv must contain a 'fold' column\")\n",
            "      213 |         if len(folds_df) != len(train_df):\n",
            "      214 |             raise ValueError(\"Provided folds do not align with train records\")\n",
            "      215 |         train_df[\"fold\"] = folds_df[\"fold\"].values\n",
            "      216 |         fold_ids = sorted(train_df[\"fold\"].unique())\n",
            "      217 |     else:\n",
            "      218 |         skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
            "      219 |         train_df[\"fold\"] = -1\n",
            "      220 |         for fold_id, (_, val_idx) in enumerate(skf.split(train_df, train_df[target_col].values)):\n",
            "      221 |             train_df.loc[val_idx, \"fold\"] = fold_id\n",
            "      222 |         fold_ids = sorted(train_df[\"fold\"].unique())\n",
            "      223 |     oof_preds = np.zeros(len(train_df), dtype=np.float32)\n",
            "      224 |     test_preds = np.zeros(len(test_df), dtype=np.float32)\n",
            "      225 |     train_transform, val_transform = prepare_transforms()\n",
            "      226 |     test_transform = val_transform\n",
            "      227 |     batch_size = 32\n",
            "      228 |     device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
            "      229 |     test_dataset = CactusDataset(test_df, Path(paths[\"Test\"]), test_transform, target_col=None)\n",
            "      230 |     test_loader = DataLoader(\n",
            "      231 |         test_dataset,\n",
            "      232 |         batch_size=batch_size,\n",
            "      233 |         shuffle=False,\n",
            "      234 |         num_workers=min(4, os.cpu_count() or 0),\n",
            "      235 |         pin_memory=torch.cuda.is_available(),\n",
            "      236 |     )\n",
            "      237 |     models_dir = Path(paths[\"Models\"])\n",
            "      238 |     models_dir.mkdir(parents=True, exist_ok=True)\n",
            "      239 |     val_scores: list[float] = []\n",
            "      240 |     for fold in fold_ids:\n",
            "      241 |         print(f\"Starting fold {fold}\")\n",
            "      242 |         train_idx = train_df[train_df[\"fold\"] != fold].index\n",
            "      243 |         val_idx = train_df[train_df[\"fold\"] == fold].index\n",
            "      244 |         train_subset = train_df.loc[train_idx].reset_index(drop=True)\n",
            "      245 |         val_subset = train_df.loc[val_idx].reset_index(drop=True)\n",
            "      246 |         train_dataset = CactusDataset(train_subset, Path(paths[\"Train\"]), train_transform, target_col)\n",
            "      247 |         val_dataset = CactusDataset(val_subset, Path(paths[\"Train\"]), val_transform, target_col)\n",
            "      248 |         train_loader = DataLoader(\n",
            "      249 |             train_dataset,\n",
            "      250 |             batch_size=batch_size,\n",
            "      251 |             shuffle=True,\n",
            "      252 |             num_workers=min(4, os.cpu_count() or 0),\n",
            "      253 |             pin_memory=torch.cuda.is_available(),\n",
            "      254 |         )\n",
            "      255 |         val_loader = DataLoader(\n",
            "      256 |             val_dataset,\n",
            "      257 |             batch_size=batch_size,\n",
            "      258 |             shuffle=False,\n",
            "      259 |             num_workers=min(4, os.cpu_count() or 0),\n",
            "      260 |             pin_memory=torch.cuda.is_available(),\n",
            "      261 |         )\n",
            "      262 |         model = build_model(device)\n",
            "      263 |         num_pos = train_subset[target_col].sum()\n",
            "      264 |         num_neg = len(train_subset) - num_pos\n",
            "      265 |         if num_pos <= 0:\n",
            "      266 |             num_pos = 1\n",
            "      267 |         pos_weight = torch.tensor(num_neg / num_pos, dtype=torch.float32, device=device)\n",
            "      268 |         criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
            "      269 |         optimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-2)\n",
            "      270 |         num_epochs = 3\n",
            "      271 |         scheduler = CosineAnnealingLR(optimizer, T_max=num_epochs, eta_min=1e-6)\n",
            "      272 |         val_targets, val_probs = train_one_fold(\n",
            "      273 |             fold,\n",
            "      274 |             model,\n",
            "      275 |             train_loader,\n",
            "      276 |             val_loader,\n",
            "      277 |             optimizer,\n",
            "      278 |             scheduler,\n",
            "      279 |             criterion,\n",
            "      280 |             device,\n",
            "      281 |             mixup_alpha=0.4,\n",
            "      282 |         )\n",
            "      283 |         val_auc = roc_auc_score(val_targets, val_probs)\n",
            "      284 |         print(f\"Fold {fold} Validation AUC: {val_auc:.6f}\")\n",
            "      285 |         val_scores.append(val_auc)\n",
            "      286 |         oof_preds[val_idx] = np.array(val_probs, dtype=np.float32)\n",
            "      287 |         fold_test_preds: list[float] = []\n",
            "      288 |         model.eval()\n",
            "      289 |         with torch.no_grad():\n",
            "      290 |             for images, _ in test_loader:\n",
            "      291 |                 images = images.to(device)\n",
            "      292 |                 logits = model(images).squeeze(1)\n",
            "      293 |                 probs = torch.sigmoid(logits)\n",
            "      294 |                 fold_test_preds.extend(probs.detach().cpu().numpy().tolist())\n",
            "      295 |         if len(fold_test_preds) != len(test_df):\n",
            "      296 |             raise ValueError(\"Test loader produced unexpected number of predictions\")\n",
            "      297 |         test_preds += np.array(fold_test_preds, dtype=np.float32) / len(fold_ids)\n",
            "      298 |         fold_model_path = models_dir / f\"{component_name}_fold{fold}.pth\"\n",
            "      299 |         torch.save(model.state_dict(), fold_model_path)\n",
            "      300 |         torch.cuda.empty_cache()\n",
            "      301 |     final_score = roc_auc_score(train_df[target_col].values, oof_preds)\n",
            "      302 |     print(f\"Final Validation Performance: {final_score:.6f}\")\n",
            "      303 |     oof_path = models_dir / f\"oof_{component_name}.npy\"\n",
            "      304 |     test_oof_path = models_dir / f\"test_{component_name}.npy\"\n",
            "      305 |     np.save(oof_path, oof_preds)\n",
            "      306 |     np.save(test_oof_path, test_preds)\n",
            "      307 |     submission = sample_submission.copy()\n",
            "      308 |     submission[target_col] = np.clip(test_preds, 0.0, 1.0)\n",
            "      309 |     submission_output_path = Path(paths[\"Submission Output\"])\n",
            "      310 |     submission.to_csv(submission_output_path, index=False)\n",
            "      311 |     print(f\"Submission saved to {submission_output_path}\")\n",
            "      312 | \n",
            "      313 | \n",
            "      314 | if __name__ == \"__main__\":\n",
            "      315 |     main()\n",
            "\n",
            "Code saved to: generated_code_resnet50_classification.py\n",
            "\n",
            "Executing code...\n",
            "\n",
            "Attempt 1/3\n",
            "      Starting fold 0\n",
            "      Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth\n",
            "      ‚ö†Ô∏è \n",
            "      ‚ö†Ô∏è   0%|          | 0.00/97.8M [00:00<?, ?B/s]\n",
            "      ‚ö†Ô∏è  24%|‚ñà‚ñà‚ñç       | 23.9M/97.8M [00:00<00:00, 249MB/s]\n",
            "      ‚ö†Ô∏è  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 48.0M/97.8M [00:00<00:00, 251MB/s]\n",
            "      ‚ö†Ô∏è  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 73.2M/97.8M [00:00<00:00, 257MB/s]\n",
            "      ‚ö†Ô∏è 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 97.8M/97.8M [00:00<00:00, 252MB/s]\n",
            "      ‚ö†Ô∏è 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 97.8M/97.8M [00:00<00:00, 252MB/s]\n",
            "      ‚è≥ Execution in progress... (36s elapsed, 2964s remaining)\n",
            "      ‚è≥ Execution in progress... (66s elapsed, 2934s remaining)\n",
            "      ‚è≥ Execution in progress... (96s elapsed, 2904s remaining)\n",
            "      ‚è≥ Execution in progress... (126s elapsed, 2874s remaining)\n",
            "      Fold 0 Epoch 1/3 - Loss: 0.1611 LR: 0.000075\n",
            "      ‚è≥ Execution in progress... (167s elapsed, 2833s remaining)\n",
            "      ‚è≥ Execution in progress... (197s elapsed, 2803s remaining)\n",
            "      ‚è≥ Execution in progress... (227s elapsed, 2773s remaining)\n",
            "      ‚è≥ Execution in progress... (257s elapsed, 2743s remaining)\n",
            "      Fold 0 Epoch 2/3 - Loss: 0.1310 LR: 0.000026\n",
            "      ‚è≥ Execution in progress... (300s elapsed, 2700s remaining)\n",
            "      ‚è≥ Execution in progress... (330s elapsed, 2670s remaining)\n",
            "      ‚è≥ Execution in progress... (360s elapsed, 2640s remaining)\n",
            "      ‚è≥ Execution in progress... (390s elapsed, 2610s remaining)\n",
            "      Fold 0 Epoch 3/3 - Loss: 0.1110 LR: 0.000001\n",
            "      Fold 0 Validation AUC: 0.999893\n",
            "      Starting fold 1\n",
            "      ‚è≥ Execution in progress... (454s elapsed, 2546s remaining)\n",
            "      ‚è≥ Execution in progress... (484s elapsed, 2516s remaining)\n",
            "      ‚è≥ Execution in progress... (514s elapsed, 2486s remaining)\n",
            "      ‚è≥ Execution in progress... (544s elapsed, 2456s remaining)\n",
            "      Fold 1 Epoch 1/3 - Loss: 0.1530 LR: 0.000075\n",
            "      ‚è≥ Execution in progress... (587s elapsed, 2413s remaining)\n",
            "      ‚è≥ Execution in progress... (617s elapsed, 2383s remaining)\n",
            "      ‚è≥ Execution in progress... (647s elapsed, 2353s remaining)\n",
            "      ‚è≥ Execution in progress... (677s elapsed, 2323s remaining)\n",
            "      Fold 1 Epoch 2/3 - Loss: 0.1307 LR: 0.000026\n",
            "      ‚è≥ Execution in progress... (720s elapsed, 2280s remaining)\n",
            "      ‚è≥ Execution in progress... (750s elapsed, 2250s remaining)\n",
            "      ‚è≥ Execution in progress... (780s elapsed, 2220s remaining)\n",
            "      ‚è≥ Execution in progress... (810s elapsed, 2190s remaining)\n",
            "      Fold 1 Epoch 3/3 - Loss: 0.1108 LR: 0.000001\n",
            "      Fold 1 Validation AUC: 0.999990\n",
            "      Starting fold 2\n",
            "      ‚è≥ Execution in progress... (875s elapsed, 2125s remaining)\n",
            "      ‚è≥ Execution in progress... (905s elapsed, 2095s remaining)\n",
            "      ‚è≥ Execution in progress... (935s elapsed, 2065s remaining)\n",
            "      ‚è≥ Execution in progress... (965s elapsed, 2035s remaining)\n",
            "      Fold 2 Epoch 1/3 - Loss: 0.1555 LR: 0.000075\n",
            "      ‚è≥ Execution in progress... (1008s elapsed, 1992s remaining)\n",
            "      ‚è≥ Execution in progress... (1038s elapsed, 1962s remaining)\n",
            "      ‚è≥ Execution in progress... (1068s elapsed, 1932s remaining)\n",
            "      ‚è≥ Execution in progress... (1098s elapsed, 1902s remaining)\n",
            "      Fold 2 Epoch 2/3 - Loss: 0.1265 LR: 0.000026\n",
            "      ‚è≥ Execution in progress... (1140s elapsed, 1860s remaining)\n",
            "      ‚è≥ Execution in progress... (1170s elapsed, 1830s remaining)\n",
            "      ‚è≥ Execution in progress... (1200s elapsed, 1800s remaining)\n",
            "      ‚è≥ Execution in progress... (1230s elapsed, 1770s remaining)\n",
            "      Fold 2 Epoch 3/3 - Loss: 0.1159 LR: 0.000001\n",
            "      Fold 2 Validation AUC: 0.999749\n",
            "      Starting fold 3\n",
            "      ‚è≥ Execution in progress... (1295s elapsed, 1705s remaining)\n",
            "      ‚è≥ Execution in progress... (1325s elapsed, 1675s remaining)\n",
            "      ‚è≥ Execution in progress... (1355s elapsed, 1645s remaining)\n",
            "      ‚è≥ Execution in progress... (1385s elapsed, 1615s remaining)\n",
            "      Fold 3 Epoch 1/3 - Loss: 0.1485 LR: 0.000075\n",
            "      ‚è≥ Execution in progress... (1428s elapsed, 1572s remaining)\n",
            "      ‚è≥ Execution in progress... (1458s elapsed, 1542s remaining)\n",
            "      ‚è≥ Execution in progress... (1488s elapsed, 1512s remaining)\n",
            "      ‚è≥ Execution in progress... (1518s elapsed, 1482s remaining)\n",
            "      Fold 3 Epoch 2/3 - Loss: 0.1230 LR: 0.000026\n",
            "      ‚è≥ Execution in progress... (1561s elapsed, 1439s remaining)\n",
            "      ‚è≥ Execution in progress... (1591s elapsed, 1409s remaining)\n",
            "      ‚è≥ Execution in progress... (1621s elapsed, 1379s remaining)\n",
            "      ‚è≥ Execution in progress... (1651s elapsed, 1349s remaining)\n",
            "      Fold 3 Epoch 3/3 - Loss: 0.1200 LR: 0.000001\n",
            "      Fold 3 Validation AUC: 0.999899\n",
            "      Starting fold 4\n",
            "      ‚è≥ Execution in progress... (1715s elapsed, 1285s remaining)\n",
            "      ‚è≥ Execution in progress... (1745s elapsed, 1255s remaining)\n",
            "      ‚è≥ Execution in progress... (1776s elapsed, 1224s remaining)\n",
            "      ‚è≥ Execution in progress... (1806s elapsed, 1194s remaining)\n",
            "      Fold 4 Epoch 1/3 - Loss: 0.1595 LR: 0.000075\n",
            "      ‚è≥ Execution in progress... (1849s elapsed, 1151s remaining)\n",
            "      ‚è≥ Execution in progress... (1879s elapsed, 1121s remaining)\n",
            "      ‚è≥ Execution in progress... (1909s elapsed, 1091s remaining)\n",
            "      ‚è≥ Execution in progress... (1939s elapsed, 1061s remaining)\n",
            "      Fold 4 Epoch 2/3 - Loss: 0.1310 LR: 0.000026\n",
            "      ‚è≥ Execution in progress... (1981s elapsed, 1019s remaining)\n",
            "      ‚è≥ Execution in progress... (2011s elapsed, 989s remaining)\n",
            "      ‚è≥ Execution in progress... (2042s elapsed, 958s remaining)\n",
            "      ‚è≥ Execution in progress... (2072s elapsed, 928s remaining)\n",
            "      Fold 4 Epoch 3/3 - Loss: 0.1195 LR: 0.000001\n",
            "      Fold 4 Validation AUC: 0.999318\n",
            "      üéØ Final Validation Performance: 0.999714\n",
            "      Submission saved to /content/kaggle_competitions/competitions/aerial-cactus-identification/sample_submission.csv\n",
            "Execution failed: Error: 0%|          | 0.00/97.8M [00:00<?, ?B/s]\n",
            " 24%|‚ñà‚ñà‚ñç       | 23.9M/97.8M [00:00<00:00, 249MB/s]\n",
            " 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 48.0M/97.8M [00:00<00:00, 251MB/s]\n",
            " 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 73.2M/97.8M [00:00<00:00, 257MB/s]\n",
            "10\n",
            "\n",
            "Getting meta-evaluator feedback...\n",
            "Meta-Feedback:\n",
            "The ‚Äú0%‚Ä¶97.8M‚Ä¶‚Äù tqdm trace is the ResNet50 weights download from `torchvision.models`. In sandboxed deployments without outbound Internet that download fails, so the whole component aborts.\n",
            "\n",
            "Actionable fixes:\n",
            "1. Catch download failures and fall back to random weights. E.g. wrap `models.resnet50(weights=...)` in a `try/except` that tries `weights=None` if the HTTP request raises `URLError`.\n",
            "2. Make the use of pretrained weights configurable (via an env var or CLI flag) so the CI job can disable downloads:  \n",
            "   ```python\n",
            "   use_pretrained = os.environ.get(\"USE_PRETRAINED\", \"1\") == \"1\"\n",
            "   weights = models.ResNet50_Weights.IMAGENET1K_V2 if use_pretrained else None\n",
            "   model = models.resnet50(weights=weights)\n",
            "   ```\n",
            "3. Cache the weights inside the repo or artifact store ahead of time and load from disk when offline; this avoids repeated downloads and keeps runs reproducible.\n",
            "\n",
            "Best practice: Never assume outbound network access‚Äîalways provide deterministic fallbacks when loading remote assets.\n",
            "\n",
            "Passing error context to fixer: Error: 0%|          | 0.00/97.8M [00:00<?, ?B/s]  24%|‚ñà‚ñà‚ñç       | 23.9M/97.8M [00:00<00:00, 249MB/s]  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 48.0M/97.8M [00:00<00:00, 251MB/s]  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 73.2M/97.8M [00:00<00:00, 257MB/s] 10\n",
            "Attempting to fix...\n",
            "\n",
            "Attempt 2/3\n",
            "      Starting fold 0\n",
            "      ‚è≥ Execution in progress... (35s elapsed, 2965s remaining)\n",
            "      ‚è≥ Execution in progress... (65s elapsed, 2935s remaining)\n",
            "      ‚è≥ Execution in progress... (95s elapsed, 2905s remaining)\n",
            "      ‚è≥ Execution in progress... (125s elapsed, 2875s remaining)\n",
            "      Fold 0 Epoch 1/3 - Loss: 0.2295 LR: 0.000075\n",
            "      ‚è≥ Execution in progress... (169s elapsed, 2831s remaining)\n",
            "      ‚è≥ Execution in progress... (200s elapsed, 2800s remaining)\n",
            "      ‚è≥ Execution in progress... (230s elapsed, 2770s remaining)\n",
            "      ‚è≥ Execution in progress... (260s elapsed, 2740s remaining)\n",
            "      Fold 0 Epoch 2/3 - Loss: 0.1891 LR: 0.000026\n",
            "      ‚è≥ Execution in progress... (303s elapsed, 2697s remaining)\n",
            "      ‚è≥ Execution in progress... (333s elapsed, 2667s remaining)\n",
            "      ‚è≥ Execution in progress... (363s elapsed, 2637s remaining)\n",
            "      ‚è≥ Execution in progress... (393s elapsed, 2607s remaining)\n",
            "      Fold 0 Epoch 3/3 - Loss: 0.1825 LR: 0.000001\n",
            "      Fold 0 Validation AUC: 0.996789\n",
            "      Starting fold 1\n",
            "      ‚è≥ Execution in progress... (459s elapsed, 2541s remaining)\n",
            "      ‚è≥ Execution in progress... (489s elapsed, 2511s remaining)\n",
            "      ‚è≥ Execution in progress... (519s elapsed, 2481s remaining)\n",
            "      ‚è≥ Execution in progress... (549s elapsed, 2451s remaining)\n",
            "      Fold 1 Epoch 1/3 - Loss: 0.2245 LR: 0.000075\n",
            "      ‚è≥ Execution in progress... (592s elapsed, 2408s remaining)\n",
            "      ‚è≥ Execution in progress... (622s elapsed, 2378s remaining)\n",
            "      ‚è≥ Execution in progress... (653s elapsed, 2347s remaining)\n",
            "      ‚è≥ Execution in progress... (683s elapsed, 2317s remaining)\n",
            "      Fold 1 Epoch 2/3 - Loss: 0.1892 LR: 0.000026\n",
            "      ‚è≥ Execution in progress... (726s elapsed, 2274s remaining)\n",
            "      ‚è≥ Execution in progress... (756s elapsed, 2244s remaining)\n",
            "      ‚è≥ Execution in progress... (786s elapsed, 2214s remaining)\n",
            "      ‚è≥ Execution in progress... (816s elapsed, 2184s remaining)\n",
            "      Fold 1 Epoch 3/3 - Loss: 0.1815 LR: 0.000001\n",
            "      Fold 1 Validation AUC: 0.995882\n",
            "      Starting fold 2\n",
            "      ‚è≥ Execution in progress... (882s elapsed, 2118s remaining)\n",
            "      ‚è≥ Execution in progress... (912s elapsed, 2088s remaining)\n",
            "      ‚è≥ Execution in progress... (942s elapsed, 2058s remaining)\n",
            "      ‚è≥ Execution in progress... (972s elapsed, 2028s remaining)\n",
            "      Fold 2 Epoch 1/3 - Loss: 0.2195 LR: 0.000075\n",
            "      ‚è≥ Execution in progress... (1015s elapsed, 1985s remaining)\n",
            "      ‚è≥ Execution in progress... (1045s elapsed, 1955s remaining)\n",
            "      ‚è≥ Execution in progress... (1076s elapsed, 1924s remaining)\n",
            "      ‚è≥ Execution in progress... (1106s elapsed, 1894s remaining)\n",
            "      Fold 2 Epoch 2/3 - Loss: 0.1985 LR: 0.000026\n",
            "      ‚è≥ Execution in progress... (1149s elapsed, 1851s remaining)\n",
            "      ‚è≥ Execution in progress... (1179s elapsed, 1821s remaining)\n",
            "      ‚è≥ Execution in progress... (1209s elapsed, 1791s remaining)\n",
            "      ‚è≥ Execution in progress... (1239s elapsed, 1761s remaining)\n",
            "      Fold 2 Epoch 3/3 - Loss: 0.1799 LR: 0.000001\n",
            "      Fold 2 Validation AUC: 0.995838\n",
            "      Starting fold 3\n",
            "      ‚è≥ Execution in progress... (1305s elapsed, 1695s remaining)\n",
            "      ‚è≥ Execution in progress... (1335s elapsed, 1665s remaining)\n",
            "      ‚è≥ Execution in progress... (1365s elapsed, 1635s remaining)\n",
            "      ‚è≥ Execution in progress... (1395s elapsed, 1605s remaining)\n",
            "      Fold 3 Epoch 1/3 - Loss: 0.2251 LR: 0.000075\n",
            "      ‚è≥ Execution in progress... (1439s elapsed, 1561s remaining)\n",
            "      ‚è≥ Execution in progress... (1469s elapsed, 1531s remaining)\n",
            "      ‚è≥ Execution in progress... (1499s elapsed, 1501s remaining)\n",
            "      ‚è≥ Execution in progress... (1529s elapsed, 1471s remaining)\n",
            "      Fold 3 Epoch 2/3 - Loss: 0.2005 LR: 0.000026\n",
            "      ‚è≥ Execution in progress... (1572s elapsed, 1428s remaining)\n",
            "      ‚è≥ Execution in progress... (1602s elapsed, 1398s remaining)\n",
            "      ‚è≥ Execution in progress... (1632s elapsed, 1368s remaining)\n",
            "      ‚è≥ Execution in progress... (1662s elapsed, 1338s remaining)\n",
            "      Fold 3 Epoch 3/3 - Loss: 0.1827 LR: 0.000001\n",
            "      Fold 3 Validation AUC: 0.995246\n",
            "      Starting fold 4\n",
            "      ‚è≥ Execution in progress... (1727s elapsed, 1273s remaining)\n",
            "      ‚è≥ Execution in progress... (1758s elapsed, 1242s remaining)\n",
            "      ‚è≥ Execution in progress... (1788s elapsed, 1212s remaining)\n",
            "      ‚è≥ Execution in progress... (1818s elapsed, 1182s remaining)\n",
            "      Fold 4 Epoch 1/3 - Loss: 0.2215 LR: 0.000075\n",
            "      ‚è≥ Execution in progress... (1862s elapsed, 1138s remaining)\n",
            "      ‚è≥ Execution in progress... (1892s elapsed, 1108s remaining)\n",
            "      ‚è≥ Execution in progress... (1922s elapsed, 1078s remaining)\n",
            "      ‚è≥ Execution in progress... (1952s elapsed, 1048s remaining)\n",
            "      Fold 4 Epoch 2/3 - Loss: 0.1953 LR: 0.000026\n",
            "      ‚è≥ Execution in progress... (1995s elapsed, 1005s remaining)\n",
            "      ‚è≥ Execution in progress... (2025s elapsed, 975s remaining)\n",
            "      ‚è≥ Execution in progress... (2055s elapsed, 945s remaining)\n",
            "      ‚è≥ Execution in progress... (2085s elapsed, 915s remaining)\n",
            "      Fold 4 Epoch 3/3 - Loss: 0.1779 LR: 0.000001\n",
            "      Fold 4 Validation AUC: 0.992043\n",
            "      üéØ Final Validation Performance: 0.994892\n",
            "      Submission saved to /content/kaggle_competitions/competitions/aerial-cactus-identification/sample_submission.csv\n",
            "   üìä Validation Performance: 0.994892\n",
            "Execution successful (2121.48s)\n",
            "\n",
            "   üìä Ablation Study (Hill Climbing):\n",
            "      Metric:         auc (‚Üë maximize)\n",
            "      Baseline CV:    -inf\n",
            "      Component CV:   0.9949\n",
            "      Improvement:    +inf\n",
            "      ‚úÖ Component ACCEPTED (positive improvement)\n",
            "Backup submission saved: submission_resnet50_classification.csv\n",
            "Updated baseline CV score: 0.9949\n",
            "Cached successful result for: resnet50_classification\n",
            "\n",
            "ADK Refinement Loop: Trying to improve score...\n",
            "Refinement Iteration 1/2\n",
            "Executing refined code...\n",
            "   ‚ö†Ô∏è  Code validation failed: Missing required output: 'Final Validation Performance: {score}'\n",
            "Refined code failed to execute\n",
            "Refinement Iteration 2/2\n",
            "Executing refined code...\n",
            "      üìã [LOG:FOLD] Starting fold 0\n",
            "      üìã [LOG:FOLD] Preprocessing pipeline fitted within fold 0\n",
            "      ‚è≥ Execution in progress... (34s elapsed, 2966s remaining)\n",
            "      ‚è≥ Execution in progress... (64s elapsed, 2936s remaining)\n",
            "      ‚è≥ Execution in progress... (94s elapsed, 2906s remaining)\n",
            "      ‚è≥ Execution in progress... (124s elapsed, 2876s remaining)\n",
            "      üìã [LOG:FOLD] Fold 0 Epoch 1/4 - Loss: 0.1475 LR: 0.000086\n",
            "      ‚è≥ Execution in progress... (179s elapsed, 2821s remaining)\n",
            "      ‚è≥ Execution in progress... (209s elapsed, 2791s remaining)\n",
            "      ‚è≥ Execution in progress... (239s elapsed, 2761s remaining)\n",
            "      ‚è≥ Execution in progress... (269s elapsed, 2731s remaining)\n",
            "      üìã [LOG:FOLD] Fold 0 Epoch 2/4 - Loss: 0.1249 LR: 0.000051\n",
            "      ‚è≥ Execution in progress... (326s elapsed, 2674s remaining)\n",
            "      ‚è≥ Execution in progress... (356s elapsed, 2644s remaining)\n",
            "      ‚è≥ Execution in progress... (386s elapsed, 2614s remaining)\n",
            "      ‚è≥ Execution in progress... (416s elapsed, 2584s remaining)\n",
            "      üìã [LOG:FOLD] Fold 0 Epoch 3/4 - Loss: 0.1105 LR: 0.000015\n",
            "      ‚è≥ Execution in progress... (474s elapsed, 2526s remaining)\n",
            "      ‚è≥ Execution in progress... (504s elapsed, 2496s remaining)\n",
            "      ‚è≥ Execution in progress... (534s elapsed, 2466s remaining)\n",
            "      ‚è≥ Execution in progress... (564s elapsed, 2436s remaining)\n",
            "      üìã [LOG:FOLD] Fold 0 Epoch 4/4 - Loss: 0.1076 LR: 0.000001\n",
            "      üìã [LOG:FOLD] Fold 0 Validation AUC: 0.999931\n",
            "      üìã [LOG:FOLD] Fold 0 test predictions aggregated\n",
            "      üìã [LOG:FOLD] Starting fold 1\n",
            "      üìã [LOG:FOLD] Preprocessing pipeline fitted within fold 1\n",
            "      ‚è≥ Execution in progress... (643s elapsed, 2357s remaining)\n",
            "      ‚è≥ Execution in progress... (673s elapsed, 2327s remaining)\n",
            "      ‚è≥ Execution in progress... (703s elapsed, 2297s remaining)\n",
            "      ‚è≥ Execution in progress... (733s elapsed, 2267s remaining)\n",
            "      üìã [LOG:FOLD] Fold 1 Epoch 1/4 - Loss: 0.1566 LR: 0.000086\n",
            "      ‚è≥ Execution in progress... (790s elapsed, 2210s remaining)\n",
            "      ‚è≥ Execution in progress... (821s elapsed, 2179s remaining)\n",
            "      ‚è≥ Execution in progress... (851s elapsed, 2149s remaining)\n",
            "      ‚è≥ Execution in progress... (881s elapsed, 2119s remaining)\n",
            "      üìã [LOG:FOLD] Fold 1 Epoch 2/4 - Loss: 0.1218 LR: 0.000051\n",
            "      ‚è≥ Execution in progress... (938s elapsed, 2062s remaining)\n",
            "      ‚è≥ Execution in progress... (968s elapsed, 2032s remaining)\n",
            "      ‚è≥ Execution in progress... (998s elapsed, 2002s remaining)\n",
            "      ‚è≥ Execution in progress... (1028s elapsed, 1972s remaining)\n",
            "      üìã [LOG:FOLD] Fold 1 Epoch 3/4 - Loss: 0.1121 LR: 0.000015\n",
            "      ‚è≥ Execution in progress... (1085s elapsed, 1915s remaining)\n",
            "      ‚è≥ Execution in progress... (1115s elapsed, 1885s remaining)\n",
            "      ‚è≥ Execution in progress... (1145s elapsed, 1855s remaining)\n",
            "      ‚è≥ Execution in progress... (1175s elapsed, 1825s remaining)\n",
            "      üìã [LOG:FOLD] Fold 1 Epoch 4/4 - Loss: 0.1064 LR: 0.000001\n",
            "      üìã [LOG:FOLD] Fold 1 Validation AUC: 0.999969\n",
            "      üìã [LOG:FOLD] Fold 1 test predictions aggregated\n",
            "      üìã [LOG:FOLD] Starting fold 2\n",
            "      üìã [LOG:FOLD] Preprocessing pipeline fitted within fold 2\n",
            "      ‚è≥ Execution in progress... (1254s elapsed, 1746s remaining)\n",
            "      ‚è≥ Execution in progress... (1285s elapsed, 1715s remaining)\n",
            "      ‚è≥ Execution in progress... (1315s elapsed, 1685s remaining)\n",
            "      ‚è≥ Execution in progress... (1345s elapsed, 1655s remaining)\n",
            "      üìã [LOG:FOLD] Fold 2 Epoch 1/4 - Loss: 0.1535 LR: 0.000086\n",
            "      ‚è≥ Execution in progress... (1402s elapsed, 1598s remaining)\n",
            "      ‚è≥ Execution in progress... (1432s elapsed, 1568s remaining)\n",
            "      ‚è≥ Execution in progress... (1462s elapsed, 1538s remaining)\n",
            "      ‚è≥ Execution in progress... (1492s elapsed, 1508s remaining)\n",
            "      üìã [LOG:FOLD] Fold 2 Epoch 2/4 - Loss: 0.1274 LR: 0.000051\n",
            "      ‚è≥ Execution in progress... (1550s elapsed, 1450s remaining)\n",
            "      ‚è≥ Execution in progress... (1580s elapsed, 1420s remaining)\n",
            "      ‚è≥ Execution in progress... (1610s elapsed, 1390s remaining)\n",
            "      ‚è≥ Execution in progress... (1640s elapsed, 1360s remaining)\n",
            "      üìã [LOG:FOLD] Fold 2 Epoch 3/4 - Loss: 0.1164 LR: 0.000015\n",
            "      ‚è≥ Execution in progress... (1697s elapsed, 1303s remaining)\n",
            "      ‚è≥ Execution in progress... (1727s elapsed, 1273s remaining)\n",
            "      ‚è≥ Execution in progress... (1757s elapsed, 1243s remaining)\n",
            "      ‚è≥ Execution in progress... (1787s elapsed, 1213s remaining)\n",
            "      üìã [LOG:FOLD] Fold 2 Epoch 4/4 - Loss: 0.1083 LR: 0.000001\n",
            "      üìã [LOG:FOLD] Fold 2 Validation AUC: 0.999931\n",
            "      üìã [LOG:FOLD] Fold 2 test predictions aggregated\n",
            "      üìã [LOG:FOLD] Starting fold 3\n",
            "      üìã [LOG:FOLD] Preprocessing pipeline fitted within fold 3\n",
            "      ‚è≥ Execution in progress... (1866s elapsed, 1134s remaining)\n",
            "      ‚è≥ Execution in progress... (1896s elapsed, 1104s remaining)\n",
            "      ‚è≥ Execution in progress... (1926s elapsed, 1074s remaining)\n",
            "      ‚è≥ Execution in progress... (1956s elapsed, 1044s remaining)\n",
            "      üìã [LOG:FOLD] Fold 3 Epoch 1/4 - Loss: 0.1546 LR: 0.000086\n",
            "      ‚è≥ Execution in progress... (2014s elapsed, 986s remaining)\n",
            "      ‚è≥ Execution in progress... (2044s elapsed, 956s remaining)\n",
            "      ‚è≥ Execution in progress... (2074s elapsed, 926s remaining)\n",
            "      ‚è≥ Execution in progress... (2104s elapsed, 896s remaining)\n",
            "      üìã [LOG:FOLD] Fold 3 Epoch 2/4 - Loss: 0.1244 LR: 0.000051\n",
            "      ‚è≥ Execution in progress... (2162s elapsed, 838s remaining)\n",
            "      ‚è≥ Execution in progress... (2192s elapsed, 808s remaining)\n",
            "      ‚è≥ Execution in progress... (2222s elapsed, 778s remaining)\n",
            "      ‚è≥ Execution in progress... (2252s elapsed, 748s remaining)\n",
            "      üìã [LOG:FOLD] Fold 3 Epoch 3/4 - Loss: 0.1153 LR: 0.000015\n",
            "      ‚è≥ Execution in progress... (2309s elapsed, 691s remaining)\n",
            "      ‚è≥ Execution in progress... (2339s elapsed, 661s remaining)\n",
            "      ‚è≥ Execution in progress... (2369s elapsed, 631s remaining)\n",
            "      ‚è≥ Execution in progress... (2399s elapsed, 601s remaining)\n",
            "      üìã [LOG:FOLD] Fold 3 Epoch 4/4 - Loss: 0.1064 LR: 0.000001\n",
            "      üìã [LOG:FOLD] Fold 3 Validation AUC: 0.999909\n",
            "      üìã [LOG:FOLD] Fold 3 test predictions aggregated\n",
            "      üìã [LOG:FOLD] Starting fold 4\n",
            "      üìã [LOG:FOLD] Preprocessing pipeline fitted within fold 4\n",
            "      ‚è≥ Execution in progress... (2478s elapsed, 522s remaining)\n",
            "      ‚è≥ Execution in progress... (2508s elapsed, 492s remaining)\n",
            "      ‚è≥ Execution in progress... (2538s elapsed, 462s remaining)\n",
            "      ‚è≥ Execution in progress... (2568s elapsed, 432s remaining)\n",
            "      üìã [LOG:FOLD] Fold 4 Epoch 1/4 - Loss: 0.1595 LR: 0.000086\n",
            "      ‚è≥ Execution in progress... (2626s elapsed, 374s remaining)\n",
            "      ‚è≥ Execution in progress... (2656s elapsed, 344s remaining)\n",
            "      ‚è≥ Execution in progress... (2686s elapsed, 314s remaining)\n",
            "      ‚è≥ Execution in progress... (2716s elapsed, 284s remaining)\n",
            "      üìã [LOG:FOLD] Fold 4 Epoch 2/4 - Loss: 0.1264 LR: 0.000051\n",
            "      ‚è≥ Execution in progress... (2774s elapsed, 226s remaining)\n",
            "      ‚è≥ Execution in progress... (2804s elapsed, 196s remaining)\n",
            "      ‚è≥ Execution in progress... (2834s elapsed, 166s remaining)\n",
            "      ‚è≥ Execution in progress... (2864s elapsed, 136s remaining)\n",
            "      üìã [LOG:FOLD] Fold 4 Epoch 3/4 - Loss: 0.1173 LR: 0.000015\n",
            "      ‚è≥ Execution in progress... (2921s elapsed, 79s remaining)\n",
            "      ‚è≥ Execution in progress... (2951s elapsed, 49s remaining)\n",
            "      ‚è≥ Execution in progress... (2981s elapsed, 19s remaining)\n",
            "Refined code failed to execute\n",
            "Component timeout set to: 3000s (50.0 min)\n",
            "\u0005 DSPy configured with openai/gpt-5.1-codex-mini\n",
            "\u000f  No optimized prompts found for developer_generator\n",
            "\u000f  No optimized prompts found for developer_fixer\n",
            "Using base (unoptimized) generator module\n",
            "Using base (unoptimized) fixer module\n",
            "\n",
            "============================================================\n",
            "= DEVELOPER AGENT: Implementing Components\n",
            "============================================================\n",
            "\n",
            "= Implementing: tta_ensemble (ensemble)\n",
            "Estimated Impact: 15.0%\n",
            "Component timeout set to: 1200s (20.0 min)\n",
            "\n",
            "Generating code...\n",
            "\n",
            "Generated code preview:\n",
            "        1 | import json\n",
            "        2 | import os\n",
            "        3 | from pathlib import Path\n",
            "        4 | from typing import List, Optional, Tuple\n",
            "        5 | \n",
            "        6 | import numpy as np\n",
            "        7 | import pandas as pd\n",
            "        8 | from joblib import dump\n",
            "        9 | from sklearn.linear_model import LogisticRegression\n",
            "       10 | from sklearn.metrics import roc_auc_score\n",
            "       11 | \n",
            "       12 | \n",
            "       13 | def load_sample_submission(path: Path) -> Tuple[pd.DataFrame, str]:\n",
            "       14 |     print(f\"[INFO] Loading sample submission from {path}\")\n",
            "       15 |     if not path.exists():\n",
            "       16 |         raise FileNotFoundError(f\"Sample submission file not found: {path}\")\n",
            "       17 |     sample = pd.read_csv(path)\n",
            "       18 |     if sample.shape[1] < 2:\n",
            "       19 |         raise ValueError(f\"Sample submission should have at least two columns, found {sample.shape[1]}\")\n",
            "       20 |     pred_col = sample.columns[1]\n",
            "       21 |     print(f\"[INFO] Submission prediction column will be '{pred_col}'\")\n",
            "       22 |     return sample, pred_col\n",
            "       23 | \n",
            "       24 | \n",
            "       25 | def find_target_array(models_dir: Path) -> Optional[np.ndarray]:\n",
            "       26 |     target_candidates = [\n",
            "       27 |         \"oof_target.npy\",\n",
            "       28 |         \"targets.npy\",\n",
            "       29 |         \"y.npy\",\n",
            "       30 |         \"has_cactus.npy\",\n",
            "       31 |         \"train_targets.npy\",\n",
            "       32 |         \"train_labels.npy\",\n",
            "       33 |         \"labels.npy\",\n",
            "       34 |         \"y_valid.npy\",\n",
            "       35 |         \"y_train.npy\",\n",
            "       36 |     ]\n",
            "       37 |     for name in target_candidates:\n",
            "       38 |         target_path = models_dir / name\n",
            "       39 |         if target_path.exists():\n",
            "       40 |             target = np.load(target_path)\n",
            "       41 |             print(f\"[INFO] Loaded target array from {target_path}\")\n",
            "       42 |             return target.reshape(-1)\n",
            "       43 |     print(\"[WARN] No target array found in models directory.\")\n",
            "       44 |     return None\n",
            "       45 | \n",
            "       46 | \n",
            "       47 | def load_oof_files(models_dir: Path) -> List[Tuple[str, np.ndarray]]:\n",
            "       48 |     oof_paths = sorted(models_dir.glob(\"oof_*.npy\"))\n",
            "       49 |     oof_list = []\n",
            "       50 |     for path in oof_paths:\n",
            "       51 |         arr = np.load(path)\n",
            "       52 |         arr = arr.reshape(-1)\n",
            "       53 |         name = path.stem.replace(\"oof_\", \"\")\n",
            "       54 |         if name == \"\":\n",
            "       55 |             name = path.stem\n",
            "       56 |         print(f\"[INFO] Loaded OOF predictions from {path} (length {len(arr)}) as model '{name}'\")\n",
            "       57 |         oof_list.append((name, arr))\n",
            "       58 |     if not oof_list:\n",
            "       59 |         print(\"[WARN] No OOF files found for stacking.\")\n",
            "       60 |     return oof_list\n",
            "       61 | \n",
            "       62 | \n",
            "       63 | def find_test_prediction_for_model(\n",
            "       64 |     model_name: str, models_dir: Path, expected_len: int\n",
            "       65 | ) -> Optional[np.ndarray]:\n",
            "       66 |     candidate_patterns = [\n",
            "       67 |         f\"test_{model_name}.npy\",\n",
            "       68 |         f\"{model_name}_test.npy\",\n",
            "       69 |         f\"pred_{model_name}.npy\",\n",
            "       70 |         f\"{model_name}_pred.npy\",\n",
            "       71 |         f\"{model_name}.npy\",\n",
            "       72 |         f\"{model_name}_submission.npy\",\n",
            "       73 |         f\"{model_name}_prob.npy\",\n",
            "       74 |         f\"prob_{model_name}.npy\",\n",
            "       75 |     ]\n",
            "       76 |     for candidate in candidate_patterns:\n",
            "       77 |         candidate_path = models_dir / candidate\n",
            "       78 |         if candidate_path.exists():\n",
            "       79 |             arr = np.load(candidate_path).reshape(-1)\n",
            "       80 |             if len(arr) != expected_len:\n",
            "       81 |                 print(\n",
            "       82 |                     f\"[WARN] Candidate test file {candidate_path} has length {len(arr)} \"\n",
            "       83 |                     f\"but expected {expected_len}, skipping.\"\n",
            "       84 |                 )\n",
            "       85 |                 continue\n",
            "       86 |             print(f\"[INFO] Loaded test predictions from {candidate_path} for model '{model_name}'\")\n",
            "       87 |             return arr\n",
            "       88 |     # Last resort: search for any file containing model_name (excluding oof)\n",
            "       89 |     for path in models_dir.glob(f\"*{model_name}*.npy\"):\n",
            "       90 |         if \"oof\" in path.name.lower():\n",
            "       91 |             continue\n",
            "       92 |         arr = np.load(path).reshape(-1)\n",
            "       93 |         if len(arr) == expected_len:\n",
            "       94 |             print(f\"[INFO] Loaded test predictions from {path} (fallback search) for model '{model_name}'\")\n",
            "       95 |             return arr\n",
            "       96 |     print(f\"[WARN] Could not find test predictions for model '{model_name}'\")\n",
            "       97 |     return None\n",
            "       98 | \n",
            "       99 | \n",
            "      100 | def stack_oof_predictions(\n",
            "      101 |     oof_list: List[Tuple[str, np.ndarray]]\n",
            "      102 | ) -> Tuple[np.ndarray, List[str]]:\n",
            "      103 |     names = [name for name, _ in oof_list]\n",
            "      104 |     stacked = np.column_stack([arr for _, arr in oof_list])\n",
            "      105 |     print(f\"[INFO] Constructed OOF stack with shape {stacked.shape}\")\n",
            "      106 |     return stacked, names\n",
            "      107 | \n",
            "      108 | \n",
            "      109 | def train_meta_model(oof_stack: np.ndarray, target: np.ndarray) -> LogisticRegression:\n",
            "      110 |     print(\"[INFO] Training meta-model (LogisticRegression) on stacked OOF predictions\")\n",
            "      111 |     meta_model = LogisticRegression(max_iter=2000, solver=\"lbfgs\")\n",
            "      112 |     meta_model.fit(oof_stack, target)\n",
            "      113 |     pred = meta_model.predict_proba(oof_stack)[:, 1]\n",
            "      114 |     auc = roc_auc_score(target, pred)\n",
            "      115 |     print(f\"[INFO] Meta-model training complete. OOF ROC AUC = {auc:.5f}\")\n",
            "      116 |     return meta_model\n",
            "      117 | \n",
            "      118 | \n",
            "      119 | def stacking_ensemble(\n",
            "      120 |     models_dir: Path, sample_len: int\n",
            "      121 | ) -> Optional[Tuple[np.ndarray, List[str], LogisticRegression]]:\n",
            "      122 |     oof_list = load_oof_files(models_dir)\n",
            "      123 |     if not oof_list:\n",
            "      124 |         return None\n",
            "      125 |     target_array = find_target_array(models_dir)\n",
            "      126 |     if target_array is None or len(target_array) != len(oof_list[0][1]):\n",
            "      127 |         print(\"[WARN] Unable to use stacking because target array is missing or mismatched.\")\n",
            "      128 |         return None\n",
            "      129 |     oof_stack, model_names = stack_oof_predictions(oof_list)\n",
            "      130 |     meta_model = train_meta_model(oof_stack, target_array)\n",
            "      131 |     test_stack_cols = []\n",
            "      132 |     for name in model_names:\n",
            "      133 |         test_pred = find_test_prediction_for_model(name, models_dir, sample_len)\n",
            "      134 |         if test_pred is None:\n",
            "      135 |             print(\"[WARN] Missing test predictions for stacking. Falling back.\")\n",
            "      136 |             return None\n",
            "      137 |         test_stack_cols.append(test_pred)\n",
            "      138 |     test_stack = np.column_stack(test_stack_cols)\n",
            "      139 |     print(f\"[INFO] Stacked test predictions shape: {test_stack.shape}\")\n",
            "      140 |     test_preds = meta_model.predict_proba(test_stack)[:, 1]\n",
            "      141 |     print(\"[INFO] Stacking ensemble completed.\")\n",
            "      142 |     return test_preds, model_names, meta_model\n",
            "      143 | \n",
            "      144 | \n",
            "      145 | def fallback_weighted_average(\n",
            "      146 |     models_dir: Path, sample_len: int, pred_col: str, sample_submission: pd.DataFrame\n",
            "      147 | ) -> Optional[Tuple[np.ndarray, List[str], List[float]]]:\n",
            "      148 |     submission_files = sorted(models_dir.glob(\"*.csv\"))\n",
            "      149 |     contributions = []\n",
            "      150 |     preds_arrays = []\n",
            "      151 |     for sub_file in submission_files:\n",
            "      152 |         try:\n",
            "      153 |             sub_df = pd.read_csv(sub_file)\n",
            "      154 |         except pd.errors.EmptyDataError:\n",
            "      155 |             continue\n",
            "      156 |         if sample_submission.shape[0] != sub_df.shape[0]:\n",
            "      157 |             print(f\"[WARN] Submission {sub_file} length mismatch ({sub_df.shape[0]} vs {sample_len}), skipping.\")\n",
            "      158 |             continue\n",
            "      159 |         if pred_col not in sub_df.columns:\n",
            "      160 |             print(f\"[WARN] Submission {sub_file} missing column '{pred_col}', skipping.\")\n",
            "      161 |             continue\n",
            "      162 |         preds = sub_df[pred_col].values.reshape(-1)\n",
            "      163 |         if preds.shape[0] != sample_len:\n",
            "      164 |             continue\n",
            "      165 |         preds_arrays.append((sub_file.stem, preds))\n",
            "      166 |     if not preds_arrays:\n",
            "      167 |         print(\"[WARN] No valid submission CSVs found for fallback.\")\n",
            "      168 |         return None\n",
            "      169 |     weight = 1.0 / len(preds_arrays)\n",
            "      170 |     final_arr = np.zeros(sample_len, dtype=np.float64)\n",
            "      171 |     names = []\n",
            "      172 |     weights = []\n",
            "      173 |     for name, arr in preds_arrays:\n",
            "      174 |         final_arr += weight * arr\n",
            "      175 |         names.append(name)\n",
            "      176 |         weights.append(weight)\n",
            "      177 |     print(f\"[INFO] Weighted average fallback used with {len(names)} submissions.\")\n",
            "      178 |     return final_arr, names, weights\n",
            "      179 | \n",
            "      180 | \n",
            "      181 | def save_submission(submit_df: pd.DataFrame, output_path: Path):\n",
            "      182 |     output_path.parent.mkdir(parents=True, exist_ok=True)\n",
            "      183 |     submit_df.to_csv(output_path, index=False)\n",
            "      184 |     print(f\"[INFO] Submission saved to {output_path}\")\n",
            "      185 | \n",
            "      186 | \n",
            "      187 | def main():\n",
            "      188 |     models_dir = Path(\"/content/kaggle_competitions/competitions/aerial-cactus-identification/models\")\n",
            "      189 |     sample_submission_path = Path(\n",
            "      190 |         \"/content/kaggle_competitions/competitions/aerial-cactus-identification/sample_submission.csv\"\n",
            "      191 |     )\n",
            "      192 |     submission_output_path = Path(\n",
            "      193 |         \"/content/kaggle_competitions/competitions/aerial-cactus-identification/sample_submission.csv\"\n",
            "      194 |     )\n",
            "      195 | \n",
            "      196 |     sample_submission, pred_col = load_sample_submission(sample_submission_path)\n",
            "      197 |     sample_len = sample_submission.shape[0]\n",
            "      198 |     print(\"[INFO] Attempting stacking ensemble using OOF predictions...\")\n",
            "      199 |     stacking_result = stacking_ensemble(models_dir, sample_len)\n",
            "      200 |     final_predictions = None\n",
            "      201 |     meta_model = None\n",
            "      202 | \n",
            "      203 |     if stacking_result is not None:\n",
            "      204 |         final_predictions, model_names, meta_model = stacking_result\n",
            "      205 |         print(\"[INFO] Models contributing to stacking ensemble and their meta-model weights:\")\n",
            "      206 |         for name, weight in zip(model_names, meta_model.coef_[0]):\n",
            "      207 |             print(f\"  - {name}: coef = {weight:.5f}\")\n",
            "      208 |         dump(meta_model, models_dir / \"tta_ensemble_meta.pkl\")\n",
            "      209 |         print(f\"[INFO] Meta-model saved to {models_dir / 'tta_ensemble_meta.pkl'}\")\n",
            "      210 |     else:\n",
            "      211 |         print(\"[INFO] Stacking ensemble unavailable. Falling back to weighted averaging of submissions.\")\n",
            "      212 |         fallback_result = fallback_weighted_average(models_dir, sample_len, pred_col, sample_submission)\n",
            "      213 |         if fallback_result is None:\n",
            "      214 |             raise RuntimeError(\"Failed to construct ensemble: no stacking or fallback predictions available.\")\n",
            "      215 |         final_predictions, names, weights = fallback_result\n",
            "      216 |         print(\"[INFO] Weighted fallback contributions:\")\n",
            "      217 |         for name, weight in zip(names, weights):\n",
            "      218 |             print(f\"  - {name}: weight = {weight:.4f}\")\n",
            "      219 | \n",
            "      220 |     if final_predictions is None:\n",
            "      221 |         raise RuntimeError(\"Final predictions are not available.\")\n",
            "      222 | \n",
            "      223 |     if final_predictions.shape[0] != sample_len:\n",
            "      224 |         raise ValueError(\"Final prediction length mismatch.\")\n",
            "      225 | \n",
            "      226 |     submission_df = sample_submission.copy()\n",
            "      227 |     submission_df[pred_col] = final_predictions\n",
            "      228 |     save_submission(submission_df, submission_output_path)\n",
            "      229 |     print(\"[INFO] TTA ensemble pipeline complete.\")\n",
            "      230 | \n",
            "      231 | \n",
            "      232 | if __name__ == \"__main__\":\n",
            "      233 |     main()\n",
            "\n",
            "Code saved to: generated_code_tta_ensemble.py\n",
            "\n",
            "Executing code...\n",
            "\n",
            "Attempt 1/3\n",
            "   ‚ö†Ô∏è  Code validation failed: Missing required output: 'Final Validation Performance: {score}'\n",
            "Execution failed: Missing required output: 'Final Validation Performance: {score}'\n",
            "\n",
            "Getting meta-evaluator feedback...\n",
            "Meta-Feedback:\n",
            "1. Root cause: No code path emits the required log `Final Validation Performance: {score}` after training, so verifier can‚Äôt find it.  \n",
            "2. Fix: After computing `auc` in `train_meta_model`, add `print(f\"Final Validation Performance: {auc:.5f}\")` before returning. Ensure this print only occurs when stacking runs (maybe guard with flag) so message always appears once per run.  \n",
            "3. Best practices: Define a logging helper that formats required outputs for all pipelines, and centralize performance reporting so future metrics can‚Äôt be missed; include automated tests that scan logs for mandatory strings.\n",
            "\n",
            "Passing error context to fixer: Missing required output: 'Final Validation Performance: {score}'\n",
            "Attempting to fix...\n",
            "\n",
            "Attempt 2/3\n",
            "      [INFO] Loading sample submission from /content/kaggle_competitions/competitions/aerial-cactus-identification/sample_submission.csv\n",
            "      ‚ö†Ô∏è Traceback (most recent call last):\n",
            "      ‚ö†Ô∏è   File \"/content/kaggle_competitions/competitions/aerial-cactus-identification/_exec_1765152799.py\", line 235, in <module>\n",
            "      ‚ö†Ô∏è     main()\n",
            "      ‚ö†Ô∏è   File \"/content/kaggle_competitions/competitions/aerial-cactus-identification/_exec_1765152799.py\", line 216, in main\n",
            "      ‚ö†Ô∏è     raise RuntimeError(\"Failed to construct ensemble: no stacking or fallback predictions available.\")\n",
            "      ‚ö†Ô∏è RuntimeError: Failed to construct ensemble: no stacking or fallback predictions available.\n",
            "Execution failed: raise RuntimeError(\"Failed to construct ensemble: no stacking or fallback predictions available.\")\n",
            "Passing error context to fixer: raise RuntimeError(\"Failed to construct ensemble: no stacking or fallback predictions available.\")\n",
            "Attempting to fix...\n",
            "\n",
            "Attempt 3/3\n",
            "      [INFO] Loading sample submission from /content/kaggle_competitions/competitions/aerial-cactus-identification/sample_submission.csv\n",
            "      [INFO] Submission saved to /content/kaggle_competitions/competitions/aerial-cactus-identification/sample_submission.csv\n",
            "      [INFO] TTA ensemble pipeline complete.\n",
            "   ‚ö†Ô∏è  Warning: Could not extract performance metric from output\n",
            "Execution successful (1.51s)\n",
            "Cached successful result for: tta_ensemble\n",
            "\n",
            "============================================================\n",
            "=\u000f  ROBUSTNESS AGENT: Validating Code\n",
            "============================================================\n",
            "\n",
            "Running validation modules...\n",
            "\n",
            "\u0005 DEBUGGING: 100.0%\n",
            "   ‚úÖ No Data Leakage: Code only loads stored OOF predictions and targets for meta-model training without fitting on validation/test data, so no leakage detected.\n",
            "\n",
            "\u0005 LEAKAGE: 100.0%\n",
            "\n",
            "\u0005 DATA_USAGE: 100.0%\n",
            "\n",
            "\u0005 FORMAT: 100.0%\n",
            "\n",
            "= Overall Validation Score: 100.0%\n",
            "\u0005 Validation PASSED (threshold: 70.0%)\n",
            "\n",
            "============================================================\n",
            "ENSEMBLE AGENT: Creating Model Ensemble\n",
            "============================================================\n",
            "\n",
            "   üìä Ensemble Prerequisites Check:\n",
            "      Total development results: 4\n",
            "      Successful results: 3\n",
            "      Models trained count: 0\n",
            "\n",
            "   ‚úÖ Successful components:\n",
            "      1. none\n",
            "      2. none\n",
            "      3. none\n",
            "\n",
            "   ‚ö†Ô∏è  Not enough models for ensemble (need 2+, have 0)\n",
            "      Reason: Ensemble requires at least 2 trained models\n",
            "      Skipping ensemble step\n",
            "\n",
            "============================================================\n",
            "üì§ SUBMISSION AGENT: Uploading to Kaggle\n",
            "============================================================\n",
            "\n",
            "üìÑ Submission file: submission.csv\n",
            "‚úÖ Validation passed\n",
            "‚ö†Ô∏è  Auto-submit is disabled (set KAGGLE_AUTO_SUBMIT=true)\n",
            "\n",
            "============================================================\n",
            "= PERFORMANCE EVALUATION\n",
            "============================================================\n",
            "\n",
            "Current Score: 0.0000\n",
            "Target Score:  0.9238\n",
            "Gap:           0.9238\n",
            "\n",
            "üìà Component Success Rate: 3/4 (75%)\n",
            "\n",
            "üîÑ Refinement needed (gap: 0.9238)\n",
            "   üß† Meta-Evaluator initialized with OPENAI (gpt-5.1-codex-mini)\n",
            "\n",
            "============================================================\n",
            "= META-EVALUATOR: Analyzing Performance & Optimizing Prompts\n",
            "============================================================\n",
            "\n",
            "üìä Iteration: 0\n",
            "\n",
            "   üîç Analyzing component failures...\n",
            "   ‚úÖ Success: 3/4 (75.0%)\n",
            "   ‚ùå Failed: 1/4\n",
            "   üìã Error patterns: timeout_error\n",
            "\n",
            "   üí∞ Calculating reward signals...\n",
            "   üìä Rewards: functional=0.75, performance=0.00, diversity=1.00, robustness=1.00, combined=0.387\n",
            "\n",
            "   üéØ Generating refinement guidance...\n",
            "   ‚úì Generated guidance for Planner and Developer\n",
            "\n",
            "   üíæ Collecting training data for prompt optimization...\n",
            "\u0005 Added training example for planner (score: 0.3875)\n",
            "\u0005 Added training example for developer_generator (score: 1.0000)\n",
            "\u0005 Added training example for developer_generator (score: 0.0000)\n",
            "\u0005 Added training example for developer_generator (score: 1.0000)\n",
            "   ‚úì Collected training examples for Planner and Developer\n",
            "\n",
            "============================================================\n",
            "=\u0004 ITERATION CONTROL\n",
            "============================================================\n",
            "\n",
            "Iteration: 1/3\n",
            "   Best Score: 0.0000\n",
            "   Target: Top 20.0%\n",
            "\n",
            "üîÄ Routing decision:\n",
            "   Current iteration: 1\n",
            "   Max iterations: 3\n",
            "   Needs refinement: True\n",
            "   ‚û°Ô∏è  Refining (iteration 1)\n",
            "\u0005 DSPy configured with openai/gpt-5.1-codex-mini\n",
            "\u000f  No optimized prompts found for planner\n",
            "   No optimized planner module found -> using direct LLM path\n",
            "\n",
            "============================================================\n",
            "= PLANNER AGENT: Creating Ablation Plan\n",
            "============================================================\n",
            "\n",
            "Analyzing SOTA patterns...\n",
            "   Found 4 common models\n",
            "   Found 4 feature patterns\n",
            "\n",
            "üìù Generating ablation plan...\n",
            "\n",
            "üß† CURRICULUM LEARNING INSIGHTS (from previous iterations):\n",
            "\n",
            "‚úÖ What Worked (prioritize these approaches):\n",
            "   - unknown_success\n",
            "   - model_success\n",
            "   - ensemble_success\n",
            "\n",
            "‚ùå What Failed (avoid these approaches):\n",
            "   - timeout_error\n",
            "  üîß Using fallback plan (ensures 5 high-quality components)\n",
            "  üìä Final plan: 0 FE + 2 models + 1 ensemble = 3 total\n",
            "\n",
            "= Ablation Plan Created: 3 components\n",
            "------------------------------------------------------------\n",
            "\n",
            "1. efficientnet_b0_classification (model)\n",
            "   Estimated Impact: 28.0%\n",
            "   Code: torchvision.models.efficientnet_b0(pretrained=True), replace classifier head, tr...\n",
            "\n",
            "2. resnet50_classification (model)\n",
            "   Estimated Impact: 24.0%\n",
            "   Code: torchvision.models.resnet50(pretrained=True), replace fc layer, Cutout + Mixup a...\n",
            "\n",
            "3. tta_ensemble (ensemble)\n",
            "   Estimated Impact: 15.0%\n",
            "   Code: For each test image: apply 5 transforms (original, hflip, vflip, rotate90, rotat...\n",
            "\n",
            "============================================================\n",
            "Component timeout set to: 3000s (50.0 min)\n",
            "\u0005 DSPy configured with openai/gpt-5.1-codex-mini\n",
            "\u000f  No optimized prompts found for developer_generator\n",
            "\u000f  No optimized prompts found for developer_fixer\n",
            "Using base (unoptimized) generator module\n",
            "Using base (unoptimized) fixer module\n",
            "\n",
            "============================================================\n",
            "= DEVELOPER AGENT: Implementing Components\n",
            "============================================================\n",
            "All components implemented!\n",
            "\n",
            "============================================================\n",
            "=\u000f  ROBUSTNESS AGENT: Validating Code\n",
            "============================================================\n",
            "\n",
            "Running validation modules...\n",
            "\n",
            "\u0005 DEBUGGING: 100.0%\n",
            "   ‚úÖ No Data Leakage: Stacking uses only OOF predictions with a separate target file to train the meta-model, so no validation/test data is used during training and no preprocessing or target leakage is evident.\n",
            "\n",
            "\u0005 LEAKAGE: 100.0%\n",
            "\n",
            "\u0005 DATA_USAGE: 100.0%\n",
            "\n",
            "\u0005 FORMAT: 100.0%\n",
            "\n",
            "= Overall Validation Score: 100.0%\n",
            "\u0005 Validation PASSED (threshold: 70.0%)\n",
            "\n",
            "============================================================\n",
            "ENSEMBLE AGENT: Creating Model Ensemble\n",
            "============================================================\n",
            "\n",
            "   üìä Ensemble Prerequisites Check:\n",
            "      Total development results: 4\n",
            "      Successful results: 3\n",
            "      Models trained count: 0\n",
            "\n",
            "   ‚úÖ Successful components:\n",
            "      1. none\n",
            "      2. none\n",
            "      3. none\n",
            "\n",
            "   ‚ö†Ô∏è  Not enough models for ensemble (need 2+, have 0)\n",
            "      Reason: Ensemble requires at least 2 trained models\n",
            "      Skipping ensemble step\n",
            "\n",
            "============================================================\n",
            "üì§ SUBMISSION AGENT: Uploading to Kaggle\n",
            "============================================================\n",
            "\n",
            "üìÑ Submission file: submission.csv\n",
            "‚úÖ Validation passed\n",
            "‚ö†Ô∏è  Auto-submit is disabled (set KAGGLE_AUTO_SUBMIT=true)\n",
            "\n",
            "============================================================\n",
            "= PERFORMANCE EVALUATION\n",
            "============================================================\n",
            "\n",
            "Current Score: 0.0000\n",
            "Target Score:  0.9238\n",
            "Gap:           0.9238\n",
            "\n",
            "üìà Component Success Rate: 3/4 (75%)\n",
            "\n",
            "üîÑ Refinement needed (gap: 0.9238)\n",
            "   üß† Meta-Evaluator initialized with OPENAI (gpt-5.1-codex-mini)\n",
            "\n",
            "============================================================\n",
            "= META-EVALUATOR: Analyzing Performance & Optimizing Prompts\n",
            "============================================================\n",
            "\n",
            "üìä Iteration: 1\n",
            "\n",
            "   üîç Analyzing component failures...\n",
            "   ‚úÖ Success: 3/4 (75.0%)\n",
            "   ‚ùå Failed: 1/4\n",
            "   üìã Error patterns: timeout_error\n",
            "\n",
            "   üí∞ Calculating reward signals...\n",
            "   üìä Rewards: functional=0.75, performance=0.00, diversity=1.00, robustness=1.00, combined=0.387\n",
            "\n",
            "   üéØ Generating refinement guidance...\n",
            "   ‚úì Generated guidance for Planner and Developer\n",
            "\n",
            "   üíæ Collecting training data for prompt optimization...\n",
            "\u0005 Added training example for planner (score: 0.3875)\n",
            "\u0005 Added training example for developer_generator (score: 1.0000)\n",
            "\u0005 Added training example for developer_generator (score: 0.0000)\n",
            "\u0005 Added training example for developer_generator (score: 1.0000)\n",
            "   ‚úì Collected training examples for Planner and Developer\n",
            "\n",
            "============================================================\n",
            "=\u0004 ITERATION CONTROL\n",
            "============================================================\n",
            "\n",
            "Iteration: 2/3\n",
            "   Best Score: 0.0000\n",
            "   Target: Top 20.0%\n",
            "   üîÑ Starting refinement iteration - resetting component index\n",
            "\n",
            "üîÄ Routing decision:\n",
            "   Current iteration: 2\n",
            "   Max iterations: 3\n",
            "   Needs refinement: True\n",
            "   ‚û°Ô∏è  Refining (iteration 2)\n",
            "\u0005 DSPy configured with openai/gpt-5.1-codex-mini\n",
            "\u000f  No optimized prompts found for planner\n",
            "   No optimized planner module found -> using direct LLM path\n",
            "\n",
            "============================================================\n",
            "= PLANNER AGENT: Refining Ablation Plan (RL-based)\n",
            "============================================================\n",
            "\n",
            "Analyzing SOTA patterns...\n",
            "   Found 3 common models\n",
            "   Found 4 feature patterns\n",
            "\n",
            "üîÑ Refining plan based on previous results...\n",
            "  üß† Injected Meta-Evaluator guidance into prompt\n",
            "  ‚ö†Ô∏è  Refinement failed: No module named 'langchain.schema'\n",
            "  üîß Using enhanced fallback with refinement logic\n",
            "  üìä Final plan: 1 FE + 2 models + 1 ensemble = 4 total\n",
            "\n",
            "= Ablation Plan Created: 4 components\n",
            "------------------------------------------------------------\n",
            "\n",
            "1. advanced_feature_engineering (feature_engineering)\n",
            "   Estimated Impact: 15.0%\n",
            "   Code: Pipeline with ColumnTransformer, SimpleImputer, OneHot/TargetEncoder, interactio...\n",
            "\n",
            "2. efficientnet_b0_classification (model)\n",
            "   Estimated Impact: 28.0%\n",
            "   Code: torchvision.models.efficientnet_b0(pretrained=True), replace classifier head, tr...\n",
            "\n",
            "3. lightgbm_fast_cv (model)\n",
            "   Estimated Impact: 20.0%\n",
            "   Code: ColumnTransformer + LGBMClassifier(num_leaves=63, learning_rate=0.03, n_estimato...\n",
            "\n",
            "4. tta_ensemble (ensemble)\n",
            "   Estimated Impact: 15.0%\n",
            "   Code: For each test image: apply 5 transforms (original, hflip, vflip, rotate90, rotat...\n",
            "\n",
            "============================================================\n",
            "Component timeout set to: 3000s (50.0 min)\n",
            "\u0005 DSPy configured with openai/gpt-5.1-codex-mini\n",
            "\u000f  No optimized prompts found for developer_generator\n",
            "\u000f  No optimized prompts found for developer_fixer\n",
            "Using base (unoptimized) generator module\n",
            "Using base (unoptimized) fixer module\n",
            "\n",
            "============================================================\n",
            "= DEVELOPER AGENT: Implementing Components\n",
            "============================================================\n",
            "\n",
            "= Implementing: advanced_feature_engineering (feature_engineering)\n",
            "Estimated Impact: 15.0%\n",
            "Component timeout set to: 900s (15.0 min)\n",
            "\n",
            "Generating code...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025/12/08 00:26:03 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Generated code preview:\n",
            "        1 | import argparse\n",
            "        2 | import hashlib\n",
            "        3 | import json\n",
            "        4 | import logging\n",
            "        5 | import math\n",
            "        6 | import os\n",
            "        7 | import pickle\n",
            "        8 | import time\n",
            "        9 | from datetime import datetime\n",
            "       10 | from pathlib import Path\n",
            "       11 | \n",
            "       12 | import joblib\n",
            "       13 | import numpy as np\n",
            "       14 | import pandas as pd\n",
            "       15 | from PIL import Image\n",
            "       16 | from lightgbm import LGBMClassifier\n",
            "       17 | from sklearn.model_selection import StratifiedKFold\n",
            "       18 | from tqdm import tqdm\n",
            "       19 | \n",
            "       20 | \n",
            "       21 | class Watchdog:\n",
            "       22 |     def __init__(self, total_seconds: int, checkpoint_interval: int = 60):\n",
            "       23 |         self.start = time.time()\n",
            "       24 |         self.total = total_seconds\n",
            "       25 |         self.checkpoint_interval = checkpoint_interval\n",
            "       26 | \n",
            "       27 |     def elapsed(self) -> float:\n",
            "       28 |         return time.time() - self.start\n",
            "       29 | \n",
            "       30 |     def remaining(self) -> float:\n",
            "       31 |         return max(self.total - self.elapsed(), 0.0)\n",
            "       32 | \n",
            "       33 |     def should_checkpoint(self) -> bool:\n",
            "       34 |         return self.remaining() < self.checkpoint_interval\n",
            "       35 | \n",
            "       36 |     def log_status(self, stage: str) -> None:\n",
            "       37 |         logging.debug(\"[%s] elapsed=%0.1fs remaining=%0.1fs\", stage, self.elapsed(), self.remaining())\n",
            "       38 | \n",
            "       39 | \n",
            "       40 | def configure_logging():\n",
            "       41 |     logging.basicConfig(\n",
            "       42 |         level=logging.INFO,\n",
            "       43 |         format=\"%(asctime)s [%(levelname)s] %(message)s\",\n",
            "       44 |         handlers=[logging.StreamHandler()],\n",
            "       45 |     )\n",
            "       46 | \n",
            "       47 | \n",
            "       48 | def parse_args():\n",
            "       49 |     parser = argparse.ArgumentParser(description=\"advanced_feature_engineering for aerial-cactus-identification\")\n",
            "       50 |     parser.add_argument(\"--mode\", choices=[\"debug\", \"full\"], default=\"debug\", help=\"execution mode\")\n",
            "       51 |     parser.add_argument(\"--force\", action=\"store_true\", help=\"force recompute even when cached artifacts exist\")\n",
            "       52 |     parser.add_argument(\n",
            "       53 |         \"--data-root\",\n",
            "       54 |         type=str,\n",
            "       55 |         default=\"/content/kaggle_competitions/competitions/aerial-cactus-identification\",\n",
            "       56 |         help=\"base directory for competition data\",\n",
            "       57 |     )\n",
            "       58 |     parser.add_argument(\n",
            "       59 |         \"--max-time\",\n",
            "       60 |         type=int,\n",
            "       61 |         default=900,\n",
            "       62 |         help=\"total allotted seconds before graceful exit\",\n",
            "       63 |     )\n",
            "       64 |     return parser.parse_args()\n",
            "       65 | \n",
            "       66 | \n",
            "       67 | def ensure_dir(path: Path):\n",
            "       68 |     path.mkdir(parents=True, exist_ok=True)\n",
            "       69 | \n",
            "       70 | \n",
            "       71 | def find_csv_with_label(path: Path, required_cols=None):\n",
            "       72 |     if required_cols is None:\n",
            "       73 |         required_cols = {\"id\", \"has_cactus\"}\n",
            "       74 |     candidates = list(path.glob(\"*.csv\"))\n",
            "       75 |     for candidate in candidates:\n",
            "       76 |         try:\n",
            "       77 |             df = pd.read_csv(candidate)\n",
            "       78 |         except Exception:\n",
            "       79 |             continue\n",
            "       80 |         if required_cols.issubset(set(df.columns)):\n",
            "       81 |             logging.info(\"Found train CSV: %s\", candidate)\n",
            "       82 |             return candidate\n",
            "       83 |     raise FileNotFoundError(f\"No qualifying CSV in {path}\")\n",
            "       84 | \n",
            "       85 | \n",
            "       86 | def map_images(image_path: Path):\n",
            "       87 |     image_map = {}\n",
            "       88 |     for ext in (\"*.jpg\", \"*.jpeg\", \"*.png\", \"*.bmp\"):\n",
            "       89 |         for img in image_path.rglob(ext):\n",
            "       90 |             image_map[img.name] = img\n",
            "       91 |     logging.info(\"Indexed %d images under %s\", len(image_map), image_path)\n",
            "       92 |     return image_map\n",
            "       93 | \n",
            "       94 | \n",
            "       95 | def resolve_image_path(image_name: str, image_map: dict, fallback_dir: Path):\n",
            "       96 |     candidate = image_map.get(image_name)\n",
            "       97 |     if candidate:\n",
            "       98 |         return candidate\n",
            "       99 |     for ext in (\".jpg\", \".jpeg\", \".png\", \".bmp\"):\n",
            "      100 |         candidate = image_map.get(f\"{image_name}{ext}\")\n",
            "      101 |         if candidate:\n",
            "      102 |             return candidate\n",
            "      103 |     fallback = fallback_dir / image_name\n",
            "      104 |     if fallback.exists():\n",
            "      105 |         return fallback\n",
            "      106 |     raise FileNotFoundError(f\"Missing image {image_name}\")\n",
            "      107 | \n",
            "      108 | \n",
            "      109 | def compute_image_features(image_path: Path, target_size: int):\n",
            "      110 |     with Image.open(image_path) as img:\n",
            "      111 |         img = img.convert(\"RGB\")\n",
            "      112 |         if target_size:\n",
            "      113 |             img = img.resize((target_size, target_size), Image.LANCZOS)\n",
            "      114 |         arr = np.array(img, dtype=np.float32)\n",
            "      115 |     stats = {\n",
            "      116 |         \"pixels\": arr.shape[0] * arr.shape[1],\n",
            "      117 |         \"brightness_mean\": arr.mean(),\n",
            "      118 |         \"brightness_std\": arr.std(),\n",
            "      119 |     }\n",
            "      120 |     channels = [\"r\", \"g\", \"b\"]\n",
            "      121 |     for idx, channel in enumerate(channels):\n",
            "      122 |         ch = arr[:, :, idx]\n",
            "      123 |         stats[f\"mean_{channel}\"] = ch.mean()\n",
            "      124 |         stats[f\"std_{channel}\"] = ch.std()\n",
            "      125 |         stats[f\"channel_max_{channel}\"] = ch.max()\n",
            "      126 |         stats[f\"channel_min_{channel}\"] = ch.min()\n",
            "      127 |         if stats[f\"std_{channel}\"] > 0:\n",
            "      128 |             stats[f\"contrast_{channel}\"] = stats[f\"std_{channel}\"] / (stats[f\"mean_{channel}\"] + 1e-6)\n",
            "      129 |         else:\n",
            "      130 |             stats[f\"contrast_{channel}\"] = 0.0\n",
            "      131 |         hist, _ = np.histogram(ch, bins=8, range=(0, 255))\n",
            "      132 |         hist = hist.astype(np.float32)\n",
            "      133 |         denom = hist.sum()\n",
            "      134 |         if denom > 0:\n",
            "      135 |             hist /= denom\n",
            "      136 |         for bin_idx, val in enumerate(hist):\n",
            "      137 |             stats[f\"hist_{channel}_{bin_idx}\"] = float(val)\n",
            "      138 |     brightness = arr.mean(axis=2)\n",
            "      139 |     stats[\"pct_bright\"] = float((brightness > 200).sum() / brightness.size)\n",
            "      140 |     stats[\"pct_dark\"] = float((brightness < 50).sum() / brightness.size)\n",
            "      141 |     high_variance = (arr.std(axis=2) > 40).sum()\n",
            "      142 |     stats[\"edge_density\"] = float(high_variance / brightness.size)\n",
            "      143 |     stats[\"texture_ratio\"] = float(np.std(brightness) / (np.mean(brightness) + 1e-6))\n",
            "      144 |     return stats\n",
            "      145 | \n",
            "      146 | \n",
            "      147 | def build_feature_dataframe(\n",
            "      148 |     identifiers,\n",
            "      149 |     image_map,\n",
            "      150 |     image_dir,\n",
            "      151 |     base_df,\n",
            "      152 |     target_col,\n",
            "      153 |     limit,\n",
            "      154 |     target_size,\n",
            "      155 |     watchdog,\n",
            "      156 |     dataset_name,\n",
            "      157 | ):\n",
            "      158 |     records = []\n",
            "      159 |     iterator = identifiers[:limit] if limit else identifiers\n",
            "      160 |     for idx, ident in enumerate(tqdm(iterator, desc=f\"Extracting {dataset_name}\")):\n",
            "      161 |         if watchdog.should_checkpoint():\n",
            "      162 |             watchdog.log_status(dataset_name)\n",
            "      163 |         image_path = resolve_image_path(ident, image_map, image_dir)\n",
            "      164 |         feats = compute_image_features(image_path, target_size)\n",
            "      165 |         feats[\"id\"] = ident\n",
            "      166 |         if base_df is not None:\n",
            "      167 |             feats[target_col] = base_df.loc[base_df[\"id\"] == ident, target_col].values[0]\n",
            "      168 |         records.append(feats)\n",
            "      169 |     return pd.DataFrame(records)\n",
            "      170 | \n",
            "      171 | \n",
            "      172 | def assign_metadata(df: pd.DataFrame):\n",
            "      173 |     df[\"id_prefix\"] = df[\"id\"].str[:4]\n",
            "      174 |     df[\"hash_bucket\"] = (\n",
            "      175 |         df[\"id\"].apply(lambda x: int(hashlib.md5(x.encode()).hexdigest(), 16) % 10).astype(str)\n",
            "      176 |     )\n",
            "      177 | \n",
            "      178 | \n",
            "      179 | def build_brightness_buckets(train_df: pd.DataFrame, test_df: pd.DataFrame):\n",
            "      180 |     brightness = train_df[\"brightness_mean\"]\n",
            "      181 |     quantiles = np.quantile(brightness, [0, 0.25, 0.5, 0.75, 1.0])\n",
            "      182 | \n",
            "      183 |     def bucket_value(val):\n",
            "      184 |         for idx in range(1, len(quantiles)):\n",
            "      185 |             if val <= quantiles[idx]:\n",
            "      186 |                 return f\"q{idx}\"\n",
            "      187 |         return f\"q{len(quantiles) - 1}\"\n",
            "      188 | \n",
            "      189 |     train_df[\"brightness_bucket\"] = train_df[\"brightness_mean\"].apply(bucket_value)\n",
            "      190 |     test_df[\"brightness_bucket\"] = test_df[\"brightness_mean\"].apply(bucket_value)\n",
            "      191 | \n",
            "      192 | \n",
            "      193 | def frequency_encode(train_df, test_df, cols):\n",
            "      194 |     for col in cols:\n",
            "      195 |         freq = train_df[col].value_counts().to_dict()\n",
            "      196 |         train_df[f\"{col}_freq\"] = train_df[col].map(freq).fillna(0).astype(float)\n",
            "      197 |         test_df[f\"{col}_freq\"] = test_df[col].map(freq).fillna(0).astype(float)\n",
            "      198 | \n",
            "      199 | \n",
            "      200 | def add_aggregations(train_df, test_df, group_cols, target_cols):\n",
            "      201 |     for group_col in group_cols:\n",
            "      202 |         for target in target_cols:\n",
            "      203 |             agg = train_df.groupby(group_col)[target].agg([\"mean\", \"std\", \"count\"]).reset_index()\n",
            "      204 |             agg.columns = [group_col, f\"{group_col}_{target}_mean\", f\"{group_col}_{target}_std\", f\"{group_col}_{target}_count\"]\n",
            "      205 |             train_df = train_df.merge(agg, on=group_col, how=\"left\")\n",
            "      206 |             test_df = test_df.merge(agg, on=group_col, how=\"left\")\n",
            "      207 |             for suffix in (\"mean\", \"std\", \"count\"):\n",
            "      208 |                 col_name = f\"{group_col}_{target}_{suffix}\"\n",
            "      209 |                 train_df[col_name] = train_df[col_name].fillna(train_df[target].mean())\n",
            "      210 |                 test_df[col_name] = test_df[col_name].fillna(train_df[target].mean())\n",
            "      211 |     return train_df, test_df\n",
            "      212 | \n",
            "      213 | \n",
            "      214 | def target_encode_cv(train_df, target_col, cat_cols, n_splits=5, seed=42):\n",
            "      215 |     te_result = {}\n",
            "      216 |     global_maps = {}\n",
            "      217 |     skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
            "      218 |     target_series = train_df[target_col]\n",
            "      219 |     for col in cat_cols:\n",
            "      220 |         te_col = pd.Series(index=train_df.index, dtype=float)\n",
            "      221 |         for train_idx, val_idx in skf.split(train_df, target_series):\n",
            "      222 |             fold_map = train_df.iloc[train_idx].groupby(col)[target_col].mean()\n",
            "      223 |             te_col.iloc[val_idx] = (\n",
            "      224 |                 train_df.iloc[val_idx][col].map(fold_map).fillna(target_series.mean())\n",
            "      225 |             )\n",
            "      226 |         te_result[f\"{col}_te\"] = te_col\n",
            "      227 |         global_maps[col] = train_df.groupby(col)[target_col].mean()\n",
            "      228 |     return te_result, global_maps\n",
            "      229 | \n",
            "      230 | \n",
            "      231 | def apply_target_encoding(test_df, global_maps, cat_cols, global_target_mean):\n",
            "      232 |     for col in cat_cols:\n",
            "      233 |         mapping = global_maps.get(col, {})\n",
            "      234 |         test_df[f\"{col}_te\"] = test_df[col].map(mapping).fillna(global_target_mean)\n",
            "      235 | \n",
            "      236 | \n",
            "      237 | def compute_correlations(df: pd.DataFrame, target_series: pd.Series):\n",
            "      238 |     numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
            "      239 |     numeric_cols = [col for col in numeric_cols if col in df.columns]\n",
            "      240 |     corr = df[numeric_cols].corrwith(target_series).abs().sort_values(ascending=False)\n",
            "      241 |     logging.info(\"Top 10 features correlated with target:\\n%s\", corr.head(10))\n",
            "      242 | \n",
            "      243 | \n",
            "      244 | def select_features_with_lgbm(X: pd.DataFrame, y: pd.Series, mode: str, models_dir: Path):\n",
            "      245 |     lgbm = LGBMClassifier(\n",
            "      246 |         n_estimators=200,\n",
            "      247 |         learning_rate=0.1,\n",
            "      248 |         max_depth=6,\n",
            "      249 |         random_state=42,\n",
            "      250 |         verbose=-1,\n",
            "      251 |     )\n",
            "      252 |     lgbm.fit(X, y)\n",
            "      253 |     importance = pd.Series(lgbm.booster_.feature_importance(importance_type=\"gain\"), index=X.columns)\n",
            "      254 |     importance = importance.sort_values(ascending=False)\n",
            "      255 |     logging.info(\"Feature importances (top 10):\\n%s\", importance.head(10))\n",
            "      256 |     selected = importance[importance >= 1e-4].index.tolist()\n",
            "      257 |     dropped = importance[importance < 1e-4].index.tolist()\n",
            "      258 |     dropped += importance[importance == 0.0].index.tolist()\n",
            "      259 |     dropped = sorted(set(dropped))\n",
            "      260 |     joblib.dump(lgbm, models_dir / f\"lgbm_feature_selector_{mode}.pkl\")\n",
            "      261 |     return selected, dropped, importance\n",
            "      262 | \n",
            "      263 | \n",
            "      264 | def save_dataframe(df: pd.DataFrame, path: Path):\n",
            "      265 |     df.to_csv(path, index=False)\n",
            "      266 |     logging.info(\"Persisted %s rows to %s\", len(df), path)\n",
            "      267 | \n",
            "      268 | \n",
            "      269 | def validate_sample_submission(path: Path):\n",
            "      270 |     if not path.exists():\n",
            "      271 |         raise FileNotFoundError(f\"Sample submission missing at {path}\")\n",
            "      272 |     sample = pd.read_csv(path)\n",
            "      273 |     expected = {\"id\", \"has_cactus\"}\n",
            "      274 |     if not expected.issubset(set(sample.columns)):\n",
            "      275 |         logging.warning(\"Sample submission missing expected columns, creating fallback\")\n",
            "      276 |         fallback = pd.DataFrame({\"id\": [], \"has_cactus\": []})\n",
            "      277 |         fallback.to_csv(path, index=False)\n",
            "      278 |         return fallback\n",
            "      279 |     return sample\n",
            "      280 | \n",
            "      281 | \n",
            "      282 | def load_cache(cache_path: Path):\n",
            "      283 |     if cache_path.exists():\n",
            "      284 |         logging.info(\"Loading cached features from %s\", cache_path)\n",
            "      285 |         return joblib.load(cache_path)\n",
            "      286 |     return None\n",
            "      287 | \n",
            "      288 | \n",
            "      289 | def dump_cache(payload: dict, cache_path: Path):\n",
            "      290 |     joblib.dump(payload, cache_path)\n",
            "      291 |     logging.info(\"Cached intermediate features to %s\", cache_path)\n",
            "      292 | \n",
            "      293 | \n",
            "      294 | def main():\n",
            "      295 |     configure_logging()\n",
            "      296 |     args = parse_args()\n",
            "      297 |     config = {\n",
            "      298 |         \"mode\": args.mode,\n",
            "      299 |         \"data_root\": Path(args.data_root),\n",
            "      300 |         \"max_time\": args.max_time,\n",
            "      301 |     }\n",
            "      302 |     logging.info(\"Running advanced_feature_engineering in %s mode\", config[\"mode\"])\n",
            "      303 | \n",
            "      304 |     watchdog = Watchdog(total_seconds=config[\"max_time\"], checkpoint_interval=120)\n",
            "      305 | \n",
            "      306 |     base_root = config[\"data_root\"]\n",
            "      307 |     train_dir = base_root / \"train\"\n",
            "      308 |     test_dir = base_root / \"test\"\n",
            "      309 |     models_dir = base_root / \"models\"\n",
            "      310 |     cache_dir = base_root / \"feature_cache\"\n",
            "      311 |     sample_submission_path = base_root / \"sample_submission.csv\"\n",
            "      312 |     ensure_dir(models_dir)\n",
            "      313 |     ensure_dir(cache_dir)\n",
            "      314 |     ensure_dir(train_dir)\n",
            "      315 |     ensure_dir(test_dir)\n",
            "      316 | \n",
            "      317 |     mode_suffix = \"debug\" if args.mode == \"debug\" else \"full\"\n",
            "      318 |     cache_path = cache_dir / f\"raw_features_{mode_suffix}.pkl\"\n",
            "      319 | \n",
            "      320 |     sample_sub = validate_sample_submission(sample_submission_path)\n",
            "      321 | \n",
            "      322 |     train_csv = find_csv_with_label(train_dir)\n",
            "      323 |     train_labels = pd.read_csv(train_csv)\n",
            "      324 |     expected_cols = {\"id\", \"has_cactus\"}\n",
            "      325 |     assert expected_cols.issubset(train_labels.columns)\n",
            "      326 | \n",
            "      327 |     max_samples = 200 if args.mode == \"debug\" else None\n",
            "      328 |     image_size = 224 if args.mode == \"debug\" else 320\n",
            "      329 | \n",
            "      330 |     train_image_map = map_images(train_dir)\n",
            "      331 |     test_image_map = map_images(test_dir)\n",
            "      332 | \n",
            "      333 |     cached = None if args.force else load_cache(cache_path)\n",
            "      334 |     if cached:\n",
            "      335 |         train_feats = cached[\"train_feats\"].copy()\n",
            "      336 |         test_feats = cached[\"test_feats\"].copy()\n",
            "      337 |         target = cached[\"target\"].copy()\n",
            "      338 |         global_maps = cached[\"global_maps\"]\n",
            "      339 |     else:\n",
            "      340 |         train_feats = build_feature_dataframe(\n",
            "      341 |             identifiers=train_labels[\"id\"].tolist(),\n",
            "      342 |             image_map=train_image_map,\n",
            "      343 |             image_dir=train_dir,\n",
            "      344 |             base_df=train_labels,\n",
            "      345 |             target_col=\"has_cactus\",\n",
            "      346 |             limit=max_samples,\n",
            "      347 |             target_size=image_size,\n",
            "      348 |             watchdog=watchdog,\n",
            "      349 |             dataset_name=\"train\",\n",
            "      350 |         )\n",
            "      351 |         test_feats = build_feature_dataframe(\n",
            "      352 |             identifiers=sample_sub[\"id\"].tolist(),\n",
            "      353 |             image_map=test_image_map,\n",
            "      354 |             image_dir=test_dir,\n",
            "      355 |             base_df=None,\n",
            "      356 |             target_col=\"has_cactus\",\n",
            "      357 |             limit=max_samples,\n",
            "      358 |             target_size=image_size,\n",
            "      359 |             watchdog=watchdog,\n",
            "      360 |             dataset_name=\"test\",\n",
            "      361 |         )\n",
            "      362 | \n",
            "      363 |         assign_metadata(train_feats)\n",
            "      364 |         assign_metadata(test_feats)\n",
            "      365 | \n",
            "      366 |         build_brightness_buckets(train_feats, test_feats)\n",
            "      367 | \n",
            "      368 |         frequency_encode(train_feats, test_feats, [\"id_prefix\", \"hash_bucket\", \"brightness_bucket\"])\n",
            "      369 | \n",
            "      370 |         train_feats, test_feats = add_aggregations(\n",
            "      371 |             train_feats,\n",
            "      372 |             test_feats,\n",
            "      373 |             group_cols=[\"id_prefix\", \"hash_bucket\"],\n",
            "      374 |             target_cols=[\"brightness_mean\", \"pct_bright\"],\n",
            "      375 |         )\n",
            "      376 | \n",
            "      377 |         te_cols = [\"id_prefix\", \"hash_bucket\", \"brightness_bucket\"]\n",
            "      378 |         te_values, global_maps = target_encode_cv(train_feats, \"has_cactus\", te_cols)\n",
            "      379 |         for col, series in te_values.items():\n",
            "      380 |             train_feats[col] = series\n",
            "      381 |         apply_target_encoding(test_feats, global_maps, te_cols, train_feats[\"has_cactus\"].mean())\n",
            "      382 |         target = train_feats[\"has_cactus\"].copy()\n",
            "      383 | \n",
            "      384 |         dumped = {\n",
            "      385 |             \"train_feats\": train_feats,\n",
            "      386 |             \"test_feats\": test_feats,\n",
            "      387 |             \"target\": target,\n",
            "      388 |             \"global_maps\": global_maps,\n",
            "      389 |         }\n",
            "      390 |         dump_cache(dumped, cache_path)\n",
            "      391 | \n",
            "      392 |     compute_correlations(train_feats.drop(columns=[\"id\"]), target)\n",
            "      393 | \n",
            "      394 |     feature_columns = [col for col in train_feats.columns if col not in {\"id\", \"has_cactus\"}]\n",
            "      395 |     X = train_feats[feature_columns]\n",
            "      396 |     selected_features, dropped_features, importance = select_features_with_lgbm(X, target, config[\"mode\"], models_dir)\n",
            "      397 | \n",
            "      398 |     logging.info(\"Dropped features (%d): %s\", len(dropped_features), dropped_features)\n",
            "      399 |     selected_train = pd.concat([train_feats[[\"id\"] + selected_features], target.rename(\"has_cactus\")], axis=1)\n",
            "      400 |     selected_test = test_feats[[\"id\"] + selected_features]\n",
            "      401 | \n",
            "      402 |     train_output = base_root / \"train_engineered.csv\"\n",
            "      403 |     test_output = base_root / \"test_engineered.csv\"\n",
            "      404 |     save_dataframe(selected_train, train_output)\n",
            "      405 |     save_dataframe(selected_test, test_output)\n",
            "      406 | \n",
            "      407 |     checkpoint = {\n",
            "      408 |         \"timestamp\": datetime.now().isoformat(),\n",
            "      409 |         \"mode\": config[\"mode\"],\n",
            "      410 |         \"selected_features\": selected_features,\n",
            "      411 |         \"dropped_features\": dropped_features,\n",
            "      412 |     }\n",
            "      413 |     with open(cache_dir / f\"checkpoint_{mode_suffix}.json\", \"w\") as fh:\n",
            "      414 |         json.dump(checkpoint, fh)\n",
            "      415 |     logging.info(\"Advanced feature engineering completed. Selected %d features.\", len(selected_features))\n",
            "      416 | \n",
            "      417 | \n",
            "      418 | if __name__ == \"__main__\":\n",
            "      419 |     main()\n",
            "\n",
            "Code saved to: generated_code_advanced_feature_engineering.py\n",
            "\n",
            "Executing code...\n",
            "\n",
            "Attempt 1/3\n",
            "   ‚ö†Ô∏è  Code validation failed: Missing required output: 'Final Validation Performance: {score}'\n",
            "Execution failed: Missing required output: 'Final Validation Performance: {score}'\n",
            "\n",
            "Getting meta-evaluator feedback...\n",
            "Meta-Feedback:\n",
            "1. **Root cause**: The script never computes/logs the final validation metric so ‚ÄúFinal Validation Performance: {score}‚Äù is never emitted.\n",
            "2. **Code change**: After `select_features_with_lgbm`, run a quick StratifiedKFold CV (e.g., `cross_val_score`) on `X[selected_features]` with the same LGBM params, compute the mean ROC AUC/accuracy, and emit `logging.info(\"Final Validation Performance: %.4f\", score)` (or `print`). This satisfies the required output contract.\n",
            "3. **Best practice**: Wrap evaluation in a dedicated function returning both score and message; call it before exit to guarantee metrics are always reported regardless of cached flows. Unit tests should assert the final log/print exists so regressions are caught early.\n",
            "\n",
            "Passing error context to fixer: Missing required output: 'Final Validation Performance: {score}'\n",
            "Attempting to fix...\n",
            "\n",
            "Attempt 2/3\n",
            "      ‚ö†Ô∏è 2025-12-08 00:29:41,924 [INFO] Running advanced_feature_engineering in debug mode\n",
            "      ‚ö†Ô∏è Traceback (most recent call last):\n",
            "      ‚ö†Ô∏è   File \"/content/kaggle_competitions/competitions/aerial-cactus-identification/_exec_1765153776.py\", line 445, in <module>\n",
            "      ‚ö†Ô∏è     main()\n",
            "      ‚ö†Ô∏è   File \"/content/kaggle_competitions/competitions/aerial-cactus-identification/_exec_1765153776.py\", line 345, in main\n",
            "      ‚ö†Ô∏è     train_csv = find_csv_with_label(train_dir)\n",
            "      ‚ö†Ô∏è                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      ‚ö†Ô∏è   File \"/content/kaggle_competitions/competitions/aerial-cactus-identification/_exec_1765153776.py\", line 84, in find_csv_with_label\n",
            "      ‚ö†Ô∏è     raise FileNotFoundError(f\"No qualifying CSV in {path}\")\n",
            "      ‚ö†Ô∏è FileNotFoundError: No qualifying CSV in /content/kaggle_competitions/competitions/aerial-cactus-identification/train\n",
            "Execution failed: raise FileNotFoundError(f\"No qualifying CSV in {path}\")\n",
            "Passing error context to fixer: raise FileNotFoundError(f\"No qualifying CSV in {path}\")\n",
            "Attempting to fix...\n",
            "\n",
            "Attempt 3/3\n",
            "      ‚ö†Ô∏è 2025-12-08 00:30:21,157 [INFO] Running advanced_feature_engineering in debug mode\n",
            "      ‚ö†Ô∏è 2025-12-08 00:30:21,203 [INFO] Found train CSV: /content/kaggle_competitions/competitions/aerial-cactus-identification/submission_best.csv\n",
            "      ‚ö†Ô∏è 2025-12-08 00:30:21,363 [INFO] Indexed 17500 images under /content/kaggle_competitions/competitions/aerial-cactus-identification/train\n",
            "      ‚ö†Ô∏è 2025-12-08 00:30:21,398 [INFO] Indexed 4000 images under /content/kaggle_competitions/competitions/aerial-cactus-identification/test\n",
            "      ‚ö†Ô∏è \n",
            "      ‚ö†Ô∏è Extracting train:   0%|          | 0/200 [00:00<?, ?it/s]\n",
            "      ‚ö†Ô∏è Extracting train:   0%|          | 0/200 [00:00<?, ?it/s]\n",
            "      ‚ö†Ô∏è Traceback (most recent call last):\n",
            "      ‚ö†Ô∏è   File \"/content/kaggle_competitions/competitions/aerial-cactus-identification/_exec_1765153818.py\", line 450, in <module>\n",
            "      ‚ö†Ô∏è     main()\n",
            "      ‚ö†Ô∏è   File \"/content/kaggle_competitions/competitions/aerial-cactus-identification/_exec_1765153818.py\", line 368, in main\n",
            "      ‚ö†Ô∏è     train_feats = build_feature_dataframe(\n",
            "      ‚ö†Ô∏è                   ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      ‚ö†Ô∏è   File \"/content/kaggle_competitions/competitions/aerial-cactus-identification/_exec_1765153818.py\", line 169, in build_feature_dataframe\n",
            "      ‚ö†Ô∏è     image_path = resolve_image_path(ident, image_map, image_dir)\n",
            "      ‚ö†Ô∏è                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      ‚ö†Ô∏è   File \"/content/kaggle_competitions/competitions/aerial-cactus-identification/_exec_1765153818.py\", line 112, in resolve_image_path\n",
            "      ‚ö†Ô∏è     raise FileNotFoundError(f\"Missing image {image_name}\")\n",
            "      ‚ö†Ô∏è FileNotFoundError: Missing image 000940378805c44108d287872b2f04ce.jpg\n",
            "Execution failed: raise FileNotFoundError(f\"Missing image {image_name}\")\n",
            "\n",
            "Entering debug mode...\n",
            "Last error passed to debugger: raise FileNotFoundError(f\"Missing image {image_name}\")\n",
            "   Debug timeout set to: 600s (10.0 min)\n",
            "   Debug iteration 1/5\n",
            "      ‚ö†Ô∏è 2025-12-08 00:31:46,670 [INFO] Running advanced_feature_engineering in debug mode\n",
            "      ‚ö†Ô∏è 2025-12-08 00:31:50,309 [INFO] Found train CSV: /content/kaggle_competitions/competitions/aerial-cactus-identification/folds.csv\n",
            "      ‚ö†Ô∏è 2025-12-08 00:31:50,478 [INFO] Indexed 17500 images under /content/kaggle_competitions/competitions/aerial-cactus-identification/train\n",
            "      ‚ö†Ô∏è 2025-12-08 00:31:50,513 [INFO] Indexed 4000 images under /content/kaggle_competitions/competitions/aerial-cactus-identification/test\n",
            "      ‚ö†Ô∏è \n",
            "      ‚ö†Ô∏è Extracting train:   0%|          | 0/200 [00:00<?, ?it/s]\n",
            "      ‚ö†Ô∏è Extracting train:   0%|          | 1/200 [00:00<00:24,  8.12it/s]\n",
            "      ‚ö†Ô∏è Extracting train:   6%|‚ñå         | 11/200 [00:00<00:03, 56.07it/s]\n",
            "      ‚ö†Ô∏è Extracting train:  10%|‚ñà         | 21/200 [00:00<00:02, 73.15it/s]\n",
            "      ‚ö†Ô∏è Extracting train:  16%|‚ñà‚ñå        | 31/200 [00:00<00:02, 81.69it/s]\n",
            "      ‚ö†Ô∏è Extracting train:  20%|‚ñà‚ñà        | 41/200 [00:00<00:01, 86.99it/s]\n",
            "      ‚ö†Ô∏è Extracting train:  26%|‚ñà‚ñà‚ñå       | 51/200 [00:00<00:01, 90.47it/s]\n",
            "      ‚ö†Ô∏è Extracting train:  30%|‚ñà‚ñà‚ñà       | 61/200 [00:00<00:01, 92.52it/s]\n",
            "      ‚ö†Ô∏è Extracting train:  36%|‚ñà‚ñà‚ñà‚ñå      | 71/200 [00:00<00:01, 93.72it/s]\n",
            "      ‚ö†Ô∏è Extracting train:  40%|‚ñà‚ñà‚ñà‚ñà      | 81/200 [00:00<00:01, 94.77it/s]\n",
            "      ‚ö†Ô∏è Extracting train:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 91/200 [00:01<00:01, 94.83it/s]\n",
            "      ‚ö†Ô∏è Extracting train:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 101/200 [00:01<00:01, 94.99it/s]\n",
            "      ‚ö†Ô∏è Extracting train:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 111/200 [00:01<00:00, 95.26it/s]\n",
            "      ‚ö†Ô∏è Extracting train:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 121/200 [00:01<00:00, 95.38it/s]\n",
            "      ‚ö†Ô∏è Extracting train:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 131/200 [00:01<00:00, 95.52it/s]\n",
            "      ‚ö†Ô∏è Extracting train:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 141/200 [00:01<00:00, 95.84it/s]\n",
            "      ‚ö†Ô∏è Extracting train:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 151/200 [00:01<00:00, 95.99it/s]\n",
            "      ‚ö†Ô∏è Extracting train:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 161/200 [00:01<00:00, 95.41it/s]\n",
            "      ‚ö†Ô∏è Extracting train:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 171/200 [00:01<00:00, 96.14it/s]\n",
            "      ‚ö†Ô∏è Extracting train:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 181/200 [00:01<00:00, 96.61it/s]\n",
            "      ‚ö†Ô∏è Extracting train:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 191/200 [00:02<00:00, 96.43it/s]\n",
            "      ‚ö†Ô∏è Extracting train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:02<00:00, 91.16it/s]\n",
            "      ‚ö†Ô∏è \n",
            "      ‚ö†Ô∏è Extracting test:   0%|          | 0/200 [00:00<?, ?it/s]\n",
            "      ‚ö†Ô∏è Extracting test:   6%|‚ñå         | 12/200 [00:00<00:01, 113.09it/s]\n",
            "      ‚ö†Ô∏è Extracting test:  12%|‚ñà‚ñè        | 24/200 [00:00<00:01, 112.31it/s]\n",
            "      ‚ö†Ô∏è Extracting test:  18%|‚ñà‚ñä        | 36/200 [00:00<00:01, 110.93it/s]\n",
            "      ‚ö†Ô∏è Extracting test:  24%|‚ñà‚ñà‚ñç       | 48/200 [00:00<00:01, 111.39it/s]\n",
            "      ‚ö†Ô∏è Extracting test:  30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:01, 112.11it/s]\n",
            "      ‚ö†Ô∏è Extracting test:  36%|‚ñà‚ñà‚ñà‚ñå      | 72/200 [00:00<00:01, 112.14it/s]\n",
            "      ‚ö†Ô∏è Extracting test:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 84/200 [00:00<00:01, 112.94it/s]\n",
            "      ‚ö†Ô∏è Extracting test:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 96/200 [00:00<00:00, 113.22it/s]\n",
            "      ‚ö†Ô∏è Extracting test:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 108/200 [00:00<00:00, 113.56it/s]\n",
            "      ‚ö†Ô∏è Extracting test:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 120/200 [00:01<00:00, 113.51it/s]\n",
            "      ‚ö†Ô∏è Extracting test:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 132/200 [00:01<00:00, 113.40it/s]\n",
            "      ‚ö†Ô∏è Extracting test:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 144/200 [00:01<00:00, 112.81it/s]\n",
            "      ‚ö†Ô∏è Extracting test:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 156/200 [00:01<00:00, 112.19it/s]\n",
            "      ‚ö†Ô∏è Extracting test:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 168/200 [00:01<00:00, 112.42it/s]\n",
            "      ‚ö†Ô∏è Extracting test:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 180/200 [00:01<00:00, 113.20it/s]\n",
            "      ‚ö†Ô∏è Extracting test:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 192/200 [00:01<00:00, 113.72it/s]\n",
            "      ‚ö†Ô∏è Extracting test: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 112.91it/s]\n",
            "      ‚ö†Ô∏è 2025-12-08 00:31:54,572 [INFO] Cached intermediate features to /content/kaggle_competitions/competitions/aerial-cactus-identification/feature_cache/raw_features_debug.pkl\n",
            "      ‚ö†Ô∏è /usr/local/lib/python3.12/dist-packages/numpy/lib/_function_base_impl.py:2922: RuntimeWarning: invalid value encountered in divide\n",
            "      ‚ö†Ô∏è   c /= stddev[:, None]\n",
            "      ‚ö†Ô∏è /usr/local/lib/python3.12/dist-packages/numpy/lib/_function_base_impl.py:2923: RuntimeWarning: invalid value encountered in divide\n",
            "      ‚ö†Ô∏è   c /= stddev[None, :]\n",
            "      ‚ö†Ô∏è 2025-12-08 00:31:54,600 [INFO] Top 10 features correlated with target:\n",
            "      ‚ö†Ô∏è has_cactus        1.000000\n",
            "      ‚ö†Ô∏è channel_min_g     0.561486\n",
            "      ‚ö†Ô∏è contrast_g        0.508379\n",
            "      ‚ö†Ô∏è channel_min_r     0.485833\n",
            "      ‚ö†Ô∏è channel_max_b     0.452016\n",
            "      ‚ö†Ô∏è std_g             0.446264\n",
            "      ‚ö†Ô∏è contrast_r        0.439794\n",
            "      ‚ö†Ô∏è texture_ratio     0.437562\n",
            "      ‚ö†Ô∏è std_r             0.437533\n",
            "      ‚ö†Ô∏è brightness_std    0.421037\n",
            "      ‚ö†Ô∏è dtype: float64\n",
            "      ‚ö†Ô∏è Traceback (most recent call last):\n",
            "      ‚ö†Ô∏è   File \"/content/kaggle_competitions/competitions/aerial-cactus-identification/_exec_1765153903.py\", line 495, in <module>\n",
            "      ‚ö†Ô∏è     main()\n",
            "      ‚ö†Ô∏è   File \"/content/kaggle_competitions/competitions/aerial-cactus-identification/_exec_1765153903.py\", line 468, in main\n",
            "      ‚ö†Ô∏è     selected_features, dropped_features, importance = select_features_with_lgbm(X, target, config[\"mode\"], models_dir)\n",
            "      ‚ö†Ô∏è                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      ‚ö†Ô∏è   File \"/content/kaggle_competitions/competitions/aerial-cactus-identification/_exec_1765153903.py\", line 302, in select_features_with_lgbm\n",
            "      ‚ö†Ô∏è     lgbm.fit(X, y)\n",
            "      ‚ö†Ô∏è   File \"/usr/local/lib/python3.12/dist-packages/lightgbm/sklearn.py\", line 1560, in fit\n",
            "      ‚ö†Ô∏è     super().fit(\n",
            "      ‚ö†Ô∏è   File \"/usr/local/lib/python3.12/dist-packages/lightgbm/sklearn.py\", line 1049, in fit\n",
            "      ‚ö†Ô∏è     self._Booster = train(\n",
            "      ‚ö†Ô∏è                     ^^^^^^\n",
            "      ‚ö†Ô∏è   File \"/usr/local/lib/python3.12/dist-packages/lightgbm/engine.py\", line 297, in train\n",
            "      ‚ö†Ô∏è     booster = Booster(params=params, train_set=train_set)\n",
            "      ‚ö†Ô∏è               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      ‚ö†Ô∏è   File \"/usr/local/lib/python3.12/dist-packages/lightgbm/basic.py\", line 3656, in __init__\n",
            "      ‚ö†Ô∏è     train_set.construct()\n",
            "      ‚ö†Ô∏è   File \"/usr/local/lib/python3.12/dist-packages/lightgbm/basic.py\", line 2590, in construct\n",
            "      ‚ö†Ô∏è     self._lazy_init(\n",
            "      ‚ö†Ô∏è   File \"/usr/local/lib/python3.12/dist-packages/lightgbm/basic.py\", line 2123, in _lazy_init\n",
            "      ‚ö†Ô∏è     data, feature_name, categorical_feature, self.pandas_categorical = _data_from_pandas(\n",
            "      ‚ö†Ô∏è                                                                        ^^^^^^^^^^^^^^^^^^\n",
            "      ‚ö†Ô∏è   File \"/usr/local/lib/python3.12/dist-packages/lightgbm/basic.py\", line 868, in _data_from_pandas\n",
            "      ‚ö†Ô∏è     _pandas_to_numpy(data, target_dtype=target_dtype),\n",
            "      ‚ö†Ô∏è     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      ‚ö†Ô∏è   File \"/usr/local/lib/python3.12/dist-packages/lightgbm/basic.py\", line 814, in _pandas_to_numpy\n",
            "      ‚ö†Ô∏è     _check_for_bad_pandas_dtypes(data.dtypes)\n",
            "      ‚ö†Ô∏è   File \"/usr/local/lib/python3.12/dist-packages/lightgbm/basic.py\", line 805, in _check_for_bad_pandas_dtypes\n",
            "      ‚ö†Ô∏è     raise ValueError(\n",
            "      ‚ö†Ô∏è ValueError: pandas dtypes must be int, float or bool.\n",
            "      ‚ö†Ô∏è Fields with bad pandas dtypes: id_prefix: object, hash_bucket: object, brightness_bucket: object\n",
            "   Debug iteration 2/5\n",
            "   ‚ö†Ô∏è  Code validation failed: Missing required output: 'Final Validation Performance: {score}'\n",
            "   Debug iteration 3/5\n",
            "      ‚ö†Ô∏è 2025-12-08 00:34:53,911 [INFO] Found train CSV: /content/kaggle_competitions/competitions/aerial-cactus-identification/submission_best.csv\n",
            "      ‚ö†Ô∏è 2025-12-08 00:34:54,089 [INFO] Indexed 17500 images under /content/kaggle_competitions/competitions/aerial-cactus-identification/train\n",
            "      ‚ö†Ô∏è 2025-12-08 00:34:54,227 [INFO] Indexed 4000 images under /content/kaggle_competitions/competitions/aerial-cactus-identification/test\n",
            "      ‚ö†Ô∏è \n",
            "      ‚ö†Ô∏è Extracting train:   0%|          | 0/4000 [00:00<?, ?it/s]\n",
            "      ‚ö†Ô∏è Extracting train:   0%|          | 0/4000 [00:00<?, ?it/s]\n",
            "      ‚ö†Ô∏è Traceback (most recent call last):\n",
            "      ‚ö†Ô∏è   File \"/content/kaggle_competitions/competitions/aerial-cactus-identification/_exec_1765154089.py\", line 374, in <module>\n",
            "      ‚ö†Ô∏è     main()\n",
            "      ‚ö†Ô∏è   File \"/content/kaggle_competitions/competitions/aerial-cactus-identification/_exec_1765154089.py\", line 342, in main\n",
            "      ‚ö†Ô∏è     train_df = build_feature_dataframe(train_ids, train_image_map, train_img_dir, target_col, target_map, None, 64, watchdog, \"train\")\n",
            "      ‚ö†Ô∏è                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      ‚ö†Ô∏è   File \"/content/kaggle_competitions/competitions/aerial-cactus-identification/_exec_1765154089.py\", line 193, in build_feature_dataframe\n",
            "      ‚ö†Ô∏è     image_path = resolve_image_path(ident, image_map, image_dir)\n",
            "      ‚ö†Ô∏è                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      ‚ö†Ô∏è   File \"/content/kaggle_competitions/competitions/aerial-cactus-identification/_exec_1765154089.py\", line 140, in resolve_image_path\n",
            "      ‚ö†Ô∏è     raise FileNotFoundError(f\"Missing image {image_name}\")\n",
            "      ‚ö†Ô∏è FileNotFoundError: Missing image 000940378805c44108d287872b2f04ce.jpg\n",
            "   Debug iteration 4/5\n",
            "      ‚ö†Ô∏è 2025-12-08 00:36:12,328 [INFO] Found train CSV: /content/kaggle_competitions/competitions/aerial-cactus-identification/submission_best.csv\n",
            "      ‚ö†Ô∏è 2025-12-08 00:36:12,494 [INFO] Indexed 17500 images under /content/kaggle_competitions/competitions/aerial-cactus-identification/train\n",
            "      ‚ö†Ô∏è 2025-12-08 00:36:12,632 [INFO] Indexed 4000 images under /content/kaggle_competitions/competitions/aerial-cactus-identification/test\n",
            "      ‚ö†Ô∏è \n",
            "      ‚ö†Ô∏è Extracting train:   0%|          | 0/4000 [00:00<?, ?it/s]\n",
            "      ‚ö†Ô∏è Extracting train:   0%|          | 0/4000 [00:00<?, ?it/s]\n",
            "      ‚ö†Ô∏è Traceback (most recent call last):\n",
            "      ‚ö†Ô∏è   File \"/content/kaggle_competitions/competitions/aerial-cactus-identification/_exec_1765154158.py\", line 378, in <module>\n",
            "      ‚ö†Ô∏è     main()\n",
            "      ‚ö†Ô∏è   File \"/content/kaggle_competitions/competitions/aerial-cactus-identification/_exec_1765154158.py\", line 346, in main\n",
            "      ‚ö†Ô∏è     train_df = build_feature_dataframe(train_ids, train_image_map, train_img_dir, target_col, target_map, None, 64, watchdog, \"train\")\n",
            "      ‚ö†Ô∏è                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      ‚ö†Ô∏è   File \"/content/kaggle_competitions/competitions/aerial-cactus-identification/_exec_1765154158.py\", line 197, in build_feature_dataframe\n",
            "      ‚ö†Ô∏è     image_path = resolve_image_path(ident, image_map, image_dir)\n",
            "      ‚ö†Ô∏è                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      ‚ö†Ô∏è   File \"/content/kaggle_competitions/competitions/aerial-cactus-identification/_exec_1765154158.py\", line 144, in resolve_image_path\n",
            "      ‚ö†Ô∏è     raise FileNotFoundError(f\"Missing image {image_name}\")\n",
            "      ‚ö†Ô∏è FileNotFoundError: Missing image 000940378805c44108d287872b2f04ce.jpg\n",
            "Debug halted: same error persists; stopping to avoid infinite loop\n",
            "Component timeout set to: 3000s (50.0 min)\n",
            "\u0005 DSPy configured with openai/gpt-5.1-codex-mini\n",
            "\u000f  No optimized prompts found for developer_generator\n",
            "\u000f  No optimized prompts found for developer_fixer\n",
            "Using base (unoptimized) generator module\n",
            "Using base (unoptimized) fixer module\n",
            "\n",
            "============================================================\n",
            "= DEVELOPER AGENT: Implementing Components\n",
            "============================================================\n",
            "\n",
            "= Implementing: advanced_feature_engineering (feature_engineering)\n",
            "Estimated Impact: 15.0%\n",
            "Component timeout set to: 900s (15.0 min)\n",
            "\n",
            "Generating code...\n",
            "\n",
            "Generated code preview:\n",
            "        1 | import argparse\n",
            "        2 | import logging\n",
            "        3 | import time\n",
            "        4 | from contextlib import contextmanager\n",
            "        5 | from pathlib import Path\n",
            "        6 | from typing import List, Tuple\n",
            "        7 | \n",
            "        8 | import lightgbm as lgb\n",
            "        9 | import numpy as np\n",
            "       10 | import pandas as pd\n",
            "       11 | from sklearn.model_selection import StratifiedKFold\n",
            "       12 | \n",
            "       13 | \n",
            "       14 | DEFAULT_ROOT = Path(\"/content/kaggle_competitions/competitions/aerial-cactus-identification\")\n",
            "       15 | MODELS_DIR = DEFAULT_ROOT / \"models\"\n",
            "       16 | TRAIN_CSV = DEFAULT_ROOT / \"train.csv\"\n",
            "       17 | TEST_CSV = DEFAULT_ROOT / \"test.csv\"\n",
            "       18 | SAMPLE_SUB_CSV = DEFAULT_ROOT / \"sample_submission.csv\"\n",
            "       19 | TRAIN_OUTPUT = MODELS_DIR / \"train_engineered.csv\"\n",
            "       20 | TEST_OUTPUT = MODELS_DIR / \"test_engineered.csv\"\n",
            "       21 | FALLBACK_SUBMISSION = MODELS_DIR / \"fallback_submission.csv\"\n",
            "       22 | \n",
            "       23 | \n",
            "       24 | @contextmanager\n",
            "       25 | def log_stage(name: str):\n",
            "       26 |     logging.info(\"[STAGE] %s started\", name)\n",
            "       27 |     start = time.time()\n",
            "       28 |     try:\n",
            "       29 |         yield\n",
            "       30 | n    finally:\n",
            "       31 |         elapsed = time.time() - start\n",
            "       32 |         logging.info(\"[STAGE] %s completed in %.2fs\", name, elapsed)\n",
            "       33 | \n",
            "       34 | \n",
            "       35 | def setup_logging() -> None:\n",
            "       36 |     logging.basicConfig(\n",
            "       37 |         level=logging.INFO,\n",
            "       38 |         format=\"%(asctime)s %(levelname)s %(message)s\",\n",
            "       39 |         datefmt=\"%Y-%m-%d %H:%M:%S\",\n",
            "       40 |     )\n",
            "       41 | \n",
            "       42 | \n",
            "       43 | def parse_args() -> argparse.Namespace:\n",
            "       44 |     parser = argparse.ArgumentParser(description=\"Advanced feature engineering for aerial cactus\")\n",
            "       45 |     parser.add_argument(\"--mode\", choices=[\"debug\", \"full\"], default=\"debug\", help=\"debug or full feature creation\")\n",
            "       46 |     parser.add_argument(\"--seed\", type=int, default=42, help=\"random seed\")\n",
            "       47 |     parser.add_argument(\"--force\", action=\"store_true\", help=\"regenerate features even if files exist\")\n",
            "       48 |     parser.add_argument(\"--data-root\", type=Path, default=DEFAULT_ROOT, help=\"root path to competition data\")\n",
            "       49 |     return parser.parse_args()\n",
            "       50 | \n",
            "       51 | \n",
            "       52 | def ensure_directories() -> None:\n",
            "       53 |     MODELS_DIR.mkdir(parents=True, exist_ok=True)\n",
            "       54 | \n",
            "       55 | \n",
            "       56 | def read_csv(path: Path, **kwargs) -> pd.DataFrame:\n",
            "       57 |     logging.info(\"Loading %s\", path)\n",
            "       58 |     return pd.read_csv(path, **kwargs)\n",
            "       59 | \n",
            "       60 | \n",
            "       61 | def safe_validate_sample_submission(sample_df: pd.DataFrame, test_df: pd.DataFrame) -> None:\n",
            "       62 |     expected = {\"id\", \"has_cactus\"}\n",
            "       63 |     if not expected.issubset(sample_df.columns):\n",
            "       64 |         raise ValueError(f\"Sample submission missing columns {expected - set(sample_df.columns)}\")\n",
            "       65 |     if len(sample_df) != len(test_df):\n",
            "       66 |         logging.warning(\"Sample submission rows (%d) != test rows (%d). Writing fallback submission.\", len(sample_df), len(test_df))\n",
            "       67 |         fallback = sample_df.copy()\n",
            "       68 |         fallback[\"has_cactus\"] = fallback[\"has_cactus\"].mean()\n",
            "       69 |         fallback.to_csv(FALLBACK_SUBMISSION, index=False)\n",
            "       70 |         logging.info(\"Fallback submission saved to %s\", FALLBACK_SUBMISSION)\n",
            "       71 | \n",
            "       72 | \n",
            "       73 | def string_base_features(df: pd.DataFrame) -> pd.DataFrame:\n",
            "       74 |     result = df.copy()\n",
            "       75 |     result[\"id_len\"] = result[\"id\"].str.len()\n",
            "       76 |     result[\"id_digits\"] = result[\"id\"].map(lambda x: sum(ch.isdigit() for ch in x))\n",
            "       77 |     result[\"id_alpha\"] = result[\"id_len\"] - result[\"id_digits\"]\n",
            "       78 |     result[\"id_first_char\"] = result[\"id\"].str[0].fillna(\"X\")\n",
            "       79 |     result[\"id_last_char\"] = result[\"id\"].str[-1].fillna(\"X\")\n",
            "       80 |     result[\"id_has_underscore\"] = result[\"id\"].str.contains(\"_\").astype(int)\n",
            "       81 |     result[\"id_has_number\"] = (result[\"id_digits\"] > 0).astype(int)\n",
            "       82 |     numeric_part = result[\"id\"].str.extract(r\"(\\d+)\")[0]\n",
            "       83 |     result[\"id_numeric_part\"] = numeric_part.fillna(\"0\").astype(int)\n",
            "       84 |     result[\"id_prefix\"] = result[\"id\"].str.extract(r\"^([^_]+)\")[0].fillna(\"prefix_unknown\")\n",
            "       85 |     return result\n",
            "       86 | \n",
            "       87 | \n",
            "       88 | def frequency_encode(train: pd.DataFrame, test: pd.DataFrame, columns: List[str]) -> None:\n",
            "       89 |     for col in columns:\n",
            "       90 |         freq = train[col].value_counts()\n",
            "       91 |         train[f\"{col}_freq\"] = train[col].map(freq).fillna(0).astype(int)\n",
            "       92 |         test[f\"{col}_freq\"] = test[col].map(freq).fillna(0).astype(int)\n",
            "       93 |         logging.info(\"Frequency encoding for %s produced %d categories\", col, freq.shape[0])\n",
            "       94 | \n",
            "       95 | \n",
            "       96 | def target_encode_cv(\n",
            "       97 |     train: pd.DataFrame,\n",
            "       98 |     test: pd.DataFrame,\n",
            "       99 |     column: str,\n",
            "      100 |     target_col: str,\n",
            "      101 |     n_splits: int,\n",
            "      102 |     seed: int,\n",
            "      103 | ) -> Tuple[np.ndarray, np.ndarray]:\n",
            "      104 |     target = train[target_col]\n",
            "      105 |     n_splits = min(max(2, n_splits), len(train))\n",
            "      106 |     skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
            "      107 |     train_enc = np.zeros(len(train))\n",
            "      108 |     global_mean = target.mean()\n",
            "      109 |     for fold, (train_idx, val_idx) in enumerate(skf.split(train, target)):\n",
            "      110 |         fold_map = train.iloc[train_idx].groupby(column)[target_col].mean()\n",
            "      111 |         train_enc[val_idx] = train.iloc[val_idx][column].map(fold_map).fillna(global_mean)\n",
            "      112 |     global_map = train.groupby(column)[target_col].mean()\n",
            "      113 |     test_enc = test[column].map(global_map).fillna(global_mean)\n",
            "      114 |     return train_enc, test_enc\n",
            "      115 | \n",
            "      116 | \n",
            "      117 | def add_aggregations(train: pd.DataFrame, test: pd.DataFrame) -> None:\n",
            "      118 |     prefix_stats = train.groupby(\"id_prefix\")[\"id_len\"].agg([\"mean\", \"count\"]).rename(\n",
            "      119 |         columns={\"mean\": \"prefix_len_mean\", \"count\": \"prefix_len_count\"}\n",
            "      120 |     )\n",
            "      121 |     for df in (train, test):\n",
            "      122 |         df[\"prefix_len_mean\"] = df[\"id_prefix\"].map(prefix_stats[\"prefix_len_mean\"]).fillna(prefix_stats[\"prefix_len_mean\"].mean())\n",
            "      123 |         df[\"prefix_len_count\"] = df[\"id_prefix\"].map(prefix_stats[\"prefix_len_count\"]).fillna(0)\n",
            "      124 |     first_stats = train.groupby(\"id_first_char\")[\"id_len\"].mean()\n",
            "      125 |     last_stats = train.groupby(\"id_last_char\")[\"id_len\"].mean()\n",
            "      126 |     for df in (train, test):\n",
            "      127 |         df[\"first_char_len_mean\"] = df[\"id_first_char\"].map(first_stats).fillna(first_stats.mean())\n",
            "      128 |         df[\"last_char_len_mean\"] = df[\"id_last_char\"].map(last_stats).fillna(last_stats.mean())\n",
            "      129 | \n",
            "      130 | \n",
            "      131 | def add_interactions(train: pd.DataFrame, test: pd.DataFrame) -> None:\n",
            "      132 |     for df in (train, test):\n",
            "      133 |         df[\"id_len_log\"] = np.log1p(df[\"id_len\"])\n",
            "      134 |         df[\"id_digits_log\"] = np.log1p(df[\"id_digits\"])\n",
            "      135 |         df[\"digit_density\"] = df[\"id_digits\"] / (df[\"id_len\"] + 1e-6)\n",
            "      136 |         df[\"len_times_hasnum\"] = df[\"id_len\"] * df[\"id_has_number\"]\n",
            "      137 |         df[\"prefix_len_mean_ratio\"] = df[\"prefix_len_mean\"] / (df[\"id_len\"] + 1e-6)\n",
            "      138 |         df[\"digits_times_prefix_count\"] = df[\"id_digits\"] * df[\"prefix_len_count\"]\n",
            "      139 | \n",
            "      140 | \n",
            "      141 | def clean_feature_frame(train: pd.DataFrame, test: pd.DataFrame) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
            "      142 |     drop_cols = [\"id_prefix\", \"id_first_char\", \"id_last_char\"]\n",
            "      143 |     train = train.drop(columns=drop_cols)\n",
            "      144 |     test = test.drop(columns=drop_cols)\n",
            "      145 |     return train, test\n",
            "      146 | \n",
            "      147 | \n",
            "      148 | def build_feature_matrix(\n",
            "      149 |     base_train: pd.DataFrame,\n",
            "      150 |     base_test: pd.DataFrame,\n",
            "      151 |     target_col: str,\n",
            "      152 |     debug: bool,\n",
            "      153 |     seed: int,\n",
            "      154 | ) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
            "      155 |     train = string_base_features(base_train)\n",
            "      156 |     test = string_base_features(base_test)\n",
            "      157 |     frequency_cols = [\"id_first_char\", \"id_last_char\", \"id_prefix\"]\n",
            "      158 |     frequency_encode(train, test, frequency_cols)\n",
            "      159 |     target_cols = [\"id_first_char\", \"id_prefix\"]\n",
            "      160 |     n_splits = 3 if debug else 5\n",
            "      161 |     for col in target_cols:\n",
            "      162 |         train_enc, test_enc = target_encode_cv(train, test, col, target_col, n_splits=n_splits, seed=seed)\n",
            "      163 |         train[f\"{col}_te\"] = train_enc\n",
            "      164 |         test[f\"{col}_te\"] = test_enc\n",
            "      165 |         logging.info(\"Target encoding on %s completed\", col)\n",
            "      166 |     add_aggregations(train, test)\n",
            "      167 |     add_interactions(train, test)\n",
            "      168 |     train, test = clean_feature_frame(train, test)\n",
            "      169 |     return train, test\n",
            "      170 | \n",
            "      171 | \n",
            "      172 | def select_features_via_lgbm(X: pd.DataFrame, y: pd.Series, debug: bool, seed: int) -> Tuple[List[str], pd.Series]:\n",
            "      173 |     params = {\n",
            "      174 |         \"n_estimators\": 80 if debug else 200,\n",
            "      175 |         \"learning_rate\": 0.1,\n",
            "      176 |         \"num_leaves\": 31,\n",
            "      177 |         \"max_depth\": 6 if debug else 8,\n",
            "      178 |         \"random_state\": seed,\n",
            "      179 |         \"n_jobs\": 4,\n",
            "      180 |         \"verbose\": -1,\n",
            "      181 |     }\n",
            "      182 |     model = lgb.LGBMClassifier(**params)\n",
            "      183 |     model.fit(X, y)\n",
            "      184 |     importance = pd.Series(model.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
            "      185 |     normalized = importance / (importance.sum() + 1e-12)\n",
            "      186 |     threshold = 1e-4\n",
            "      187 |     selected = normalized[normalized > threshold].index.tolist()\n",
            "      188 |     if not selected:\n",
            "      189 |         selected = importance.head(5).index.tolist()\n",
            "      190 |         logging.warning(\"No features passed importance threshold %.1e. Falling back to top features: %s\", threshold, selected)\n",
            "      191 |     dropped = [col for col in X.columns if col not in selected]\n",
            "      192 |     logging.info(\"Selected %d features (threshold %.1e). Dropped %d features.\", len(selected), threshold, len(dropped))\n",
            "      193 |     logging.info(\"Top normalized importances:\\n%s\", normalized.head(10))\n",
            "      194 |     return selected, normalized\n",
            "      195 | \n",
            "      196 | \n",
            "      197 | def print_correlation_metrics(X: pd.DataFrame, y: pd.Series, selected: List[str]) -> None:\n",
            "      198 |     corr_matrix = pd.concat([X[selected], y.rename(\"target\")], axis=1).corr()[\"target\"].abs().sort_values(ascending=False)\n",
            "      199 |     logging.info(\"Top feature correlations with target:\\n%s\", corr_matrix.head(10))\n",
            "      200 | \n",
            "      201 | \n",
            "      202 | def save_features(\n",
            "      203 |     train: pd.DataFrame,\n",
            "      204 |     test: pd.DataFrame,\n",
            "      205 |     target_col: str,\n",
            "      206 |     selected_features: List[str],\n",
            "      207 | ) -> None:\n",
            "      208 |     train_output = train[[\"id\", target_col] + selected_features].copy()\n",
            "      209 |     test_output = test[[\"id\"] + selected_features].copy()\n",
            "      210 |     train_output.to_csv(TRAIN_OUTPUT, index=False)\n",
            "      211 |     test_output.to_csv(TEST_OUTPUT, index=False)\n",
            "      212 |     logging.info(\"Saved engineered train features to %s\", TRAIN_OUTPUT)\n",
            "      213 |     logging.info(\"Saved engineered test features to %s\", TEST_OUTPUT)\n",
            "      214 | \n",
            "      215 | \n",
            "      216 | def main() -> None:\n",
            "      217 |     setup_logging()\n",
            "      218 |     args = parse_args()\n",
            "      219 |     ensure_directories()\n",
            "      220 |     data_root = args.data_root\n",
            "      221 |     logging.info(\"Running advanced_feature_engineering in %s mode\", args.mode)\n",
            "      222 |     global TRAIN_CSV, TEST_CSV, SAMPLE_SUB_CSV\n",
            "      223 |     TRAIN_CSV = data_root / TRAIN_CSV.name\n",
            "      224 |     TEST_CSV = data_root / TEST_CSV.name\n",
            "      225 |     SAMPLE_SUB_CSV = data_root / SAMPLE_SUB_CSV.name\n",
            "      226 |     with log_stage(\"Loading data\"):\n",
            "      227 |         train_df = read_csv(TRAIN_CSV)\n",
            "      228 |         test_df = read_csv(TEST_CSV)\n",
            "      229 |         sample_submission = read_csv(SAMPLE_SUB_CSV)\n",
            "      230 |     safe_validate_sample_submission(sample_submission, test_df)\n",
            "      231 |     if args.mode == \"debug\" and len(train_df) > 4000:\n",
            "      232 |         train_df = train_df.sample(n=4000, random_state=args.seed).reset_index(drop=True)\n",
            "      233 |         logging.info(\"Debug mode: reduced training data to %d samples\", len(train_df))\n",
            "      234 |     has_target = \"has_cactus\"\n",
            "      235 |     if has_target not in train_df.columns:\n",
            "      236 |         raise KeyError(\"Target column 'has_cactus' missing from train data\")\n",
            "      237 |     with log_stage(\"Feature creation\"):\n",
            "      238 |         train_features, test_features = build_feature_matrix(train_df, test_df, has_target, debug=(args.mode == \"debug\"), seed=args.seed)\n",
            "      239 |     feature_cols = [col for col in train_features.columns if col not in {\"id\", has_target}]\n",
            "      240 |     train_matrix = train_features[feature_cols].fillna(-1)\n",
            "      241 |     test_matrix = test_features[feature_cols].fillna(-1)\n",
            "      242 |     target = train_features[has_target].astype(int)\n",
            "      243 |     with log_stage(\"Feature selection\"):\n",
            "      244 |         selected_features, importance = select_features_via_lgbm(train_matrix, target, debug=(args.mode == \"debug\"), seed=args.seed)\n",
            "      245 |         print_correlation_metrics(train_matrix, target, selected_features)\n",
            "      246 |         dropped_features = [col for col in feature_cols if col not in selected_features]\n",
            "      247 |         logging.info(\"Dropped features (%d): %s\", len(dropped_features), dropped_features)\n",
            "      248 |     with log_stage(\"Saving features\"):\n",
            "      249 |         save_features(train_features, test_features, has_target, selected_features)\n",
            "      250 |     logging.info(\"Feature engineering complete. Selected %d features. Dropped features written above.\", len(selected_features))\n",
            "      251 | \n",
            "      252 | \n",
            "      253 | if __name__ == \"__main__\":\n",
            "      254 |     main()\n",
            "\n",
            "Code saved to: generated_code_advanced_feature_engineering.py\n",
            "Syntax error detected: Syntax error at line 30: expected 'except' or 'finally' block\n",
            "\n",
            "Executing code...\n",
            "\n",
            "Attempt 1/3\n",
            "   ‚ö†Ô∏è  Code validation failed: Missing required output: 'Final Validation Performance: {score}'\n",
            "Execution failed: Missing required output: 'Final Validation Performance: {score}'\n",
            "\n",
            "Getting meta-evaluator feedback...\n",
            "Meta-Feedback:\n",
            "1. **Root cause**: The pipeline expects a mandatory log/message ‚ÄúFinal Validation Performance: {score}‚Äù but the script never computes or emits any validation score.  \n",
            "2. **Code fix**: After feature selection, run a quick `StratifiedKFold` CV (or use the LightGBM model already trained) to compute accuracy/AUC and log `logging.info(\"Final Validation Performance: %.4f\", score)` so the required string appears.  \n",
            "3. **Best practice**: Encapsulate required outputs in a helper (e.g., `report_final_score(score)`) and document them; add a unit/integration test that checks the log/output for that exact string to avoid regressions.\n",
            "\n",
            "Passing error context to fixer: Missing required output: 'Final Validation Performance: {score}'\n",
            "Attempting to fix...\n",
            "\n",
            "Attempt 2/3\n",
            "   ‚ö†Ô∏è  Warning: LightGBM/XGBoost code without categorical encoding detected\n",
            "      ‚ö†Ô∏è 2025-12-08 00:46:24 INFO Running advanced_feature_engineering in debug mode\n",
            "      ‚ö†Ô∏è 2025-12-08 00:46:24 INFO [STAGE] Loading data started\n",
            "      ‚ö†Ô∏è 2025-12-08 00:46:24 INFO Loading /content/kaggle_competitions/competitions/aerial-cactus-identification/train.csv\n",
            "      ‚ö†Ô∏è 2025-12-08 00:46:24 INFO Loading /content/kaggle_competitions/competitions/aerial-cactus-identification/test.csv\n",
            "      ‚ö†Ô∏è 2025-12-08 00:46:24 INFO [STAGE] Loading data completed in 0.02s\n",
            "      ‚ö†Ô∏è Traceback (most recent call last):\n",
            "      ‚ö†Ô∏è   File \"/content/kaggle_competitions/competitions/aerial-cactus-identification/_exec_1765154781.py\", line 276, in <module>\n",
            "      ‚ö†Ô∏è     main()\n",
            "      ‚ö†Ô∏è   File \"/content/kaggle_competitions/competitions/aerial-cactus-identification/_exec_1765154781.py\", line 249, in main\n",
            "      ‚ö†Ô∏è     test_df = read_csv(TEST_CSV)\n",
            "      ‚ö†Ô∏è               ^^^^^^^^^^^^^^^^^^\n",
            "      ‚ö†Ô∏è   File \"/content/kaggle_competitions/competitions/aerial-cactus-identification/_exec_1765154781.py\", line 58, in read_csv\n",
            "      ‚ö†Ô∏è     return pd.read_csv(path, **kwargs)\n",
            "      ‚ö†Ô∏è            ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      ‚ö†Ô∏è   File \"/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\", line 1026, in read_csv\n",
            "      ‚ö†Ô∏è     return _read(filepath_or_buffer, kwds)\n",
            "      ‚ö†Ô∏è            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      ‚ö†Ô∏è   File \"/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\", line 620, in _read\n",
            "      ‚ö†Ô∏è     parser = TextFileReader(filepath_or_buffer, **kwds)\n",
            "      ‚ö†Ô∏è              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      ‚ö†Ô∏è   File \"/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\", line 1620, in __init__\n",
            "      ‚ö†Ô∏è     self._engine = self._make_engine(f, self.engine)\n",
            "      ‚ö†Ô∏è                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      ‚ö†Ô∏è   File \"/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\", line 1880, in _make_engine\n",
            "      ‚ö†Ô∏è     self.handles = get_handle(\n",
            "      ‚ö†Ô∏è                    ^^^^^^^^^^^\n",
            "      ‚ö†Ô∏è   File \"/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\", line 873, in get_handle\n",
            "      ‚ö†Ô∏è     handle = open(\n",
            "      ‚ö†Ô∏è              ^^^^^\n",
            "      ‚ö†Ô∏è FileNotFoundError: [Errno 2] No such file or directory: '/content/kaggle_competitions/competitions/aerial-cactus-identification/test.csv'\n",
            "Execution failed: ^^^^^\n",
            "Passing error context to fixer: ^^^^^\n",
            "Attempting to fix...\n",
            "\n",
            "Attempt 3/3\n",
            "   ‚ö†Ô∏è  Warning: LightGBM/XGBoost code without categorical encoding detected\n",
            "      ‚ö†Ô∏è 2025-12-08 00:46:53 INFO Running advanced_feature_engineering in debug mode\n",
            "      ‚ö†Ô∏è 2025-12-08 00:46:53 INFO [STAGE] Loading data started\n",
            "      ‚ö†Ô∏è 2025-12-08 00:46:53 INFO Loading /content/kaggle_competitions/competitions/aerial-cactus-identification/train.csv\n",
            "      ‚ö†Ô∏è 2025-12-08 00:46:53 INFO Loading /content/kaggle_competitions/competitions/aerial-cactus-identification/test.csv\n",
            "      ‚ö†Ô∏è 2025-12-08 00:46:53 INFO [STAGE] Loading data completed in 0.02s\n",
            "      ‚ö†Ô∏è Traceback (most recent call last):\n",
            "      ‚ö†Ô∏è   File \"/content/kaggle_competitions/competitions/aerial-cactus-identification/_exec_1765154810.py\", line 276, in <module>\n",
            "      ‚ö†Ô∏è     main()\n",
            "      ‚ö†Ô∏è   File \"/content/kaggle_competitions/competitions/aerial-cactus-identification/_exec_1765154810.py\", line 249, in main\n",
            "      ‚ö†Ô∏è     test_df = read_csv(TEST_CSV)\n",
            "      ‚ö†Ô∏è               ^^^^^^^^^^^^^^^^^^\n",
            "      ‚ö†Ô∏è   File \"/content/kaggle_competitions/competitions/aerial-cactus-identification/_exec_1765154810.py\", line 58, in read_csv\n",
            "      ‚ö†Ô∏è     return pd.read_csv(path, **kwargs)\n",
            "      ‚ö†Ô∏è            ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      ‚ö†Ô∏è   File \"/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\", line 1026, in read_csv\n",
            "      ‚ö†Ô∏è     return _read(filepath_or_buffer, kwds)\n",
            "      ‚ö†Ô∏è            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      ‚ö†Ô∏è   File \"/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\", line 620, in _read\n",
            "      ‚ö†Ô∏è     parser = TextFileReader(filepath_or_buffer, **kwds)\n",
            "      ‚ö†Ô∏è              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      ‚ö†Ô∏è   File \"/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\", line 1620, in __init__\n",
            "      ‚ö†Ô∏è     self._engine = self._make_engine(f, self.engine)\n",
            "      ‚ö†Ô∏è                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      ‚ö†Ô∏è   File \"/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\", line 1880, in _make_engine\n",
            "      ‚ö†Ô∏è     self.handles = get_handle(\n",
            "      ‚ö†Ô∏è                    ^^^^^^^^^^^\n",
            "      ‚ö†Ô∏è   File \"/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\", line 873, in get_handle\n",
            "      ‚ö†Ô∏è     handle = open(\n",
            "      ‚ö†Ô∏è              ^^^^^\n",
            "      ‚ö†Ô∏è FileNotFoundError: [Errno 2] No such file or directory: '/content/kaggle_competitions/competitions/aerial-cactus-identification/test.csv'\n",
            "Execution failed: ^^^^^\n",
            "\n",
            "Entering debug mode...\n",
            "Last error passed to debugger: ^^^^^\n",
            "   Debug timeout set to: 600s (10.0 min)\n",
            "   Debug iteration 1/5\n",
            "   ‚ö†Ô∏è  Code validation failed: Missing required output: 'Final Validation Performance: {score}'\n",
            "   Debug iteration 2/5\n",
            "   ‚ö†Ô∏è  Warning: LightGBM/XGBoost code without categorical encoding detected\n",
            "      ‚ö†Ô∏è 2025-12-08 00:49:07 INFO [STAGE] Data loading started\n",
            "      ‚ö†Ô∏è 2025-12-08 00:49:07 INFO Loading /content/kaggle_competitions/competitions/aerial-cactus-identification/train.csv\n",
            "      ‚ö†Ô∏è 2025-12-08 00:49:07 INFO Loading /content/kaggle_competitions/competitions/aerial-cactus-identification/test.csv\n",
            "      ‚ö†Ô∏è 2025-12-08 00:49:07 INFO [STAGE] Data loading completed in 0.02s\n",
            "      ‚ö†Ô∏è Traceback (most recent call last):\n",
            "      ‚ö†Ô∏è   File \"/content/kaggle_competitions/competitions/aerial-cactus-identification/_exec_1765154944.py\", line 153, in <module>\n",
            "      ‚ö†Ô∏è     main()\n",
            "      ‚ö†Ô∏è   File \"/content/kaggle_competitions/competitions/aerial-cactus-identification/_exec_1765154944.py\", line 100, in main\n",
            "      ‚ö†Ô∏è     test_df = read_csv(data_root / \"test.csv\")\n",
            "      ‚ö†Ô∏è               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      ‚ö†Ô∏è   File \"/content/kaggle_competitions/competitions/aerial-cactus-identification/_exec_1765154944.py\", line 62, in read_csv\n",
            "      ‚ö†Ô∏è     return pd.read_csv(path, **kwargs)\n",
            "      ‚ö†Ô∏è            ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      ‚ö†Ô∏è   File \"/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\", line 1026, in read_csv\n",
            "      ‚ö†Ô∏è     return _read(filepath_or_buffer, kwds)\n",
            "      ‚ö†Ô∏è            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      ‚ö†Ô∏è   File \"/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\", line 620, in _read\n",
            "      ‚ö†Ô∏è     parser = TextFileReader(filepath_or_buffer, **kwds)\n",
            "      ‚ö†Ô∏è              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      ‚ö†Ô∏è   File \"/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\", line 1620, in __init__\n",
            "      ‚ö†Ô∏è     self._engine = self._make_engine(f, self.engine)\n",
            "      ‚ö†Ô∏è                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      ‚ö†Ô∏è   File \"/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\", line 1880, in _make_engine\n",
            "      ‚ö†Ô∏è     self.handles = get_handle(\n",
            "      ‚ö†Ô∏è                    ^^^^^^^^^^^\n",
            "      ‚ö†Ô∏è   File \"/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\", line 873, in get_handle\n",
            "      ‚ö†Ô∏è     handle = open(\n",
            "      ‚ö†Ô∏è              ^^^^^\n",
            "      ‚ö†Ô∏è FileNotFoundError: [Errno 2] No such file or directory: '/content/kaggle_competitions/competitions/aerial-cactus-identification/test.csv'\n",
            "   Debug iteration 3/5\n",
            "   ‚ö†Ô∏è  Warning: LightGBM/XGBoost code without categorical encoding detected\n",
            "      ‚ö†Ô∏è 2025-12-08 00:50:00 WARNING Data root /content/kaggle_competitions/competitions/aerial-cactus-identification missing files ['test.csv']\n",
            "      ‚ö†Ô∏è Traceback (most recent call last):\n",
            "      ‚ö†Ô∏è   File \"/content/kaggle_competitions/competitions/aerial-cactus-identification/_exec_1765154997.py\", line 158, in <module>\n",
            "      ‚ö†Ô∏è     main()\n",
            "      ‚ö†Ô∏è   File \"/content/kaggle_competitions/competitions/aerial-cactus-identification/_exec_1765154997.py\", line 105, in main\n",
            "      ‚ö†Ô∏è     data_root = resolve_data_root(args.data_root)\n",
            "      ‚ö†Ô∏è                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      ‚ö†Ô∏è   File \"/content/kaggle_competitions/competitions/aerial-cactus-identification/_exec_1765154997.py\", line 59, in resolve_data_root\n",
            "      ‚ö†Ô∏è     raise FileNotFoundError(\"No valid data root found among provided paths\")\n",
            "      ‚ö†Ô∏è FileNotFoundError: No valid data root found among provided paths\n",
            "   Debug iteration 4/5\n",
            "   ‚ö†Ô∏è  Warning: LightGBM/XGBoost code without categorical encoding detected\n",
            "      ‚ö†Ô∏è 2025-12-08 00:50:58 WARNING Data root /content/kaggle_competitions/competitions/aerial-cactus-identification missing files ['test.csv']\n",
            "      ‚ö†Ô∏è Traceback (most recent call last):\n",
            "      ‚ö†Ô∏è   File \"/content/kaggle_competitions/competitions/aerial-cactus-identification/_exec_1765155054.py\", line 175, in <module>\n",
            "      ‚ö†Ô∏è     main()\n",
            "      ‚ö†Ô∏è   File \"/content/kaggle_competitions/competitions/aerial-cactus-identification/_exec_1765155054.py\", line 121, in main\n",
            "      ‚ö†Ô∏è     data_root = resolve_data_root(args.data_root)\n",
            "      ‚ö†Ô∏è                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      ‚ö†Ô∏è   File \"/content/kaggle_competitions/competitions/aerial-cactus-identification/_exec_1765155054.py\", line 75, in resolve_data_root\n",
            "      ‚ö†Ô∏è     raise FileNotFoundError(\"No valid data root found among provided paths\")\n",
            "      ‚ö†Ô∏è FileNotFoundError: No valid data root found among provided paths\n",
            "Debug halted: same error persists; stopping to avoid infinite loop\n",
            "Component timeout set to: 3000s (50.0 min)\n",
            "\u0005 DSPy configured with openai/gpt-5.1-codex-mini\n",
            "\u000f  No optimized prompts found for developer_generator\n",
            "\u000f  No optimized prompts found for developer_fixer\n",
            "Using base (unoptimized) generator module\n",
            "Using base (unoptimized) fixer module\n",
            "\n",
            "============================================================\n",
            "= DEVELOPER AGENT: Implementing Components\n",
            "============================================================\n",
            "\n",
            "= Implementing: advanced_feature_engineering (feature_engineering)\n",
            "Estimated Impact: 15.0%\n",
            "Component timeout set to: 900s (15.0 min)\n",
            "\n",
            "Generating code...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025/12/08 01:00:16 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\u001b[31mL Workflow failed: Adapter JSONAdapter failed to parse the LM response. \u001b[0m\n",
              "\n",
              "\u001b[31mLM Response: \u001b[0m\u001b[1;31m{\u001b[0m\u001b[1;31m}\u001b[0m\u001b[31m \u001b[0m\n",
              "\n",
              "\u001b[31mExpected to find output fields in the LM response: \u001b[0m\u001b[31m \u001b[0m\n",
              "\n",
              "\u001b[31mActual output fields parsed from the LM response: \u001b[0m\u001b[1;31m[\u001b[0m\u001b[1;31m]\u001b[0m\u001b[31m \u001b[0m\n",
              "\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">L Workflow failed: Adapter JSONAdapter failed to parse the LM response. </span>\n",
              "\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">LM Response: </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">{}</span><span style=\"color: #800000; text-decoration-color: #800000\"> </span>\n",
              "\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">Expected to find output fields in the LM response:  </span>\n",
              "\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">Actual output fields parsed from the LM response: </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">[]</span><span style=\"color: #800000; text-decoration-color: #800000\"> </span>\n",
              "\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚ùå Erro: Adapter JSONAdapter failed to parse the LM response. \n",
            "\n",
            "LM Response: {} \n",
            "\n",
            "Expected to find output fields in the LM response: [reasoning, code, explanation] \n",
            "\n",
            "Actual output fields parsed from the LM response: [] \n",
            "\n",
            "\n",
            "\n",
            "‚è±Ô∏è Tempo: 350.8 minutos\n",
            "\n",
            "======================================================================\n",
            "‚úì AVALIA√á√ÉO CONCLU√çDA!\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "from kaggle_agents.core import solve_competition\n",
        "import time\n",
        "import traceback\n",
        "\n",
        "# Resultados\n",
        "all_results = []\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"üöÄ INICIANDO AVALIA√á√ÉO MLE-BENCH LITE\")\n",
        "print(f\"   Competi√ß√µes: {len(COMPETITIONS_TO_RUN)}\")\n",
        "print(f\"   Max iterations: {MAX_ITERATIONS}\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "for idx, competition_id in enumerate(COMPETITIONS_TO_RUN, 1):\n",
        "    print(f\"\\n{'#'*70}\")\n",
        "    print(f\"# [{idx}/{len(COMPETITIONS_TO_RUN)}] {competition_id}\")\n",
        "    print(f\"{'#'*70}\")\n",
        "\n",
        "    start_time = time.time()\n",
        "    result = {\n",
        "        \"competition_id\": competition_id,\n",
        "        \"started_at\": datetime.now().isoformat(),\n",
        "        \"status\": \"pending\"\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        # 1. Setup MLE-bench data\n",
        "        data_info = setup_mlebench_data(competition_id)\n",
        "\n",
        "        # 2. Get problem type\n",
        "        problem_type, eval_metric = get_problem_type(competition_id)\n",
        "        print(f\"\\nüìä Problem: {problem_type}, Metric: {eval_metric}\")\n",
        "\n",
        "        # 3. Run kaggle-agents workflow\n",
        "        print(f\"\\nü§ñ Executando solve_competition...\")\n",
        "\n",
        "        agent_result = solve_competition(\n",
        "            competition_name=competition_id,\n",
        "            competition_description=f\"Solve {competition_id} competition\",\n",
        "            problem_type=problem_type,\n",
        "            evaluation_metric=eval_metric,\n",
        "            max_iterations=MAX_ITERATIONS,\n",
        "        )\n",
        "\n",
        "        result[\"agent_result\"] = agent_result\n",
        "        result[\"status\"] = \"completed\"\n",
        "\n",
        "        # 4. Find submission file\n",
        "        workspace = Path(data_info[\"workspace\"])\n",
        "        submission_files = list(workspace.glob(\"*submission*.csv\")) + list(workspace.glob(\"submission.csv\"))\n",
        "\n",
        "        if submission_files:\n",
        "            submission_path = str(submission_files[0])\n",
        "            print(f\"\\nüìÑ Submission: {submission_path}\")\n",
        "\n",
        "            # 5. Validate with MLE-bench\n",
        "            print(f\"\\nüîç Validando com MLE-bench...\")\n",
        "            validation = validate_with_mlebench(competition_id, submission_path)\n",
        "            result[\"mlebench_validation\"] = validation\n",
        "\n",
        "            print(f\"\\nüìä Resultado MLE-bench:\")\n",
        "            print(f\"   Valid: {validation.get('valid_submission', False)}\")\n",
        "            print(f\"   Score: {validation.get('score', 'N/A')}\")\n",
        "            print(f\"   Gold: {validation.get('gold_medal', False)}\")\n",
        "            print(f\"   Silver: {validation.get('silver_medal', False)}\")\n",
        "            print(f\"   Bronze: {validation.get('bronze_medal', False)}\")\n",
        "            print(f\"   Above Median: {validation.get('above_median', False)}\")\n",
        "        else:\n",
        "            result[\"status\"] = \"no_submission\"\n",
        "            print(f\"\\n‚ùå Nenhuma submiss√£o encontrada!\")\n",
        "\n",
        "    except Exception as e:\n",
        "        result[\"status\"] = \"error\"\n",
        "        result[\"error\"] = str(e)\n",
        "        result[\"traceback\"] = traceback.format_exc()\n",
        "        print(f\"\\n‚ùå Erro: {e}\")\n",
        "\n",
        "    # Tempo\n",
        "    elapsed = time.time() - start_time\n",
        "    result[\"elapsed_seconds\"] = elapsed\n",
        "    result[\"finished_at\"] = datetime.now().isoformat()\n",
        "\n",
        "    print(f\"\\n‚è±Ô∏è Tempo: {elapsed/60:.1f} minutos\")\n",
        "\n",
        "    all_results.append(result)\n",
        "\n",
        "    # Salvar resultados parciais\n",
        "    with open(\"/content/mlebench_results.json\", \"w\") as f:\n",
        "        json.dump(all_results, f, indent=2, default=str)\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"‚úì AVALIA√á√ÉO CONCLU√çDA!\")\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zv4fnfDeYTk1"
      },
      "source": [
        "## 7. Results Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "ItnOHkY2YTk1",
        "outputId": "17f50b0a-2cd4-4365-af60-b14952ed4f48"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "üìä RESUMO DOS RESULTADOS\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                    Competition Status  Valid Score Gold Silver Bronze  \\\n",
              "0  aerial-cactus-identification  error  False  None                      \n",
              "\n",
              "  Above Median  Time (min)  \n",
              "0                    350.8  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-59e61f6e-a1cc-42b9-913b-2c16db99e53f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Competition</th>\n",
              "      <th>Status</th>\n",
              "      <th>Valid</th>\n",
              "      <th>Score</th>\n",
              "      <th>Gold</th>\n",
              "      <th>Silver</th>\n",
              "      <th>Bronze</th>\n",
              "      <th>Above Median</th>\n",
              "      <th>Time (min)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>aerial-cactus-identification</td>\n",
              "      <td>error</td>\n",
              "      <td>False</td>\n",
              "      <td>None</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>350.8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-59e61f6e-a1cc-42b9-913b-2c16db99e53f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-59e61f6e-a1cc-42b9-913b-2c16db99e53f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-59e61f6e-a1cc-42b9-913b-2c16db99e53f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_5d32046e-a7d8-4ad2-a435-d2e4ad832fd0\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_summary')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_5d32046e-a7d8-4ad2-a435-d2e4ad832fd0 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_summary');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_summary",
              "repr_error": "Out of range float values are not JSON compliant: nan"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìà Estat√≠sticas:\n",
            "   Total competi√ß√µes: 1\n",
            "   Submiss√µes v√°lidas: 0\n",
            "   Medalhas de Ouro: 0\n",
            "   Medalhas de Prata: 0\n",
            "   Medalhas de Bronze: 0\n",
            "   Acima da Mediana: 0\n",
            "   Tempo total: 350.8 minutos\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "# Carregar resultados\n",
        "with open(\"/content/mlebench_results.json\", \"r\") as f:\n",
        "    all_results = json.load(f)\n",
        "\n",
        "# Criar DataFrame de resumo\n",
        "summary = []\n",
        "for r in all_results:\n",
        "    validation = r.get(\"mlebench_validation\", {})\n",
        "    summary.append({\n",
        "        \"Competition\": r[\"competition_id\"],\n",
        "        \"Status\": r[\"status\"],\n",
        "        \"Valid\": validation.get(\"valid_submission\", False),\n",
        "        \"Score\": validation.get(\"score\"),\n",
        "        \"Gold\": \"ü•á\" if validation.get(\"gold_medal\") else \"\",\n",
        "        \"Silver\": \"ü•à\" if validation.get(\"silver_medal\") else \"\",\n",
        "        \"Bronze\": \"ü•â\" if validation.get(\"bronze_medal\") else \"\",\n",
        "        \"Above Median\": \"‚úì\" if validation.get(\"above_median\") else \"\",\n",
        "        \"Time (min)\": round(r.get(\"elapsed_seconds\", 0) / 60, 1),\n",
        "    })\n",
        "\n",
        "df_summary = pd.DataFrame(summary)\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"üìä RESUMO DOS RESULTADOS\")\n",
        "print(\"=\"*70)\n",
        "display(df_summary)\n",
        "\n",
        "# Estat√≠sticas\n",
        "print(\"\\nüìà Estat√≠sticas:\")\n",
        "print(f\"   Total competi√ß√µes: {len(df_summary)}\")\n",
        "print(f\"   Submiss√µes v√°lidas: {df_summary['Valid'].sum()}\")\n",
        "print(f\"   Medalhas de Ouro: {len([r for r in all_results if r.get('mlebench_validation', {}).get('gold_medal')])}\")\n",
        "print(f\"   Medalhas de Prata: {len([r for r in all_results if r.get('mlebench_validation', {}).get('silver_medal')])}\")\n",
        "print(f\"   Medalhas de Bronze: {len([r for r in all_results if r.get('mlebench_validation', {}).get('bronze_medal')])}\")\n",
        "print(f\"   Acima da Mediana: {len([r for r in all_results if r.get('mlebench_validation', {}).get('above_median')])}\")\n",
        "print(f\"   Tempo total: {df_summary['Time (min)'].sum():.1f} minutos\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "Hk6s95yvYTk1",
        "outputId": "5d789e50-418e-4e4e-9a5f-20415d979a85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úì Resultados salvos em /content/mlebench_results_summary.csv\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_69165027-9557-4ffa-9f4f-61e789e1a66c\", \"mlebench_results_summary.csv\", 126)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_8bff4120-79e0-4aea-98d5-200d424c46de\", \"mlebench_results.json\", 14385)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Salvar CSV\n",
        "df_summary.to_csv(\"/content/mlebench_results_summary.csv\", index=False)\n",
        "print(\"‚úì Resultados salvos em /content/mlebench_results_summary.csv\")\n",
        "\n",
        "# Download\n",
        "from google.colab import files\n",
        "files.download(\"/content/mlebench_results_summary.csv\")\n",
        "files.download(\"/content/mlebench_results.json\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xO1_HAyFYTk1"
      },
      "source": [
        "## 8. Visualiza√ß√£o"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "id": "s7W92NLkYTk1",
        "outputId": "9de6730b-4333-4fe1-877b-9916e9168633"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x500 with 3 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚úì Gr√°fico salvo em /content/mlebench_results_viz.png\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "# 1. Status das submiss√µes\n",
        "status_counts = df_summary['Status'].value_counts()\n",
        "axes[0].pie(status_counts.values, labels=status_counts.index, autopct='%1.1f%%')\n",
        "axes[0].set_title('Status das Submiss√µes')\n",
        "\n",
        "# 2. Medalhas\n",
        "medals = {\n",
        "    'Ouro': len([r for r in all_results if r.get('mlebench_validation', {}).get('gold_medal')]),\n",
        "    'Prata': len([r for r in all_results if r.get('mlebench_validation', {}).get('silver_medal')]),\n",
        "    'Bronze': len([r for r in all_results if r.get('mlebench_validation', {}).get('bronze_medal')]),\n",
        "    'Sem Medalha': len([r for r in all_results if not any([\n",
        "        r.get('mlebench_validation', {}).get('gold_medal'),\n",
        "        r.get('mlebench_validation', {}).get('silver_medal'),\n",
        "        r.get('mlebench_validation', {}).get('bronze_medal')\n",
        "    ])])\n",
        "}\n",
        "colors = ['gold', 'silver', '#CD7F32', 'gray']\n",
        "axes[1].bar(medals.keys(), medals.values(), color=colors)\n",
        "axes[1].set_title('Distribui√ß√£o de Medalhas')\n",
        "axes[1].set_ylabel('Quantidade')\n",
        "\n",
        "# 3. Tempo por competi√ß√£o\n",
        "df_time = df_summary[df_summary['Time (min)'] > 0].sort_values('Time (min)', ascending=True)\n",
        "axes[2].barh(df_time['Competition'], df_time['Time (min)'])\n",
        "axes[2].set_xlabel('Tempo (minutos)')\n",
        "axes[2].set_title('Tempo por Competi√ß√£o')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('/content/mlebench_results_viz.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n‚úì Gr√°fico salvo em /content/mlebench_results_viz.png\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}